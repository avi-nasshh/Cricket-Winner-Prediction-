{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91126ec7-d610-4be2-a44c-2a20fd788394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n",
      "   match id  Player Id    match_dt  team1 team2 winner       by  win amount  \\\n",
      "0   8638034    7907451  01/01/2021  Nn Ds    Wn     Wn  wickets           9   \n",
      "1   8638034    4381761  01/01/2021  Nn Ds    Wn     Wn  wickets           9   \n",
      "2   8638034      31464  01/01/2021  Nn Ds    Wn     Wn  wickets           9   \n",
      "3   8638034     258649  01/01/2021  Nn Ds    Wn     Wn  wickets           9   \n",
      "4   8638034    4949790  01/01/2021  Nn Ds    Wn     Wn  wickets           9   \n",
      "\n",
      "  toss winner toss decision  ... inning2_wickets inning2_balls team1_id  \\\n",
      "0          Wn         field  ...               1            97    17982   \n",
      "1          Wn         field  ...               1            97    17982   \n",
      "2          Wn         field  ...               1            97    17982   \n",
      "3          Wn         field  ...               1            97    17982   \n",
      "4          Wn         field  ...               1            97    17982   \n",
      "\n",
      "  team2_id winner_id  inning_x runs_x balls_faced  Fours_x  Sixes_x  \n",
      "0    18570     18570         1      7           5        1        0  \n",
      "1    18570     18570         1     46          46        4        1  \n",
      "2    18570     18570         1      8          11        1        0  \n",
      "3    18570     18570         1     19          12        2        1  \n",
      "4    18570     18570         1      9          10        0        0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with different encoding to handle potential issues\n",
    "file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the file: {e}\")\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "try:\n",
    "    print(\"Column names:\", df.columns.tolist())\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying the dataframe: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90064cd8-7aa3-4320-ba2a-d8a07a9c1d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/689905764.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/689905764.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with rolling averages saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_batting Avg.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: Date format incorrect. Details: {e}\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate and update rolling averages for a team\n",
    "def calculate_rolling_average(df, team_id):\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "    team_data = team_data.drop_duplicates(subset=['match id'])\n",
    "    \n",
    "    rolling_avgs = {}\n",
    "    previous_scores = []\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # print(f\"Processing Match ID {match_id} for Team {team_id} on {current_match_date}\")\n",
    "        # print(f\"Previous matches excluding current match date:\")\n",
    "        # print(matches_excluding_current[['match id', 'match_dt', 'inning1_runs', 'inning2_runs']])\n",
    "        \n",
    "        if len(matches_excluding_current) > 0:\n",
    "            scores = []\n",
    "            for idx, row in matches_excluding_current.iterrows():\n",
    "                if row['team1_id'] == team_id:\n",
    "                    scores.append(row['inning1_runs'])\n",
    "                if row['team2_id'] == team_id:\n",
    "                    scores.append(row['inning2_runs'])\n",
    "            \n",
    "            previous_scores = scores[-5:] if len(scores) > 5 else scores\n",
    "            rolling_average = pd.Series(previous_scores).mean()\n",
    "            rolling_avgs[match_id] = rolling_average\n",
    "            # print(f\"Match ID {match_id}: Calculated rolling average for team {team_id}: {rolling_average}. Previous scores: {previous_scores}\")\n",
    "        else:\n",
    "            rolling_avgs[match_id] = None\n",
    "            # print(f\"Match ID {match_id}: No previous matches for team {team_id}.\")\n",
    "    \n",
    "    return rolling_avgs\n",
    "\n",
    "# Function to add rolling average columns to the original dataframe\n",
    "def add_rolling_average_columns(df):\n",
    "    # Initialize rolling average columns with NaN\n",
    "    df['rolling_avg_team1'] = pd.NA\n",
    "    df['rolling_avg_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    team1_ids = df['team1_id'].unique()\n",
    "    team2_ids = df['team2_id'].unique()\n",
    "    \n",
    "    for team_id in team1_ids:\n",
    "        # print(f\"Processing team {team_id} for rolling_avg_team1.\")\n",
    "        rolling_avgs_team1 = calculate_rolling_average(df, team_id)\n",
    "        for match_id, avg in rolling_avgs_team1.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'rolling_avg_team1'] = avg\n",
    "\n",
    "    for team_id in team2_ids:\n",
    "        # print(f\"Processing team {team_id} for rolling_avg_team2.\")\n",
    "        rolling_avgs_team2 = calculate_rolling_average(df, team_id)\n",
    "        for match_id, avg in rolling_avgs_team2.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'rolling_avg_team2'] = avg\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to update and save the modified dataframe to a new CSV file\n",
    "def update_and_save_to_csv(df, file_path):\n",
    "    if df is not None:\n",
    "        df = add_rolling_average_columns(df)\n",
    "        if df is not None:\n",
    "            df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with rolling averages saved to {file_path}\")\n",
    "        else:\n",
    "            print(\"Error: Could not calculate rolling average columns.\")\n",
    "    else:\n",
    "        print(\"Error: DataFrame is None. Cannot proceed with updating and saving.\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Print the columns to debug\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        # Convert match date\n",
    "        df = convert_match_date(df)\n",
    "        \n",
    "        if df is not None:\n",
    "            # Perform update and save to CSV\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_batting Avg.csv'\n",
    "            update_and_save_to_csv(df, new_file_path)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761eee9-fff0-44fb-bfc7-53b6157a7357",
   "metadata": {},
   "source": [
    "# Batting avg and strike rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5728ba-565d-4854-8a30-9f89578e9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/995929707.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/995929707.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with rolling averages and strike rates saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Batting Done.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: Date format incorrect. Details: {e}\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate rolling averages for runs scored by a team\n",
    "def calculate_rolling_average(df, team_id):\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "    team_data = team_data.drop_duplicates(subset=['match id'])\n",
    "    \n",
    "    rolling_avgs = {}\n",
    "    previous_scores = []\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # Debugging print statements\n",
    "        # print(f\"Processing Match ID {match_id} for Team {team_id} on {current_match_date}\")\n",
    "        # print(f\"Previous matches excluding current match date:\")\n",
    "        # print(matches_excluding_current[['match id', 'match_dt', 'inning1_runs', 'inning2_runs']])\n",
    "        \n",
    "        if len(matches_excluding_current) > 0:\n",
    "            scores = []\n",
    "            for idx, row in matches_excluding_current.iterrows():\n",
    "                if row['team1_id'] == team_id:\n",
    "                    scores.append(row['inning1_runs'])\n",
    "                if row['team2_id'] == team_id:\n",
    "                    scores.append(row['inning2_runs'])\n",
    "            \n",
    "            previous_scores = scores[-5:] if len(scores) > 5 else scores\n",
    "            rolling_average = pd.Series(previous_scores).mean()\n",
    "            rolling_avgs[match_id] = rolling_average\n",
    "            # print(f\"Match ID {match_id}: Calculated rolling average for team {team_id}: {rolling_average}. Previous scores: {previous_scores}\")\n",
    "        else:\n",
    "            rolling_avgs[match_id] = None\n",
    "            # print(f\"Match ID {match_id}: No previous matches for team {team_id}.\")\n",
    "    \n",
    "    return rolling_avgs\n",
    "\n",
    "# Function to calculate rolling strike rate for a team\n",
    "def calculate_rolling_strike_rate(df, team_id):\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "    team_data = team_data.drop_duplicates(subset=['match id'])\n",
    "    \n",
    "    rolling_strike_rates = {}\n",
    "    previous_strike_rates = []\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # Debugging print statements\n",
    "        # print(f\"Processing Match ID {match_id} for Team {team_id} on {current_match_date}\")\n",
    "        # print(f\"Previous matches excluding current match date:\")\n",
    "        # print(matches_excluding_current[['match id', 'match_dt', 'inning1_runs', 'inning1_balls', 'inning2_runs', 'inning2_balls']])\n",
    "        \n",
    "        if len(matches_excluding_current) > 0:\n",
    "            strike_rates = []\n",
    "            for idx, row in matches_excluding_current.iterrows():\n",
    "                if row['team1_id'] == team_id:\n",
    "                    runs_scored = row['inning1_runs']\n",
    "                    balls_faced = min(row['inning1_balls'], 120)\n",
    "                    strike_rate = (runs_scored / balls_faced) * 100 if balls_faced > 0 else 0\n",
    "                    strike_rates.append(strike_rate)\n",
    "                if row['team2_id'] == team_id:\n",
    "                    runs_scored = row['inning2_runs']\n",
    "                    balls_faced = min(row['inning2_balls'], 120)\n",
    "                    strike_rate = (runs_scored / balls_faced) * 100 if balls_faced > 0 else 0\n",
    "                    strike_rates.append(strike_rate)\n",
    "            \n",
    "            previous_strike_rates = strike_rates[-5:] if len(strike_rates) > 5 else strike_rates\n",
    "            rolling_strike_rate = pd.Series(previous_strike_rates).mean()\n",
    "            rolling_strike_rates[match_id] = rolling_strike_rate\n",
    "            # print(f\"Match ID {match_id}: Calculated rolling strike rate for team {team_id}: {rolling_strike_rate}. Previous strike rates: {previous_strike_rates}\")\n",
    "        else:\n",
    "            rolling_strike_rates[match_id] = None\n",
    "            # print(f\"Match ID {match_id}: No previous matches for team {team_id}.\")\n",
    "    \n",
    "    return rolling_strike_rates\n",
    "\n",
    "# Function to add rolling average columns to the original dataframe\n",
    "def add_rolling_average_columns(df):\n",
    "    # Initialize rolling average columns with NaN\n",
    "    df['rolling_avg_team1'] = pd.NA\n",
    "    df['rolling_avg_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    team1_ids = df['team1_id'].unique()\n",
    "    team2_ids = df['team2_id'].unique()\n",
    "    \n",
    "    for team_id in team1_ids:\n",
    "        # print(f\"Processing team {team_id} for rolling_avg_team1.\")\n",
    "        rolling_avgs_team1 = calculate_rolling_average(df, team_id)\n",
    "        for match_id, avg in rolling_avgs_team1.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'rolling_avg_team1'] = avg\n",
    "\n",
    "    for team_id in team2_ids:\n",
    "        # print(f\"Processing team {team_id} for rolling_avg_team2.\")\n",
    "        rolling_avgs_team2 = calculate_rolling_average(df, team_id)\n",
    "        for match_id, avg in rolling_avgs_team2.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'rolling_avg_team2'] = avg\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to add rolling strike rate columns to the original dataframe\n",
    "def add_rolling_strike_rate_columns(df):\n",
    "    # Initialize rolling strike rate columns with NaN\n",
    "    df['rolling_strike_rate_team1'] = pd.NA\n",
    "    df['rolling_strike_rate_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    team1_ids = df['team1_id'].unique()\n",
    "    team2_ids = df['team2_id'].unique()\n",
    "    \n",
    "    for team_id in team1_ids:\n",
    "        # print(f\"Processing team {team_id} for rolling_strike_rate_team1.\")\n",
    "        rolling_strike_rates_team1 = calculate_rolling_strike_rate(df, team_id)\n",
    "        for match_id, avg in rolling_strike_rates_team1.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'rolling_strike_rate_team1'] = avg\n",
    "\n",
    "    for team_id in team2_ids:\n",
    "        # print(f\"Processing team {team_id} for rolling_strike_rate_team2.\")\n",
    "        rolling_strike_rates_team2 = calculate_rolling_strike_rate(df, team_id)\n",
    "        for match_id, avg in rolling_strike_rates_team2.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'rolling_strike_rate_team2'] = avg\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to update and save the modified dataframe to a new CSV file\n",
    "def update_and_save_to_csv(df, file_path):\n",
    "    if df is not None:\n",
    "        df = add_rolling_average_columns(df)\n",
    "        df = add_rolling_strike_rate_columns(df)\n",
    "        if df is not None:\n",
    "            df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with rolling averages and strike rates saved to {file_path}\")\n",
    "        else:\n",
    "            print(\"Error: Could not calculate rolling average columns.\")\n",
    "    else:\n",
    "        print(\"Error: DataFrame is None. Cannot proceed with updating and saving.\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Print the columns to debug\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        # Convert match date\n",
    "        df = convert_match_date(df)\n",
    "        \n",
    "        if df is not None:\n",
    "            # Perform update and save to CSV\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Batting Done.csv'\n",
    "            update_and_save_to_csv(df, new_file_path)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ce8d7-8157-4b2f-902e-593ada9bd8c4",
   "metadata": {},
   "source": [
    "# Boundary Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88089a84-ef9a-4c46-b571-582201307e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/1980040472.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/1980040472.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with score instances saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Batting Instances.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate the number of 30+, 50+, and 100+ scores for a team in the last 5 matches\n",
    "def calculate_score_instances(df, team_id):\n",
    "    # Filter the team data considering both innings\n",
    "    team_data = df[((df['team1_id'] == team_id) & (df['inning_x'] == 1)) | \n",
    "                   ((df['team2_id'] == team_id) & (df['inning_x'] == 2))].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "\n",
    "    score_instances = {\n",
    "        '30+': {},\n",
    "        '50+': {},\n",
    "        '100+': {}\n",
    "    }\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # Select only the last 5 distinct matches\n",
    "        last_five_matches_ids = matches_excluding_current.drop_duplicates(subset=['match id'], keep='last').tail(5)['match id']\n",
    "        last_five_matches = matches_excluding_current[matches_excluding_current['match id'].isin(last_five_matches_ids)]\n",
    "\n",
    "        if len(last_five_matches) > 0:\n",
    "            scores_30 = last_five_matches[last_five_matches['runs_x'] >= 30].shape[0]\n",
    "            scores_50 = last_five_matches[last_five_matches['runs_x'] >= 50].shape[0]\n",
    "            scores_100 = last_five_matches[last_five_matches['runs_x'] >= 100].shape[0]\n",
    "            \n",
    "            score_instances['30+'][match_id] = scores_30\n",
    "            score_instances['50+'][match_id] = scores_50\n",
    "            score_instances['100+'][match_id] = scores_100\n",
    "        else:\n",
    "            score_instances['30+'][match_id] = 0\n",
    "            score_instances['50+'][match_id] = 0\n",
    "            score_instances['100+'][match_id] = 0\n",
    "    \n",
    "    return score_instances\n",
    "\n",
    "# Function to add columns for 30+, 50+, and 100+ scores to the original dataframe\n",
    "def add_score_instance_columns(df):\n",
    "    # Initialize columns with NaN\n",
    "    df['no_30+score_team_last5_team1'] = pd.NA\n",
    "    df['no_50+score_team_last5_team1'] = pd.NA\n",
    "    df['no_100+score_team_last5_team1'] = pd.NA\n",
    "    df['no_30+score_team_last5_team2'] = pd.NA\n",
    "    df['no_50+score_team_last5_team2'] = pd.NA\n",
    "    df['no_100+score_team_last5_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    for team_id in df['team1_id'].unique():\n",
    "        score_instances_team1 = calculate_score_instances(df, team_id)\n",
    "        \n",
    "        for match_id, count in score_instances_team1['30+'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'no_30+score_team_last5_team1'] = count\n",
    "        for match_id, count in score_instances_team1['50+'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'no_50+score_team_last5_team1'] = count\n",
    "        for match_id, count in score_instances_team1['100+'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'no_100+score_team_last5_team1'] = count\n",
    "\n",
    "    for team_id in df['team2_id'].unique():\n",
    "        score_instances_team2 = calculate_score_instances(df, team_id)\n",
    "        \n",
    "        for match_id, count in score_instances_team2['30+'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'no_30+score_team_last5_team2'] = count\n",
    "        for match_id, count in score_instances_team2['50+'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'no_50+score_team_last5_team2'] = count\n",
    "        for match_id, count in score_instances_team2['100+'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'no_100+score_team_last5_team2'] = count\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Print the columns to debug\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        # Convert match date\n",
    "        df = convert_match_date(df)\n",
    "        \n",
    "        if df is not None:\n",
    "            # Perform update and save to CSV\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Batting Instances.csv'\n",
    "            df = add_score_instance_columns(df)\n",
    "            df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with score instances saved to {new_file_path}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011c1b8-043f-42b4-ad2a-707f56a66a82",
   "metadata": {},
   "source": [
    "# Boundary Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59451e8-4925-418b-af8e-cf46c5c9133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/531500050.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/531500050.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with boundaries instances saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Boundary Instance.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate the number of 4s and 6s hit by batsmen in the last 5 matches\n",
    "def calculate_boundaries_instances(df, team_id):\n",
    "    # Filter the team data considering both innings\n",
    "    team_data = df[((df['team1_id'] == team_id) & (df['inning_x'] == 1)) | \n",
    "                   ((df['team2_id'] == team_id) & (df['inning_x'] == 2))].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "\n",
    "    boundaries_instances = {\n",
    "        '4s': {},\n",
    "        '6s': {}\n",
    "    }\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # Select only the last 5 distinct matches\n",
    "        last_five_matches_ids = matches_excluding_current.drop_duplicates(subset=['match id'], keep='last').tail(5)['match id']\n",
    "        last_five_matches = matches_excluding_current[matches_excluding_current['match id'].isin(last_five_matches_ids)]\n",
    "\n",
    "        if len(last_five_matches) > 0:\n",
    "            fours_hit = last_five_matches['Fours_x'].sum()\n",
    "            sixes_hit = last_five_matches['Sixes_x'].sum()\n",
    "            \n",
    "            boundaries_instances['4s'][match_id] = fours_hit\n",
    "            boundaries_instances['6s'][match_id] = sixes_hit\n",
    "        else:\n",
    "            boundaries_instances['4s'][match_id] = 0\n",
    "            boundaries_instances['6s'][match_id] = 0\n",
    "    \n",
    "    return boundaries_instances\n",
    "\n",
    "# Function to add columns for 4s and 6s to the original dataframe\n",
    "def add_boundaries_instance_columns(df):\n",
    "    # Initialize columns with NaN\n",
    "    df['boundaries_hit_team1'] = pd.NA\n",
    "    df['boundaries_hit_team2'] = pd.NA\n",
    "    df['sixes_hit_team1'] = pd.NA\n",
    "    df['sixes_hit_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    for team_id in df['team1_id'].unique():\n",
    "        boundaries_instances_team1 = calculate_boundaries_instances(df, team_id)\n",
    "        \n",
    "        for match_id, count in boundaries_instances_team1['4s'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'boundaries_hit_team1'] = count\n",
    "        for match_id, count in boundaries_instances_team1['6s'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'sixes_hit_team1'] = count\n",
    "\n",
    "    for team_id in df['team2_id'].unique():\n",
    "        boundaries_instances_team2 = calculate_boundaries_instances(df, team_id)\n",
    "        \n",
    "        for match_id, count in boundaries_instances_team2['4s'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'boundaries_hit_team2'] = count\n",
    "        for match_id, count in boundaries_instances_team2['6s'].items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'sixes_hit_team2'] = count\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Print the columns to debug\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        # Convert match date\n",
    "        df = convert_match_date(df)\n",
    "        \n",
    "        if df is not None:\n",
    "            # Perform update and save to CSV\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Boundary Instance.csv'\n",
    "            df = add_boundaries_instance_columns(df)\n",
    "            df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with boundaries instances saved to {new_file_path}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c5454-4262-4702-b129-98247f1d0256",
   "metadata": {},
   "source": [
    "# Rolling bowler strike rate last 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d281ecd-884f-482e-bfdb-ec496cba5040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/4122290275.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/4122290275.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with rolling average bowling strike rate saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Bowling_Strike_Rate.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate the rolling average of bowling strike rate for a team\n",
    "def calculate_rolling_bowl_strike_rate(df, team_id):\n",
    "    # Filter the team data considering both innings\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "\n",
    "    bowl_strike_rate = {}\n",
    "    \n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # Drop duplicates based on match_id\n",
    "        matches_excluding_current = matches_excluding_current.drop_duplicates(subset=['match id'])\n",
    "\n",
    "        # Select only the last 5 distinct matches\n",
    "        last_five_matches_ids = matches_excluding_current.tail(5)['match id']\n",
    "        last_five_matches = matches_excluding_current[matches_excluding_current['match id'].isin(last_five_matches_ids)]\n",
    "\n",
    "        if len(last_five_matches) > 0:\n",
    "            total_balls_faced = last_five_matches['inning2_balls'].clip(upper=120).sum()\n",
    "            total_wickets = last_five_matches['inning2_wickets'].sum()\n",
    "            bowl_strike_rate_value = total_balls_faced / total_wickets if total_wickets > 0 else 0\n",
    "            \n",
    "            bowl_strike_rate[match_id] = bowl_strike_rate_value\n",
    "        else:\n",
    "            bowl_strike_rate[match_id] = 0\n",
    "    \n",
    "    return bowl_strike_rate\n",
    "\n",
    "# Function to add columns for rolling average of bowling strike rate to the original dataframe\n",
    "def add_rolling_bowl_strike_rate_columns(df):\n",
    "    # Initialize columns with NaN\n",
    "    df['rolling_avg_bowl_strRate_team1'] = pd.NA\n",
    "    df['rolling_avg_bowl_strRate_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    team_ids = pd.concat([df['team1_id'], df['team2_id']]).unique()\n",
    "    \n",
    "    for team_id in team_ids:\n",
    "        bowl_strike_rate = calculate_rolling_bowl_strike_rate(df, team_id)\n",
    "        \n",
    "        for match_id, rate in bowl_strike_rate.items():\n",
    "            if df.loc[df['match id'] == match_id, 'team1_id'].values[0] == team_id:\n",
    "                df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'rolling_avg_bowl_strRate_team1'] = rate\n",
    "            elif df.loc[df['match id'] == match_id, 'team2_id'].values[0] == team_id:\n",
    "                df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'rolling_avg_bowl_strRate_team2'] = rate\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Print the columns to debug\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        # Convert match date\n",
    "        df = convert_match_date(df)\n",
    "        \n",
    "        if df is not None:\n",
    "            # Perform update and save to CSV\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Bowling_Strike_Rate.csv'\n",
    "            df = add_rolling_bowl_strike_rate_columns(df)\n",
    "            df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with rolling average bowling strike rate saved to {new_file_path}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30af9e1b-02b1-4252-b199-5372a278c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/3178739026.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/3178739026.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with rolling average bowler economy saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Bowler_Economy.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], infer_datetime_format=True, errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate the rolling average of bowler economy for a team\n",
    "def calculate_rolling_bowler_economy(df, team_id):\n",
    "    # Filter the team data considering both innings\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "\n",
    "    bowler_economy = {}\n",
    "    \n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        # Drop duplicates based on match_id\n",
    "        matches_excluding_current = matches_excluding_current.drop_duplicates(subset=['match id'])\n",
    "\n",
    "        # Select only the last 5 distinct matches\n",
    "        last_five_matches_ids = matches_excluding_current.tail(5)['match id']\n",
    "        last_five_matches = matches_excluding_current[matches_excluding_current['match id'].isin(last_five_matches_ids)]\n",
    "\n",
    "        if len(last_five_matches) > 0:\n",
    "            total_runs_conceded = last_five_matches['inning2_runs'].sum()\n",
    "            total_balls_faced = last_five_matches['inning2_balls'].clip(upper=120).sum()\n",
    "            bowler_economy_value = (total_runs_conceded / total_balls_faced) * 6 if total_balls_faced > 0 else 0\n",
    "            \n",
    "            bowler_economy[match_id] = bowler_economy_value\n",
    "        else:\n",
    "            bowler_economy[match_id] = 0\n",
    "    \n",
    "    return bowler_economy\n",
    "\n",
    "# Function to add columns for rolling average of bowler economy to the original dataframe\n",
    "def add_rolling_bowler_economy_columns(df):\n",
    "    # Initialize columns with NaN\n",
    "    df['avg_bowler_economy_last5_team1'] = pd.NA\n",
    "    df['avg_bowler_economy_last5_team2'] = pd.NA\n",
    "    \n",
    "    # Process each team separately for team1_id and team2_id\n",
    "    team_ids = pd.concat([df['team1_id'], df['team2_id']]).unique()\n",
    "    \n",
    "    for team_id in team_ids:\n",
    "        bowler_economy = calculate_rolling_bowler_economy(df, team_id)\n",
    "        \n",
    "        for match_id, rate in bowler_economy.items():\n",
    "            if df.loc[df['match id'] == match_id, 'team1_id'].values[0] == team_id:\n",
    "                df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'avg_bowler_economy_last5_team1'] = rate\n",
    "            elif df.loc[df['match id'] == match_id, 'team2_id'].values[0] == team_id:\n",
    "                df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'avg_bowler_economy_last5_team2'] = rate\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Print the columns to debug\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        # Convert match date\n",
    "        df = convert_match_date(df)\n",
    "        \n",
    "        if df is not None:\n",
    "            # Perform update and save to CSV\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Bowler_Economy.csv'\n",
    "            df = add_rolling_bowler_economy_columns(df)\n",
    "            df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with rolling average bowler economy saved to {new_file_path}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b02875f-3100-4fae-8af8-78825a8f794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n",
      "Error: Date format incorrect. Please ensure the date format is '%d/%m/%Y'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], format='%d/%m/%Y')\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"Error: Date format incorrect. Please ensure the date format is '%d/%m/%Y'.\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate the rolling total of wickets taken for a team\n",
    "def calculate_rolling_wickets_taken(df, team_id):\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "\n",
    "    wickets_taken = {}\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        matches_excluding_current = matches_excluding_current.drop_duplicates(subset=['match id'])\n",
    "\n",
    "        last_five_matches_ids = matches_excluding_current.tail(5)['match id']\n",
    "        last_five_matches = matches_excluding_current[matches_excluding_current['match id'].isin(last_five_matches_ids)]\n",
    "\n",
    "        total_wickets = 0\n",
    "        for _, row in last_five_matches.iterrows():\n",
    "            if row['team1_id'] == team_id:\n",
    "                total_wickets += row['inning2_wickets']\n",
    "            if row['team2_id'] == team_id:\n",
    "                total_wickets += row['inning1_wickets']\n",
    "\n",
    "        wickets_taken[match_id] = total_wickets\n",
    "\n",
    "    return wickets_taken\n",
    "\n",
    "# Function to add columns for rolling total of wickets taken and extras conceded to the original dataframe\n",
    "def add_rolling_wickets_and_extras_columns(df):\n",
    "    df['wickets_taken_last5_team1'] = pd.NA\n",
    "    df['wickets_taken_last5_team2'] = pd.NA\n",
    "\n",
    "    for team_id in df['team1_id'].unique():\n",
    "        wickets_taken = calculate_rolling_wickets_taken(df, team_id)\n",
    "\n",
    "        for match_id, count in wickets_taken.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'wickets_taken_last5_team1'] = count\n",
    "\n",
    "    for team_id in df['team2_id'].unique():\n",
    "        wickets_taken = calculate_rolling_wickets_taken(df, team_id)\n",
    "\n",
    "        for match_id, count in wickets_taken.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'wickets_taken_last5_team2'] = count\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "\n",
    "    if df is not None:\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        df = convert_match_date(df)\n",
    "\n",
    "        if df is not None:\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Wickets_and_Extras.csv'\n",
    "            df = add_rolling_wickets_and_extras_columns(df)\n",
    "            df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with rolling total of wickets taken saved to {new_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59a2483b-0070-424b-a07d-e66289c77f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['match id', 'Player Id', 'match_dt', 'team1', 'team2', 'winner', 'by', 'win amount', 'toss winner', 'toss decision', 'venue', 'city', 'lighting', 'series_name', 'season', 'ground_id', 'umpire1', 'umpire2', 'inning1_runs', 'inning1_wickets', 'inning1_balls', 'inning2_runs', 'inning2_wickets', 'inning2_balls', 'team1_id', 'team2_id', 'winner_id', 'inning_x', 'runs_x', 'balls_faced', 'Fours_x', 'Sixes_x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/vv78xffs7mz93tb1wsgmf_7m0000gn/T/ipykernel_53579/190642324.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['match_dt'] = pd.to_datetime(df['match_dt'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe with rolling total of wickets taken saved to /Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Wickets_and_Extras.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided file with error handling\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Unable to decode file. Please check the file encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert 'match_dt' column to datetime format with error handling\n",
    "def convert_match_date(df):\n",
    "    try:\n",
    "        df['match_dt'] = pd.to_datetime(df['match_dt'], errors='coerce')\n",
    "        df = df.dropna(subset=['match_dt'])  # Drop rows where date conversion failed\n",
    "        df.sort_values(by='match_dt', inplace=True)\n",
    "    except KeyError:\n",
    "        print(\"Error: 'match_dt' column not found in the dataset.\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Function to calculate the rolling total of wickets taken for a team\n",
    "def calculate_rolling_wickets_taken(df, team_id):\n",
    "    team_data = df[(df['team1_id'] == team_id) | (df['team2_id'] == team_id)].copy()\n",
    "    team_data = team_data.sort_values(by='match_dt').reset_index(drop=True)\n",
    "\n",
    "    wickets_taken = {}\n",
    "\n",
    "    for i in range(len(team_data)):\n",
    "        match_id = team_data.iloc[i]['match id']\n",
    "        current_match_date = team_data.iloc[i]['match_dt']\n",
    "        matches_excluding_current = team_data[team_data['match_dt'] < current_match_date]\n",
    "\n",
    "        matches_excluding_current = matches_excluding_current.drop_duplicates(subset=['match id'])\n",
    "\n",
    "        last_five_matches_ids = matches_excluding_current.tail(5)['match id']\n",
    "        last_five_matches = matches_excluding_current[matches_excluding_current['match id'].isin(last_five_matches_ids)]\n",
    "\n",
    "        total_wickets = 0\n",
    "        for _, row in last_five_matches.iterrows():\n",
    "            if row['team1_id'] == team_id:\n",
    "                total_wickets += row['inning2_wickets']\n",
    "            if row['team2_id'] == team_id:\n",
    "                total_wickets += row['inning1_wickets']\n",
    "\n",
    "        wickets_taken[match_id] = total_wickets\n",
    "\n",
    "    return wickets_taken\n",
    "\n",
    "# Function to add columns for rolling total of wickets taken and extras conceded to the original dataframe\n",
    "def add_rolling_wickets_and_extras_columns(df):\n",
    "    df['wickets_taken_last5_team1'] = pd.NA\n",
    "    df['wickets_taken_last5_team2'] = pd.NA\n",
    "\n",
    "    for team_id in df['team1_id'].unique():\n",
    "        wickets_taken = calculate_rolling_wickets_taken(df, team_id)\n",
    "\n",
    "        for match_id, count in wickets_taken.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team1_id'] == team_id), 'wickets_taken_last5_team1'] = count\n",
    "\n",
    "    for team_id in df['team2_id'].unique():\n",
    "        wickets_taken = calculate_rolling_wickets_taken(df, team_id)\n",
    "\n",
    "        for match_id, count in wickets_taken.items():\n",
    "            df.loc[(df['match id'] == match_id) & (df['team2_id'] == team_id), 'wickets_taken_last5_team2'] = count\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data.csv'\n",
    "    df = load_dataset(file_path)\n",
    "\n",
    "    if df is not None:\n",
    "        print(\"Columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "        df = convert_match_date(df)\n",
    "\n",
    "        if df is not None:\n",
    "            new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Round 2 Final Data_Wickets_and_Extras.csv'\n",
    "            df = add_rolling_wickets_and_extras_columns(df)\n",
    "            df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Updated dataframe with rolling total of wickets taken saved to {new_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8e4742c-00a9-43d1-b703-3c980472a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for team_id: 33949 and match_dt: 2023-01-09 00:00:00\n",
      "Filtered 38 matches for team_id: 33949\n",
      "Found 24 matches before and 14 matches after 2023-01-09 00:00:00\n",
      "First match after 2023-01-09 00:00:00: 2023-01-14 00:00:00 (team1_id: 33942, team2_id: 33949)\n",
      "Team 33949 is playing as team2 in the first match after 2023-01-09 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33949: [144.0 120.0 5 3 1 45 23 6.964467005076143 15.972972972972974 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33949.\n",
      "Extracting data for team_id: 33928 and match_dt: 2023-01-09 00:00:00\n",
      "Filtered 40 matches for team_id: 33928\n",
      "Found 25 matches before and 15 matches after 2023-01-09 00:00:00\n",
      "First match after 2023-01-09 00:00:00: 2023-01-15 00:00:00 (team1_id: 33963, team2_id: 33928)\n",
      "Team 33928 is playing as team2 in the first match after 2023-01-09 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 33928: [151.8 140.69509403582325 7 3 0 53 28 8.313653136531364 15.055555555555555\n",
      " 33]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33928.\n",
      "Extracting data for team_id: 209 and match_dt: 2022-10-16 00:00:00\n",
      "Filtered 17 matches for team_id: 209\n",
      "Found 9 matches before and 8 matches after 2022-10-16 00:00:00\n",
      "First match after 2022-10-16 00:00:00: 2022-10-18 00:00:00 (team1_id: 209, team2_id: 118)\n",
      "Team 209 is playing as team1 in the first match after 2022-10-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 209: [120.6 102.34675300619573 5 2 0 39 18 6.574007220216607 23.083333333333332\n",
      " 25]\n",
      "Adding extracted data to team1 columns in first file for team1_id 209.\n",
      "Extracting data for team_id: 69 and match_dt: 2022-10-16 00:00:00\n",
      "Filtered 49 matches for team_id: 69\n",
      "Found 32 matches before and 17 matches after 2022-10-16 00:00:00\n",
      "First match after 2022-10-16 00:00:00: 2022-10-20 00:00:00 (team1_id: 69, team2_id: 118)\n",
      "Team 69 is playing as team1 in the first match after 2022-10-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 69: [149.2 128.2499862870934 11 4 0 46 29 8.266423357664234 26.095238095238095\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 69.\n",
      "Extracting data for team_id: 7573 and match_dt: 2023-06-21 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 24 matches before and 3 matches after 2023-06-21 00:00:00\n",
      "First match after 2023-06-21 00:00:00: 2023-06-23 00:00:00 (team1_id: 9967, team2_id: 7573)\n",
      "Team 7573 is playing as team2 in the first match after 2023-06-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 7573: [179.2 149.7909604519774 12 2 0 67 43 8.6875 15.157894736842104 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7573.\n",
      "Extracting data for team_id: 9701 and match_dt: 2023-06-21 00:00:00\n",
      "Filtered 40 matches for team_id: 9701\n",
      "Found 36 matches before and 4 matches after 2023-06-21 00:00:00\n",
      "First match after 2023-06-21 00:00:00: 2023-07-06 00:00:00 (team1_id: 7727, team2_id: 9701)\n",
      "Team 9701 is playing as team2 in the first match after 2023-06-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 9701: [153.4 145.9010750918765 11 2 0 54 42 8.823529411764707 17.0 47]\n",
      "Adding extracted data to team2 columns in first file for team2_id 9701.\n",
      "Extracting data for team_id: 22784 and match_dt: 2022-02-08 00:00:00\n",
      "Filtered 15 matches for team_id: 22784\n",
      "Found 6 matches before and 9 matches after 2022-02-08 00:00:00\n",
      "First match after 2022-02-08 00:00:00: 2022-02-11 00:00:00 (team1_id: 23750, team2_id: 22784)\n",
      "Team 22784 is playing as team2 in the first match after 2022-02-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 22784: [138.8 119.54901960784314 5 2 0 43 26 7.3578947368421055\n",
      " 15.833333333333334 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 22784.\n",
      "Extracting data for team_id: 22763 and match_dt: 2022-02-08 00:00:00\n",
      "Filtered 16 matches for team_id: 22763\n",
      "Found 6 matches before and 10 matches after 2022-02-08 00:00:00\n",
      "First match after 2022-02-08 00:00:00: 2022-02-11 00:00:00 (team1_id: 22763, team2_id: 22497)\n",
      "Team 22763 is playing as team1 in the first match after 2022-02-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 22763: [136.4 116.65290519877676 8 3 0 40 21 6.580310880829016 19.3 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 22763.\n",
      "Extracting data for team_id: 23841 and match_dt: 2022-02-07 00:00:00\n",
      "Filtered 12 matches for team_id: 23841\n",
      "Found 5 matches before and 7 matches after 2022-02-07 00:00:00\n",
      "First match after 2022-02-07 00:00:00: 2022-02-14 00:00:00 (team1_id: 23841, team2_id: 22784)\n",
      "Team 23841 is playing as team1 in the first match after 2022-02-07 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 23841: [151.0 125.83333333333334 9 1 0 63 22 6.979591836734693 17.294117647058822\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 23841.\n",
      "Extracting data for team_id: 23750 and match_dt: 2022-02-07 00:00:00\n",
      "Filtered 17 matches for team_id: 23750\n",
      "Found 5 matches before and 12 matches after 2022-02-07 00:00:00\n",
      "First match after 2022-02-07 00:00:00: 2022-02-11 00:00:00 (team1_id: 23750, team2_id: 22784)\n",
      "Team 23750 is playing as team1 in the first match after 2022-02-07 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 23750: [127.6 113.88712346905 5 1 0 38 13 6.652406417112299 15.16216216216216 39]\n",
      "Adding extracted data to team2 columns in first file for team2_id 23750.\n",
      "Extracting data for team_id: 30393 and match_dt: 2023-04-23 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 31 matches before and 6 matches after 2023-04-23 00:00:00\n",
      "First match after 2023-04-23 00:00:00: 2023-05-14 00:00:00 (team1_id: 30393, team2_id: 30428)\n",
      "Team 30393 is playing as team1 in the first match after 2023-04-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [172.8 149.05882352941177 9 7 0 53 45 8.337391304347827 14.743589743589745\n",
      " 42]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30428 and match_dt: 2023-04-23 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 26 matches before and 7 matches after 2023-04-23 00:00:00\n",
      "First match after 2023-04-23 00:00:00: 2023-04-27 00:00:00 (team1_id: 30428, team2_id: 30414)\n",
      "Team 30428 is playing as team1 in the first match after 2023-04-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30428: [170.4 142.5056497175141 10 5 0 72 40 8.680203045685278 23.64 26]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 36112 and match_dt: 2023-09-19 00:00:00\n",
      "Filtered 27 matches for team_id: 36112\n",
      "Found 26 matches before and 1 matches after 2023-09-19 00:00:00\n",
      "First match after 2023-09-19 00:00:00: 2023-10-09 00:00:00 (team1_id: 36112, team2_id: 36126)\n",
      "Team 36112 is playing as team1 in the first match after 2023-09-19 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 36112: [153.2 133.88426821405545 10 3 0 63 28 7.3906542056074755\n",
      " 13.717948717948715 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36112.\n",
      "Extracting data for team_id: 36098 and match_dt: 2023-09-19 00:00:00\n",
      "Filtered 23 matches for team_id: 36098\n",
      "Found 22 matches before and 1 matches after 2023-09-19 00:00:00\n",
      "First match after 2023-09-19 00:00:00: 2023-09-22 00:00:00 (team1_id: 36084, team2_id: 36098)\n",
      "Team 36098 is playing as team2 in the first match after 2023-09-19 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36098: [161.4 134.5 8 4 1 69 31 7.472924187725631 20.51851851851852 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36098.\n",
      "Extracting data for team_id: 34 and match_dt: 2023-09-03 00:00:00\n",
      "Filtered 44 matches for team_id: 34\n",
      "Found 40 matches before and 4 matches after 2023-09-03 00:00:00\n",
      "First match after 2023-09-03 00:00:00: 2023-12-12 00:00:00 (team1_id: 55, team2_id: 34)\n",
      "Team 34 is playing as team2 in the first match after 2023-09-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 34: [176.4 166.1009372746936 10 4 1 90 35 10.77327935222672 17.03448275862069\n",
      " 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 34.\n",
      "Extracting data for team_id: 27 and match_dt: 2023-09-03 00:00:00\n",
      "Filtered 47 matches for team_id: 27\n",
      "Found 39 matches before and 8 matches after 2023-09-03 00:00:00\n",
      "First match after 2023-09-03 00:00:00: 2023-11-23 00:00:00 (team1_id: 27, team2_id: 55)\n",
      "Team 27 is playing as team1 in the first match after 2023-09-03 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 27: [178.8 157.5217391304348 11 4 0 87 35 8.59963436928702 17.64516129032258\n",
      " 40]\n",
      "Adding extracted data to team2 columns in first file for team2_id 27.\n",
      "Extracting data for team_id: 30393 and match_dt: 2022-05-27 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 23 matches before and 14 matches after 2022-05-27 00:00:00\n",
      "First match after 2022-05-27 00:00:00: 2022-08-05 00:00:00 (team1_id: 30393, team2_id: 36014)\n",
      "Team 30393 is playing as team1 in the first match after 2022-05-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [163.4 137.3985507246377 9 4 1 75 28 8.13781512605042 19.193548387096776\n",
      " 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30428 and match_dt: 2022-05-27 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 22 matches before and 11 matches after 2022-05-27 00:00:00\n",
      "First match after 2022-05-27 00:00:00: 2022-05-29 00:00:00 (team1_id: 30428, team2_id: 48341)\n",
      "Team 30428 is playing as team1 in the first match after 2022-05-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30428: [185.8 154.83333333333331 9 6 2 80 46 8.84 16.666666666666668 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 36014 and match_dt: 2022-05-17 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 20 matches before and 12 matches after 2022-05-17 00:00:00\n",
      "First match after 2022-05-17 00:00:00: 2022-05-22 00:00:00 (team1_id: 36014, team2_id: 30407)\n",
      "Team 36014 is playing as team1 in the first match after 2022-05-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 36014: [158.8 135.5852749301025 12 3 0 61 35 8.115843270868824 18.93548387096774\n",
      " 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30435 and match_dt: 2022-05-17 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 19 matches before and 12 matches after 2022-05-17 00:00:00\n",
      "First match after 2022-05-17 00:00:00: 2022-06-04 00:00:00 (team1_id: 30435, team2_id: 30400)\n",
      "Team 30435 is playing as team1 in the first match after 2022-05-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [161.2 134.33333333333334 7 2 0 57 21 8.13065326633166 17.057142857142857\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 40298 and match_dt: 2023-02-10 00:00:00\n",
      "Filtered 32 matches for team_id: 40298\n",
      "Found 12 matches before and 20 matches after 2023-02-10 00:00:00\n",
      "First match after 2023-02-10 00:00:00: 2023-02-16 00:00:00 (team1_id: 45072, team2_id: 40298)\n",
      "Team 40298 is playing as team2 in the first match after 2023-02-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 40298: [177.4 150.15804402087588 11 6 1 48 49 7.983050847457627\n",
      " 21.071428571428573 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40298.\n",
      "Extracting data for team_id: 35790 and match_dt: 2023-02-10 00:00:00\n",
      "Filtered 22 matches for team_id: 35790\n",
      "Found 4 matches before and 18 matches after 2023-02-10 00:00:00\n",
      "First match after 2023-02-10 00:00:00: 2023-02-14 00:00:00 (team1_id: 45072, team2_id: 35790)\n",
      "Team 35790 is playing as team2 in the first match after 2023-02-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 35790: [147.25 128.58693207377416 7 2 0 46 24 7.416666666666667 16.0 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 35790.\n",
      "Extracting data for team_id: 769 and match_dt: 2023-10-30 00:00:00\n",
      "Filtered 5 matches for team_id: 769\n",
      "Found 4 matches before and 1 matches after 2023-10-30 00:00:00\n",
      "First match after 2023-10-30 00:00:00: 2024-04-13 00:00:00 (team1_id: 202, team2_id: 769)\n",
      "Team 769 is playing as team2 in the first match after 2023-10-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 769: [141.25 117.70833333333331 8 0 0 40 15 7.540178571428571 24.88888888888889\n",
      " 18]\n",
      "Adding extracted data to team1 columns in first file for team1_id 769.\n",
      "Extracting data for team_id: 202 and match_dt: 2023-10-30 00:00:00\n",
      "Filtered 37 matches for team_id: 202\n",
      "Found 25 matches before and 12 matches after 2023-10-30 00:00:00\n",
      "First match after 2023-10-30 00:00:00: 2023-10-31 00:00:00 (team1_id: 279, team2_id: 202)\n",
      "Team 202 is playing as team2 in the first match after 2023-10-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 202: [153.4 129.90090090090092 9 1 0 47 25 7.877551020408163 25.565217391304348\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 202.\n",
      "Extracting data for team_id: 33956 and match_dt: 2023-02-02 00:00:00\n",
      "Filtered 44 matches for team_id: 33956\n",
      "Found 33 matches before and 11 matches after 2023-02-02 00:00:00\n",
      "First match after 2023-02-02 00:00:00: 2023-06-01 00:00:00 (team1_id: 33949, team2_id: 33956)\n",
      "Team 33956 is playing as team2 in the first match after 2023-02-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33956: [168.2 140.42857142857142 10 5 2 51 32 6.6310160427807485 14.025 40]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33956.\n",
      "Extracting data for team_id: 33921 and match_dt: 2023-02-02 00:00:00\n",
      "Filtered 44 matches for team_id: 33921\n",
      "Found 32 matches before and 12 matches after 2023-02-02 00:00:00\n",
      "First match after 2023-02-02 00:00:00: 2023-04-02 00:00:00 (team1_id: 33921, team2_id: 33935)\n",
      "Team 33921 is playing as team1 in the first match after 2023-02-02 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33921: [157.2 131.4632768361582 8 3 0 70 17 7.555183946488293 20.620689655172413\n",
      " 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33921.\n",
      "Extracting data for team_id: 46766 and match_dt: 2023-08-20 00:00:00\n",
      "Filtered 18 matches for team_id: 46766\n",
      "Found 14 matches before and 4 matches after 2023-08-20 00:00:00\n",
      "First match after 2023-08-20 00:00:00: 2023-08-23 00:00:00 (team1_id: 46766, team2_id: 46738)\n",
      "Team 46766 is playing as team1 in the first match after 2023-08-20 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 46766: [153.2 172.92051607068808 10 4 0 59 33 9.048498845265588\n",
      " 14.433333333333334 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 46766.\n",
      "Extracting data for team_id: 46745 and match_dt: 2023-08-20 00:00:00\n",
      "Filtered 16 matches for team_id: 46745\n",
      "Found 14 matches before and 2 matches after 2023-08-20 00:00:00\n",
      "First match after 2023-08-20 00:00:00: 2023-08-22 00:00:00 (team1_id: 46745, team2_id: 46752)\n",
      "Team 46745 is playing as team1 in the first match after 2023-08-20 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 46745: [157.0 151.968585175798 12 5 0 58 40 8.204322200392927 18.178571428571427\n",
      " 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 46745.\n",
      "Extracting data for team_id: 33949 and match_dt: 2022-12-31 00:00:00\n",
      "Filtered 38 matches for team_id: 33949\n",
      "Found 24 matches before and 14 matches after 2022-12-31 00:00:00\n",
      "First match after 2022-12-31 00:00:00: 2023-01-14 00:00:00 (team1_id: 33942, team2_id: 33949)\n",
      "Team 33949 is playing as team2 in the first match after 2022-12-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33949: [144.0 120.0 5 3 1 45 23 6.964467005076143 15.972972972972974 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33949.\n",
      "Extracting data for team_id: 33914 and match_dt: 2022-12-31 00:00:00\n",
      "Filtered 42 matches for team_id: 33914\n",
      "Found 26 matches before and 16 matches after 2022-12-31 00:00:00\n",
      "First match after 2022-12-31 00:00:00: 2023-01-14 00:00:00 (team1_id: 33921, team2_id: 33914)\n",
      "Team 33914 is playing as team2 in the first match after 2022-12-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 33914: [144.4 121.42753623188403 7 2 0 55 15 7.096267190569744 14.542857142857144\n",
      " 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33914.\n",
      "Extracting data for team_id: 38814 and match_dt: 2023-08-26 00:00:00\n",
      "Filtered 22 matches for team_id: 38814\n",
      "Found 20 matches before and 2 matches after 2023-08-26 00:00:00\n",
      "First match after 2023-08-26 00:00:00: 2023-08-27 00:00:00 (team1_id: 38814, team2_id: 36126)\n",
      "Team 38814 is playing as team1 in the first match after 2023-08-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 38814: [140.6 121.93480195816645 7 4 0 47 36 7.332167832167832 14.3 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 38814.\n",
      "Extracting data for team_id: 36070 and match_dt: 2023-08-26 00:00:00\n",
      "Filtered 25 matches for team_id: 36070\n",
      "Found 22 matches before and 3 matches after 2023-08-26 00:00:00\n",
      "First match after 2023-08-26 00:00:00: 2023-08-30 00:00:00 (team1_id: 36126, team2_id: 36070)\n",
      "Team 36070 is playing as team2 in the first match after 2023-08-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36070: [159.6 134.41891891891893 6 4 1 52 44 8.101522842639595 18.46875 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36070.\n",
      "Extracting data for team_id: 27 and match_dt: 2022-02-11 00:00:00\n",
      "Filtered 47 matches for team_id: 27\n",
      "Found 22 matches before and 25 matches after 2022-02-11 00:00:00\n",
      "First match after 2022-02-11 00:00:00: 2022-02-15 00:00:00 (team1_id: 69, team2_id: 27)\n",
      "Team 27 is playing as team2 in the first match after 2022-02-11 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 27: [154.2 132.40214576396596 10 3 0 63 28 9.04093567251462 32.0625 20]\n",
      "Adding extracted data to team1 columns in first file for team1_id 27.\n",
      "Extracting data for team_id: 69 and match_dt: 2022-02-11 00:00:00\n",
      "Filtered 49 matches for team_id: 69\n",
      "Found 22 matches before and 27 matches after 2022-02-11 00:00:00\n",
      "First match after 2022-02-11 00:00:00: 2022-02-15 00:00:00 (team1_id: 69, team2_id: 27)\n",
      "Team 69 is playing as team1 in the first match after 2022-02-11 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 69: [146.2 124.13198757763976 8 3 0 60 19 8.05090909090909 25.0 25]\n",
      "Adding extracted data to team2 columns in first file for team2_id 69.\n",
      "Extracting data for team_id: 41 and match_dt: 2022-01-30 00:00:00\n",
      "Filtered 49 matches for team_id: 41\n",
      "Found 27 matches before and 22 matches after 2022-01-30 00:00:00\n",
      "First match after 2022-01-30 00:00:00: 2022-02-08 00:00:00 (team1_id: 41, team2_id: 55)\n",
      "Team 41 is playing as team1 in the first match after 2022-01-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 41: [159.6 136.05832041554487 9 4 1 50 44 8.02061855670103 20.785714285714285\n",
      " 43]\n",
      "Adding extracted data to team1 columns in first file for team1_id 41.\n",
      "Extracting data for team_id: 20 and match_dt: 2022-01-30 00:00:00\n",
      "Filtered 48 matches for team_id: 20\n",
      "Found 22 matches before and 26 matches after 2022-01-30 00:00:00\n",
      "First match after 2022-01-30 00:00:00: 2022-02-10 00:00:00 (team1_id: 20, team2_id: 62)\n",
      "Team 20 is playing as team1 in the first match after 2022-01-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 20: [170.0 141.66666666666669 9 6 0 57 47 8.192109777015437 20.103448275862068\n",
      " 25]\n",
      "Adding extracted data to team2 columns in first file for team2_id 20.\n",
      "Extracting data for team_id: 7258 and match_dt: 2022-06-02 00:00:00\n",
      "Filtered 37 matches for team_id: 7258\n",
      "Found 16 matches before and 21 matches after 2022-06-02 00:00:00\n",
      "First match after 2022-06-02 00:00:00: 2022-06-17 00:00:00 (team1_id: 7258, team2_id: 9967)\n",
      "Team 7258 is playing as team1 in the first match after 2022-06-02 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 7258: [155.2 141.65377736718364 9 5 0 67 30 8.62998102466793 18.821428571428573\n",
      " 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7258.\n",
      "Extracting data for team_id: 7573 and match_dt: 2022-06-02 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 15 matches before and 12 matches after 2022-06-02 00:00:00\n",
      "First match after 2022-06-02 00:00:00: 2022-06-21 00:00:00 (team1_id: 8700, team2_id: 7573)\n",
      "Team 7573 is playing as team2 in the first match after 2022-06-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 7573: [170.6 142.8205128205128 9 4 0 63 36 9.89655172413793 22.695652173913043\n",
      " 23]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7573.\n",
      "Extracting data for team_id: 48341 and match_dt: 2023-04-25 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 16 matches before and 8 matches after 2023-04-25 00:00:00\n",
      "First match after 2023-04-25 00:00:00: 2023-04-29 00:00:00 (team1_id: 30400, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match after 2023-04-25 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [150.8 127.06351236146634 9 4 0 63 21 7.591216216216216 21.142857142857142\n",
      " 38]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30435 and match_dt: 2023-04-25 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 25 matches before and 6 matches after 2023-04-25 00:00:00\n",
      "First match after 2023-04-25 00:00:00: 2023-05-16 00:00:00 (team1_id: 48334, team2_id: 30435)\n",
      "Team 30435 is playing as team2 in the first match after 2023-04-25 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30435: [175.4 149.29510703363914 8 3 0 61 35 9.132743362831858 22.6 26]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 40550 and match_dt: 2023-02-14 00:00:00\n",
      "Filtered 35 matches for team_id: 40550\n",
      "Found 19 matches before and 16 matches after 2023-02-14 00:00:00\n",
      "First match after 2023-02-14 00:00:00: 2023-02-20 00:00:00 (team1_id: 40592, team2_id: 40550)\n",
      "Team 40550 is playing as team2 in the first match after 2023-02-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 40550: [176.2 146.83333333333331 9 4 0 62 31 8.08 17.647058823529413 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40550.\n",
      "Extracting data for team_id: 40564 and match_dt: 2023-02-14 00:00:00\n",
      "Filtered 33 matches for team_id: 40564\n",
      "Found 16 matches before and 17 matches after 2023-02-14 00:00:00\n",
      "First match after 2023-02-14 00:00:00: 2023-02-16 00:00:00 (team1_id: 40564, team2_id: 40578)\n",
      "Team 40564 is playing as team1 in the first match after 2023-02-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 40564: [137.6 116.95482866043616 6 2 0 62 15 7.054481546572935 21.884615384615383\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 40564.\n",
      "Extracting data for team_id: 251 and match_dt: 2022-07-12 00:00:00\n",
      "Filtered 20 matches for team_id: 251\n",
      "Found 0 matches before and 20 matches after 2022-07-12 00:00:00\n",
      "First match after 2022-07-12 00:00:00: 2022-07-17 00:00:00 (team1_id: 251, team2_id: 146)\n",
      "Team 251 is playing as team1 in the first match after 2022-07-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 251: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team1 columns in first file for team1_id 251.\n",
      "Extracting data for team_id: 153 and match_dt: 2022-07-12 00:00:00\n",
      "Filtered 1 matches for team_id: 153\n",
      "Found 1 matches before and 0 matches after 2022-07-12 00:00:00\n",
      "No match after 2022-07-12 00:00:00. Using first match before 2022-07-12 00:00:00: 2021-08-10 00:00:00 (team1_id: 153, team2_id: 223)\n",
      "Team 153 is playing as team1 in the first match before 2022-07-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 153: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team2 columns in first file for team2_id 153.\n",
      "Extracting data for team_id: 23869 and match_dt: 2022-02-25 00:00:00\n",
      "Filtered 12 matches for team_id: 23869\n",
      "Found 4 matches before and 8 matches after 2022-02-25 00:00:00\n",
      "First match after 2022-02-25 00:00:00: 2022-07-02 00:00:00 (team1_id: 22497, team2_id: 23869)\n",
      "Team 23869 is playing as team2 in the first match after 2022-02-25 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 23869: [143.75 125.96153846153848 9 2 0 37 21 6.6891891891891895\n",
      " 20.181818181818183 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 23869.\n",
      "Extracting data for team_id: 22497 and match_dt: 2022-02-25 00:00:00\n",
      "Filtered 13 matches for team_id: 22497\n",
      "Found 4 matches before and 9 matches after 2022-02-25 00:00:00\n",
      "First match after 2022-02-25 00:00:00: 2022-02-27 00:00:00 (team1_id: 22497, team2_id: 23750)\n",
      "Team 22497 is playing as team1 in the first match after 2022-02-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 22497: [151.75 126.45833333333331 9 2 0 56 14 7.233404710920771\n",
      " 17.296296296296298 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 22497.\n",
      "Extracting data for team_id: 300 and match_dt: 2022-07-10 00:00:00\n",
      "Filtered 2 matches for team_id: 300\n",
      "Found 0 matches before and 2 matches after 2022-07-10 00:00:00\n",
      "First match after 2022-07-10 00:00:00: 2022-09-07 00:00:00 (team1_id: 895, team2_id: 300)\n",
      "Team 300 is playing as team2 in the first match after 2022-07-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 300: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team1 columns in first file for team1_id 300.\n",
      "Extracting data for team_id: 895 and match_dt: 2022-07-10 00:00:00\n",
      "Filtered 1 matches for team_id: 895\n",
      "Found 0 matches before and 1 matches after 2022-07-10 00:00:00\n",
      "First match after 2022-07-10 00:00:00: 2022-09-07 00:00:00 (team1_id: 895, team2_id: 300)\n",
      "Team 895 is playing as team1 in the first match after 2022-07-10 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 895: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team2 columns in first file for team2_id 895.\n",
      "Extracting data for team_id: 7608 and match_dt: 2023-06-23 00:00:00\n",
      "Filtered 28 matches for team_id: 7608\n",
      "Found 27 matches before and 1 matches after 2023-06-23 00:00:00\n",
      "First match after 2023-06-23 00:00:00: 2023-09-06 00:00:00 (team1_id: 9701, team2_id: 7608)\n",
      "Team 7608 is playing as team2 in the first match after 2023-06-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 7608: [143.6 139.22881355932205 8 1 0 56 20 8.738336713995944 18.25925925925926\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7608.\n",
      "Extracting data for team_id: 9701 and match_dt: 2023-06-23 00:00:00\n",
      "Filtered 40 matches for team_id: 9701\n",
      "Found 36 matches before and 4 matches after 2023-06-23 00:00:00\n",
      "First match after 2023-06-23 00:00:00: 2023-07-06 00:00:00 (team1_id: 7727, team2_id: 9701)\n",
      "Team 9701 is playing as team2 in the first match after 2023-06-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 9701: [153.4 145.9010750918765 11 2 0 54 42 8.823529411764707 17.0 47]\n",
      "Adding extracted data to team2 columns in first file for team2_id 9701.\n",
      "Extracting data for team_id: 23113 and match_dt: 2022-02-17 00:00:00\n",
      "Filtered 14 matches for team_id: 23113\n",
      "Found 8 matches before and 6 matches after 2022-02-17 00:00:00\n",
      "First match after 2022-02-17 00:00:00: 2022-02-20 00:00:00 (team1_id: 22784, team2_id: 23113)\n",
      "Team 23113 is playing as team2 in the first match after 2022-02-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 23113: [130.6 112.57898547541524 7 1 0 46 18 6.8125 21.333333333333332 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 23113.\n",
      "Extracting data for team_id: 23750 and match_dt: 2022-02-17 00:00:00\n",
      "Filtered 17 matches for team_id: 23750\n",
      "Found 6 matches before and 11 matches after 2022-02-17 00:00:00\n",
      "First match after 2022-02-17 00:00:00: 2022-02-19 00:00:00 (team1_id: 23869, team2_id: 23750)\n",
      "Team 23750 is playing as team2 in the first match after 2022-02-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 23750: [135.2 117.57894736842104 6 0 0 46 11 6.490434782608695 14.024390243902438\n",
      " 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 23750.\n",
      "Extracting data for team_id: 30421 and match_dt: 2022-05-21 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 24 matches before and 13 matches after 2022-05-21 00:00:00\n",
      "First match after 2022-05-21 00:00:00: 2022-07-04 00:00:00 (team1_id: 30421, team2_id: 48334)\n",
      "Team 30421 is playing as team1 in the first match after 2022-05-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30421: [168.4 155.63377926421404 12 4 0 79 37 8.835164835164836 17.0625 38]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 30435 and match_dt: 2022-05-21 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 19 matches before and 12 matches after 2022-05-21 00:00:00\n",
      "First match after 2022-05-21 00:00:00: 2022-06-04 00:00:00 (team1_id: 30435, team2_id: 30400)\n",
      "Team 30435 is playing as team1 in the first match after 2022-05-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [161.2 134.33333333333334 7 2 0 57 21 8.13065326633166 17.057142857142857\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 7573 and match_dt: 2022-05-27 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 14 matches before and 13 matches after 2022-05-27 00:00:00\n",
      "First match after 2022-05-27 00:00:00: 2022-05-29 00:00:00 (team1_id: 7573, team2_id: 8700)\n",
      "Team 7573 is playing as team1 in the first match after 2022-05-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 7573: [158.4 134.8205128205128 7 4 0 56 35 9.309941520467836 19.0 22]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7573.\n",
      "Extracting data for team_id: 9876 and match_dt: 2022-05-27 00:00:00\n",
      "Filtered 35 matches for team_id: 9876\n",
      "Found 14 matches before and 21 matches after 2022-05-27 00:00:00\n",
      "First match after 2022-05-27 00:00:00: 2022-05-31 00:00:00 (team1_id: 9876, team2_id: 7608)\n",
      "Team 9876 is playing as team1 in the first match after 2022-05-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 9876: [187.2 165.89886941753042 10 6 0 77 44 8.994708994708995 15.75 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 9876.\n",
      "Extracting data for team_id: 272 and match_dt: 2023-11-02 00:00:00\n",
      "Filtered 11 matches for team_id: 272\n",
      "Found 9 matches before and 2 matches after 2023-11-02 00:00:00\n",
      "First match after 2023-11-02 00:00:00: 2024-04-15 00:00:00 (team1_id: 202, team2_id: 272)\n",
      "Team 272 is playing as team2 in the first match after 2023-11-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 272: [141.0 124.29793735676088 7 4 0 55 16 6.654545454545454 25.0 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 272.\n",
      "Extracting data for team_id: 237 and match_dt: 2023-11-02 00:00:00\n",
      "Filtered 19 matches for team_id: 237\n",
      "Found 13 matches before and 6 matches after 2023-11-02 00:00:00\n",
      "First match after 2023-11-02 00:00:00: 2024-01-03 00:00:00 (team1_id: 237, team2_id: 209)\n",
      "Team 237 is playing as team1 in the first match after 2023-11-02 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 237: [154.6 132.66300366300365 11 4 0 71 18 8.02061855670103 27.714285714285715\n",
      " 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 237.\n",
      "Extracting data for team_id: 46766 and match_dt: 2023-08-13 00:00:00\n",
      "Filtered 18 matches for team_id: 46766\n",
      "Found 14 matches before and 4 matches after 2023-08-13 00:00:00\n",
      "First match after 2023-08-13 00:00:00: 2023-08-23 00:00:00 (team1_id: 46766, team2_id: 46738)\n",
      "Team 46766 is playing as team1 in the first match after 2023-08-13 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 46766: [153.2 172.92051607068808 10 4 0 59 33 9.048498845265588\n",
      " 14.433333333333334 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 46766.\n",
      "Extracting data for team_id: 46745 and match_dt: 2023-08-13 00:00:00\n",
      "Filtered 16 matches for team_id: 46745\n",
      "Found 13 matches before and 3 matches after 2023-08-13 00:00:00\n",
      "First match after 2023-08-13 00:00:00: 2023-08-18 00:00:00 (team1_id: 46773, team2_id: 46745)\n",
      "Team 46745 is playing as team2 in the first match after 2023-08-13 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 46745: [156.2 150.64505576403332 12 6 0 57 39 8.539877300613497 20.375 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 46745.\n",
      "Extracting data for team_id: 10366 and match_dt: 2023-06-22 00:00:00\n",
      "Filtered 34 matches for team_id: 10366\n",
      "Found 32 matches before and 2 matches after 2023-06-22 00:00:00\n",
      "First match after 2023-06-22 00:00:00: 2023-06-23 00:00:00 (team1_id: 10366, team2_id: 10576)\n",
      "Team 10366 is playing as team1 in the first match after 2023-06-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 10366: [176.2 149.6422018348624 12 3 0 89 22 8.587436332767403 17.323529411764707\n",
      " 33]\n",
      "Adding extracted data to team1 columns in first file for team1_id 10366.\n",
      "Extracting data for team_id: 10618 and match_dt: 2023-06-22 00:00:00\n",
      "Filtered 35 matches for team_id: 10618\n",
      "Found 34 matches before and 1 matches after 2023-06-22 00:00:00\n",
      "First match after 2023-06-22 00:00:00: 2023-09-06 00:00:00 (team1_id: 10618, team2_id: 10576)\n",
      "Team 10618 is playing as team1 in the first match after 2023-06-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 10618: [141.0 129.84523809523807 7 4 0 63 23 7.608365019011407 14.61111111111111\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 10618.\n",
      "Extracting data for team_id: 13957 and match_dt: 2023-10-17 00:00:00\n",
      "Filtered 14 matches for team_id: 13957\n",
      "Found 13 matches before and 1 matches after 2023-10-17 00:00:00\n",
      "First match after 2023-10-17 00:00:00: 2023-10-25 00:00:00 (team1_id: 15301, team2_id: 13957)\n",
      "Team 13957 is playing as team2 in the first match after 2023-10-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 13957: [171.2 153.1826484018265 8 7 0 61 25 9.667924528301889 25.238095238095237\n",
      " 23]\n",
      "Adding extracted data to team1 columns in first file for team1_id 13957.\n",
      "Extracting data for team_id: 12046 and match_dt: 2023-10-17 00:00:00\n",
      "Filtered 14 matches for team_id: 12046\n",
      "Found 13 matches before and 1 matches after 2023-10-17 00:00:00\n",
      "First match after 2023-10-17 00:00:00: 2023-10-21 00:00:00 (team1_id: 13474, team2_id: 12046)\n",
      "Team 12046 is playing as team2 in the first match after 2023-10-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 12046: [152.4 129.69314641744546 9 3 1 69 22 8.02127659574468 26.857142857142858\n",
      " 22]\n",
      "Adding extracted data to team2 columns in first file for team2_id 12046.\n",
      "Extracting data for team_id: 32388 and match_dt: 2023-10-25 00:00:00\n",
      "Filtered 11 matches for team_id: 32388\n",
      "Found 11 matches before and 0 matches after 2023-10-25 00:00:00\n",
      "No match after 2023-10-25 00:00:00. Using first match before 2023-10-25 00:00:00: 2023-10-19 00:00:00 (team1_id: 32388, team2_id: 12718)\n",
      "Team 32388 is playing as team1 in the first match before 2023-10-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 32388: [155.4 129.5 4 2 0 26 10 7.51006711409396 19.866666666666667 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 32388.\n",
      "Extracting data for team_id: 11283 and match_dt: 2023-10-25 00:00:00\n",
      "Filtered 19 matches for team_id: 11283\n",
      "Found 19 matches before and 0 matches after 2023-10-25 00:00:00\n",
      "No match after 2023-10-25 00:00:00. Using first match before 2023-10-25 00:00:00: 2023-10-16 00:00:00 (team1_id: 11283, team2_id: 13166)\n",
      "Team 11283 is playing as team1 in the first match before 2023-10-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 11283: [148.8 132.69982773471145 6 1 0 31 17 8.326530612244898 24.5 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 11283.\n",
      "Extracting data for team_id: 188 and match_dt: 2023-03-29 00:00:00\n",
      "Filtered 54 matches for team_id: 188\n",
      "Found 39 matches before and 15 matches after 2023-03-29 00:00:00\n",
      "First match after 2023-03-29 00:00:00: 2023-07-10 00:00:00 (team1_id: 62, team2_id: 188)\n",
      "Team 188 is playing as team2 in the first match after 2023-03-29 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 188: [154.0 131.11165048543688 4 2 0 33 12 7.225680933852139 13.526315789473683\n",
      " 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 188.\n",
      "Extracting data for team_id: 216 and match_dt: 2023-03-29 00:00:00\n",
      "Filtered 50 matches for team_id: 216\n",
      "Found 34 matches before and 16 matches after 2023-03-29 00:00:00\n",
      "First match after 2023-03-29 00:00:00: 2023-07-12 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 216 is playing as team1 in the first match after 2023-03-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 216: [130.8 131.83422937303482 6 3 0 53 13 7.759842519685039 19.53846153846154\n",
      " 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 216.\n",
      "Extracting data for team_id: 40452 and match_dt: 2022-01-25 00:00:00\n",
      "Filtered 11 matches for team_id: 40452\n",
      "Found 4 matches before and 7 matches after 2022-01-25 00:00:00\n",
      "First match after 2022-01-25 00:00:00: 2022-08-02 00:00:00 (team1_id: 40424, team2_id: 40452)\n",
      "Team 40452 is playing as team2 in the first match after 2022-01-25 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 40452: [156.25 132.67045454545456 8 3 0 51 22 7.621978021978021 14.67741935483871\n",
      " 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40452.\n",
      "Extracting data for team_id: 45072 and match_dt: 2022-01-25 00:00:00\n",
      "Filtered 27 matches for team_id: 45072\n",
      "Found 0 matches before and 27 matches after 2022-01-25 00:00:00\n",
      "First match after 2022-01-25 00:00:00: 2022-01-29 00:00:00 (team1_id: 40424, team2_id: 45072)\n",
      "Team 45072 is playing as team2 in the first match after 2022-01-25 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 45072: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team2 columns in first file for team2_id 45072.\n",
      "Extracting data for team_id: 7727 and match_dt: 2022-06-09 00:00:00\n",
      "Filtered 35 matches for team_id: 7727\n",
      "Found 17 matches before and 18 matches after 2022-06-09 00:00:00\n",
      "First match after 2022-06-09 00:00:00: 2022-06-17 00:00:00 (team1_id: 7727, team2_id: 8056)\n",
      "Team 7727 is playing as team1 in the first match after 2022-06-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 7727: [149.6 124.66666666666669 8 1 0 67 22 8.455066921606118 21.791666666666668\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7727.\n",
      "Extracting data for team_id: 7258 and match_dt: 2022-06-09 00:00:00\n",
      "Filtered 37 matches for team_id: 7258\n",
      "Found 16 matches before and 21 matches after 2022-06-09 00:00:00\n",
      "First match after 2022-06-09 00:00:00: 2022-06-17 00:00:00 (team1_id: 7258, team2_id: 9967)\n",
      "Team 7258 is playing as team1 in the first match after 2022-06-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 7258: [155.2 141.65377736718364 9 5 0 67 30 8.62998102466793 18.821428571428573\n",
      " 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7258.\n",
      "Extracting data for team_id: 47487 and match_dt: 2022-12-08 00:00:00\n",
      "Filtered 20 matches for team_id: 47487\n",
      "Found 11 matches before and 9 matches after 2022-12-08 00:00:00\n",
      "First match after 2022-12-08 00:00:00: 2022-12-13 00:00:00 (team1_id: 47494, team2_id: 47487)\n",
      "Team 47487 is playing as team2 in the first match after 2022-12-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 47487: [131.4 118.7462121212121 8 3 0 63 15 6.8833652007648185 12.75609756097561\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 47487.\n",
      "Extracting data for team_id: 47508 and match_dt: 2022-12-08 00:00:00\n",
      "Filtered 21 matches for team_id: 47508\n",
      "Found 9 matches before and 12 matches after 2022-12-08 00:00:00\n",
      "First match after 2022-12-08 00:00:00: 2022-12-13 00:00:00 (team1_id: 47480, team2_id: 47508)\n",
      "Team 47508 is playing as team2 in the first match after 2022-12-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 47508: [131.4 123.00678149297444 8 3 0 56 18 8.0 19.92 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 47508.\n",
      "Extracting data for team_id: 46780 and match_dt: 2022-08-13 00:00:00\n",
      "Filtered 20 matches for team_id: 46780\n",
      "Found 10 matches before and 10 matches after 2022-08-13 00:00:00\n",
      "First match after 2022-08-13 00:00:00: 2022-08-15 00:00:00 (team1_id: 46731, team2_id: 46780)\n",
      "Team 46780 is playing as team2 in the first match after 2022-08-13 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 46780: [155.2 157.44311010133794 10 4 0 44 43 8.714285714285714 15.4 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 46780.\n",
      "Extracting data for team_id: 46752 and match_dt: 2022-08-13 00:00:00\n",
      "Filtered 17 matches for team_id: 46752\n",
      "Found 9 matches before and 8 matches after 2022-08-13 00:00:00\n",
      "First match after 2022-08-13 00:00:00: 2022-08-26 00:00:00 (team1_id: 46752, team2_id: 46745)\n",
      "Team 46752 is playing as team1 in the first match after 2022-08-13 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 46752: [131.4 133.55577755577755 9 1 0 54 24 9.130434782608695 19.0 16]\n",
      "Adding extracted data to team2 columns in first file for team2_id 46752.\n",
      "Extracting data for team_id: 42573 and match_dt: 2023-01-13 00:00:00\n",
      "Filtered 28 matches for team_id: 42573\n",
      "Found 8 matches before and 20 matches after 2023-01-13 00:00:00\n",
      "First match after 2023-01-13 00:00:00: 2023-01-20 00:00:00 (team1_id: 40424, team2_id: 42573)\n",
      "Team 42573 is playing as team2 in the first match after 2023-01-13 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 42573: [154.0 136.69288389513108 7 4 0 45 29 7.9613356766256596\n",
      " 20.321428571428573 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 42573.\n",
      "Extracting data for team_id: 35790 and match_dt: 2023-01-13 00:00:00\n",
      "Filtered 22 matches for team_id: 35790\n",
      "Found 0 matches before and 22 matches after 2023-01-13 00:00:00\n",
      "First match after 2023-01-13 00:00:00: 2023-01-19 00:00:00 (team1_id: 47529, team2_id: 35790)\n",
      "Team 35790 is playing as team2 in the first match after 2023-01-13 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 35790: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team2 columns in first file for team2_id 35790.\n",
      "Extracting data for team_id: 7573 and match_dt: 2022-06-07 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 15 matches before and 12 matches after 2022-06-07 00:00:00\n",
      "First match after 2022-06-07 00:00:00: 2022-06-21 00:00:00 (team1_id: 8700, team2_id: 7573)\n",
      "Team 7573 is playing as team2 in the first match after 2022-06-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 7573: [170.6 142.8205128205128 9 4 0 63 36 9.89655172413793 22.695652173913043\n",
      " 23]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7573.\n",
      "Extracting data for team_id: 7608 and match_dt: 2022-06-07 00:00:00\n",
      "Filtered 28 matches for team_id: 7608\n",
      "Found 16 matches before and 12 matches after 2022-06-07 00:00:00\n",
      "First match after 2022-06-07 00:00:00: 2022-06-17 00:00:00 (team1_id: 9701, team2_id: 7608)\n",
      "Team 7608 is playing as team2 in the first match after 2022-06-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 7608: [140.6 127.93583678296866 5 1 0 34 26 7.449438202247191 14.432432432432432\n",
      " 40]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7608.\n",
      "Extracting data for team_id: 40550 and match_dt: 2023-02-23 00:00:00\n",
      "Filtered 35 matches for team_id: 40550\n",
      "Found 20 matches before and 15 matches after 2023-02-23 00:00:00\n",
      "First match after 2023-02-23 00:00:00: 2023-02-26 00:00:00 (team1_id: 40606, team2_id: 40550)\n",
      "Team 40550 is playing as team2 in the first match after 2023-02-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 40550: [169.0 141.5042735042735 9 4 0 69 31 8.311557788944723 17.558823529411764\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40550.\n",
      "Extracting data for team_id: 40578 and match_dt: 2023-02-23 00:00:00\n",
      "Filtered 37 matches for team_id: 40578\n",
      "Found 20 matches before and 17 matches after 2023-02-23 00:00:00\n",
      "First match after 2023-02-23 00:00:00: 2023-02-24 00:00:00 (team1_id: 40578, team2_id: 40592)\n",
      "Team 40578 is playing as team1 in the first match after 2023-02-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 40578: [175.0 147.95238095238096 10 6 0 66 42 8.908783783783784\n",
      " 19.096774193548388 33]\n",
      "Adding extracted data to team2 columns in first file for team2_id 40578.\n",
      "Extracting data for team_id: 76 and match_dt: 2023-10-29 00:00:00\n",
      "Filtered 43 matches for team_id: 76\n",
      "Found 34 matches before and 9 matches after 2023-10-29 00:00:00\n",
      "First match after 2023-10-29 00:00:00: 2023-12-01 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 76 is playing as team2 in the first match after 2023-10-29 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 76: [150.6 125.90677966101696 7 3 0 64 20 8.089285714285715 20.74074074074074\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 76.\n",
      "Extracting data for team_id: 209 and match_dt: 2023-10-29 00:00:00\n",
      "Filtered 17 matches for team_id: 209\n",
      "Found 13 matches before and 4 matches after 2023-10-29 00:00:00\n",
      "First match after 2023-10-29 00:00:00: 2023-11-24 00:00:00 (team1_id: 251, team2_id: 209)\n",
      "Team 209 is playing as team2 in the first match after 2023-10-29 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 209: [142.0 127.49490004079966 8 5 0 56 22 7.639285714285714 24.347826086956523\n",
      " 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 209.\n",
      "Extracting data for team_id: 76 and match_dt: 2023-01-14 00:00:00\n",
      "Filtered 43 matches for team_id: 76\n",
      "Found 29 matches before and 14 matches after 2023-01-14 00:00:00\n",
      "First match after 2023-01-14 00:00:00: 2023-01-15 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 76 is playing as team2 in the first match after 2023-01-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 76: [161.4 135.87315634218288 11 4 0 70 19 7.042158516020237\n",
      " 19.129032258064516 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 76.\n",
      "Extracting data for team_id: 216 and match_dt: 2023-01-14 00:00:00\n",
      "Filtered 50 matches for team_id: 216\n",
      "Found 32 matches before and 18 matches after 2023-01-14 00:00:00\n",
      "First match after 2023-01-14 00:00:00: 2023-01-15 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 216 is playing as team1 in the first match after 2023-01-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 216: [142.0 125.94024000158528 9 4 0 49 19 7.959183673469387 31.705882352941178\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 216.\n",
      "Extracting data for team_id: 33935 and match_dt: 2022-01-06 00:00:00\n",
      "Filtered 45 matches for team_id: 33935\n",
      "Found 19 matches before and 26 matches after 2022-01-06 00:00:00\n",
      "First match after 2022-01-06 00:00:00: 2022-01-17 00:00:00 (team1_id: 33921, team2_id: 33935)\n",
      "Team 33935 is playing as team2 in the first match after 2022-01-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33935: [174.6 149.11904761904765 10 5 1 59 36 7.7907375643224706\n",
      " 17.147058823529413 39]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33935.\n",
      "Extracting data for team_id: 33963 and match_dt: 2022-01-06 00:00:00\n",
      "Filtered 36 matches for team_id: 33963\n",
      "Found 17 matches before and 19 matches after 2022-01-06 00:00:00\n",
      "First match after 2022-01-06 00:00:00: 2022-01-15 00:00:00 (team1_id: 33956, team2_id: 33963)\n",
      "Team 33963 is playing as team2 in the first match after 2022-01-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 33963: [175.2 152.8709677419355 9 5 0 69 41 8.350180505415162 14.205128205128204\n",
      " 33]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33963.\n",
      "Extracting data for team_id: 33942 and match_dt: 2023-12-23 00:00:00\n",
      "Filtered 35 matches for team_id: 33942\n",
      "Found 30 matches before and 5 matches after 2023-12-23 00:00:00\n",
      "First match after 2023-12-23 00:00:00: 2023-12-26 00:00:00 (team1_id: 33935, team2_id: 33942)\n",
      "Team 33942 is playing as team2 in the first match after 2023-12-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33942: [155.0 129.57062146892656 11 4 0 57 30 7.614991482112436 21.74074074074074\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33942.\n",
      "Extracting data for team_id: 33928 and match_dt: 2023-12-23 00:00:00\n",
      "Filtered 40 matches for team_id: 33928\n",
      "Found 33 matches before and 7 matches after 2023-12-23 00:00:00\n",
      "First match after 2023-12-23 00:00:00: 2023-12-28 00:00:00 (team1_id: 33928, team2_id: 33949)\n",
      "Team 33928 is playing as team1 in the first match after 2023-12-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33928: [166.8 141.6969696969697 9 7 0 72 34 8.774869109947645 30.157894736842103\n",
      " 22]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33928.\n",
      "Extracting data for team_id: 8182 and match_dt: 2022-06-10 00:00:00\n",
      "Filtered 34 matches for team_id: 8182\n",
      "Found 17 matches before and 17 matches after 2022-06-10 00:00:00\n",
      "First match after 2022-06-10 00:00:00: 2022-06-17 00:00:00 (team1_id: 8182, team2_id: 8917)\n",
      "Team 8182 is playing as team1 in the first match after 2022-06-10 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 8182: [171.4 142.83333333333334 9 3 0 68 26 7.742608695652175 14.743589743589745\n",
      " 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8182.\n",
      "Extracting data for team_id: 6838 and match_dt: 2022-06-10 00:00:00\n",
      "Filtered 32 matches for team_id: 6838\n",
      "Found 21 matches before and 11 matches after 2022-06-10 00:00:00\n",
      "First match after 2022-06-10 00:00:00: 2022-06-17 00:00:00 (team1_id: 10618, team2_id: 6838)\n",
      "Team 6838 is playing as team2 in the first match after 2022-06-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 6838: [176.2 147.65384615384613 9 1 0 71 26 8.75392670157068 15.916666666666666\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 6838.\n",
      "Extracting data for team_id: 46766 and match_dt: 2023-08-17 00:00:00\n",
      "Filtered 18 matches for team_id: 46766\n",
      "Found 14 matches before and 4 matches after 2023-08-17 00:00:00\n",
      "First match after 2023-08-17 00:00:00: 2023-08-23 00:00:00 (team1_id: 46766, team2_id: 46738)\n",
      "Team 46766 is playing as team1 in the first match after 2023-08-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 46766: [153.2 172.92051607068808 10 4 0 59 33 9.048498845265588\n",
      " 14.433333333333334 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 46766.\n",
      "Extracting data for team_id: 46731 and match_dt: 2023-08-17 00:00:00\n",
      "Filtered 21 matches for team_id: 46731\n",
      "Found 19 matches before and 2 matches after 2023-08-17 00:00:00\n",
      "First match after 2023-08-17 00:00:00: 2023-08-19 00:00:00 (team1_id: 46731, team2_id: 46780)\n",
      "Team 46731 is playing as team1 in the first match after 2023-08-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 46731: [150.0 146.02078471845613 8 5 0 57 28 8.37890625 17.655172413793103 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 46731.\n",
      "Extracting data for team_id: 48950 and match_dt: 2023-01-19 00:00:00\n",
      "Filtered 19 matches for team_id: 48950\n",
      "Found 3 matches before and 16 matches after 2023-01-19 00:00:00\n",
      "First match after 2023-01-19 00:00:00: 2023-01-22 00:00:00 (team1_id: 48929, team2_id: 48950)\n",
      "Team 48950 is playing as team2 in the first match after 2023-01-19 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48950: [146.66666666666666 142.1527777777778 5 2 0 34 15 8.486842105263158 16.0\n",
      " 22]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48950.\n",
      "Extracting data for team_id: 48943 and match_dt: 2023-01-19 00:00:00\n",
      "Filtered 19 matches for team_id: 48943\n",
      "Found 2 matches before and 17 matches after 2023-01-19 00:00:00\n",
      "First match after 2023-01-19 00:00:00: 2023-01-21 00:00:00 (team1_id: 48943, team2_id: 48922)\n",
      "Team 48943 is playing as team1 in the first match after 2023-01-19 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 48943: [167.0 139.16666666666669 4 2 0 25 14 8.35 17.142857142857142 14]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48943.\n",
      "Extracting data for team_id: 293 and match_dt: 2023-12-29 00:00:00\n",
      "Filtered 38 matches for team_id: 293\n",
      "Found 28 matches before and 10 matches after 2023-12-29 00:00:00\n",
      "First match after 2023-12-29 00:00:00: 2023-12-31 00:00:00 (team1_id: 202, team2_id: 293)\n",
      "Team 293 is playing as team2 in the first match after 2023-12-29 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 293: [126.0 109.6791215994756 4 3 0 44 26 6.567425569176883 16.314285714285713\n",
      " 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 293.\n",
      "Extracting data for team_id: 202 and match_dt: 2023-12-29 00:00:00\n",
      "Filtered 37 matches for team_id: 202\n",
      "Found 26 matches before and 11 matches after 2023-12-29 00:00:00\n",
      "First match after 2023-12-29 00:00:00: 2023-12-31 00:00:00 (team1_id: 202, team2_id: 293)\n",
      "Team 202 is playing as team1 in the first match after 2023-12-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 202: [144.2 127.45645645645644 7 0 0 46 21 7.72192513368984 22.44 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 202.\n",
      "Extracting data for team_id: 45947 and match_dt: 2022-10-22 00:00:00\n",
      "Filtered 10 matches for team_id: 45947\n",
      "Found 10 matches before and 0 matches after 2022-10-22 00:00:00\n",
      "No match after 2022-10-22 00:00:00. Using first match before 2022-10-22 00:00:00: 2022-10-18 00:00:00 (team1_id: 15413, team2_id: 45947)\n",
      "Team 45947 is playing as team2 in the first match before 2022-10-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 45947: [126.2 111.36786018755326 2 2 0 19 11 7.152542372881356 19.666666666666668\n",
      " 19]\n",
      "Adding extracted data to team1 columns in first file for team1_id 45947.\n",
      "Extracting data for team_id: 12389 and match_dt: 2022-10-22 00:00:00\n",
      "Filtered 11 matches for team_id: 12389\n",
      "Found 10 matches before and 1 matches after 2022-10-22 00:00:00\n",
      "First match after 2022-10-22 00:00:00: 2023-10-19 00:00:00 (team1_id: 12473, team2_id: 12389)\n",
      "Team 12389 is playing as team2 in the first match after 2022-10-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 12389: [139.8 119.30382775119617 3 0 0 7 11 7.366024518388791 17.303030303030305\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 12389.\n",
      "Extracting data for team_id: 69 and match_dt: 2022-08-27 00:00:00\n",
      "Filtered 49 matches for team_id: 69\n",
      "Found 31 matches before and 18 matches after 2022-08-27 00:00:00\n",
      "First match after 2022-08-27 00:00:00: 2022-09-09 00:00:00 (team1_id: 62, team2_id: 69)\n",
      "Team 69 is playing as team2 in the first match after 2022-08-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 69: [153.6 128.50564971751413 11 4 0 51 26 8.498181818181818 27.5 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 69.\n",
      "Extracting data for team_id: 293 and match_dt: 2022-08-27 00:00:00\n",
      "Filtered 38 matches for team_id: 293\n",
      "Found 15 matches before and 23 matches after 2022-08-27 00:00:00\n",
      "First match after 2022-08-27 00:00:00: 2022-08-30 00:00:00 (team1_id: 188, team2_id: 293)\n",
      "Team 293 is playing as team2 in the first match after 2022-08-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 293: [134.0 116.04609929078016 8 2 0 42 23 6.949806949806949 15.696969696969695\n",
      " 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 293.\n",
      "Extracting data for team_id: 40564 and match_dt: 2022-02-16 00:00:00\n",
      "Filtered 33 matches for team_id: 40564\n",
      "Found 14 matches before and 19 matches after 2022-02-16 00:00:00\n",
      "First match after 2022-02-16 00:00:00: 2022-02-18 00:00:00 (team1_id: 40564, team2_id: 40606)\n",
      "Team 40564 is playing as team1 in the first match after 2022-02-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 40564: [142.8 121.28816199376948 7 3 0 54 22 7.571177504393673 24.73913043478261\n",
      " 21]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40564.\n",
      "Extracting data for team_id: 44904 and match_dt: 2022-02-16 00:00:00\n",
      "Filtered 42 matches for team_id: 44904\n",
      "Found 15 matches before and 27 matches after 2022-02-16 00:00:00\n",
      "First match after 2022-02-16 00:00:00: 2022-02-18 00:00:00 (team1_id: 44904, team2_id: 40592)\n",
      "Team 44904 is playing as team1 in the first match after 2022-02-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 44904: [179.8 151.33333333333331 13 6 0 76 40 8.25 15.17948717948718 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 44904.\n",
      "Extracting data for team_id: 33956 and match_dt: 2023-12-22 00:00:00\n",
      "Filtered 44 matches for team_id: 33956\n",
      "Found 37 matches before and 7 matches after 2023-12-22 00:00:00\n",
      "First match after 2023-12-22 00:00:00: 2023-12-26 00:00:00 (team1_id: 33956, team2_id: 33949)\n",
      "Team 33956 is playing as team1 in the first match after 2023-12-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 33956: [155.0 133.24540617629313 8 6 0 64 16 8.034782608695652 27.38095238095238\n",
      " 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33956.\n",
      "Extracting data for team_id: 33914 and match_dt: 2023-12-22 00:00:00\n",
      "Filtered 42 matches for team_id: 33914\n",
      "Found 34 matches before and 8 matches after 2023-12-22 00:00:00\n",
      "First match after 2023-12-22 00:00:00: 2023-12-29 00:00:00 (team1_id: 33914, team2_id: 33942)\n",
      "Team 33914 is playing as team1 in the first match after 2023-12-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33914: [172.4 143.81792717086833 10 6 1 73 30 9.31777378815081 37.13333333333333\n",
      " 19]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33914.\n",
      "Extracting data for team_id: 30393 and match_dt: 2022-04-23 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 18 matches before and 19 matches after 2022-04-23 00:00:00\n",
      "First match after 2022-04-23 00:00:00: 2022-04-26 00:00:00 (team1_id: 30428, team2_id: 30393)\n",
      "Team 30393 is playing as team2 in the first match after 2022-04-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30393: [157.0 133.93146417445482 9 3 0 71 22 7.737649063032368 18.93548387096774\n",
      " 40]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 36014 and match_dt: 2022-04-23 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 18 matches before and 14 matches after 2022-04-23 00:00:00\n",
      "First match after 2022-04-23 00:00:00: 2022-05-05 00:00:00 (team1_id: 30421, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match after 2022-04-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [164.6 140.41860826343586 13 4 0 59 36 8.412265758091994\n",
      " 20.964285714285715 33]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 48 and match_dt: 2023-08-30 00:00:00\n",
      "Filtered 57 matches for team_id: 48\n",
      "Found 44 matches before and 13 matches after 2023-08-30 00:00:00\n",
      "First match after 2023-08-30 00:00:00: 2023-12-27 00:00:00 (team1_id: 48, team2_id: 188)\n",
      "Team 48 is playing as team1 in the first match after 2023-08-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 48: [166.6 143.09523809523813 10 5 0 72 26 8.530249110320284\n",
      " 18.733333333333334 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48.\n",
      "Extracting data for team_id: 20 and match_dt: 2023-08-30 00:00:00\n",
      "Filtered 48 matches for team_id: 20\n",
      "Found 43 matches before and 5 matches after 2023-08-30 00:00:00\n",
      "First match after 2023-08-30 00:00:00: 2023-09-03 00:00:00 (team1_id: 20, team2_id: 188)\n",
      "Team 20 is playing as team1 in the first match after 2023-08-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 20: [164.2 137.5689655172414 8 5 0 65 38 7.919561243144424 15.194444444444445\n",
      " 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 20.\n",
      "Extracting data for team_id: 17744 and match_dt: 2023-02-03 00:00:00\n",
      "Filtered 29 matches for team_id: 17744\n",
      "Found 23 matches before and 6 matches after 2023-02-03 00:00:00\n",
      "First match after 2023-02-03 00:00:00: 2023-12-22 00:00:00 (team1_id: 17982, team2_id: 17744)\n",
      "Team 17744 is playing as team2 in the first match after 2023-02-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 17744: [172.6 163.07471264367817 12 4 0 71 41 9.657992565055762\n",
      " 17.933333333333334 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 17744.\n",
      "Extracting data for team_id: 17982 and match_dt: 2023-02-03 00:00:00\n",
      "Filtered 32 matches for team_id: 17982\n",
      "Found 22 matches before and 10 matches after 2023-02-03 00:00:00\n",
      "First match after 2023-02-03 00:00:00: 2023-04-01 00:00:00 (team1_id: 18570, team2_id: 17982)\n",
      "Team 17982 is playing as team2 in the first match after 2023-02-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 17982: [152.4 140.3972693972694 7 4 0 62 40 8.239845261121857 16.677419354838708\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 17982.\n",
      "Extracting data for team_id: 36084 and match_dt: 2023-09-17 00:00:00\n",
      "Filtered 24 matches for team_id: 36084\n",
      "Found 22 matches before and 2 matches after 2023-09-17 00:00:00\n",
      "First match after 2023-09-17 00:00:00: 2023-09-22 00:00:00 (team1_id: 36084, team2_id: 36098)\n",
      "Team 36084 is playing as team1 in the first match after 2023-09-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 36084: [176.0 147.8025693035835 10 4 0 62 46 7.7558348294434465\n",
      " 18.566666666666663 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36084.\n",
      "Extracting data for team_id: 36070 and match_dt: 2023-09-17 00:00:00\n",
      "Filtered 25 matches for team_id: 36070\n",
      "Found 24 matches before and 1 matches after 2023-09-17 00:00:00\n",
      "First match after 2023-09-17 00:00:00: 2023-10-09 00:00:00 (team1_id: 36084, team2_id: 36070)\n",
      "Team 36070 is playing as team2 in the first match after 2023-09-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36070: [151.6 133.56702962182413 6 3 1 54 42 8.26909090909091 16.176470588235293\n",
      " 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36070.\n",
      "Extracting data for team_id: 41 and match_dt: 2022-02-16 00:00:00\n",
      "Filtered 49 matches for team_id: 41\n",
      "Found 28 matches before and 21 matches after 2022-02-16 00:00:00\n",
      "First match after 2022-02-16 00:00:00: 2022-03-07 00:00:00 (team1_id: 41, team2_id: 188)\n",
      "Team 41 is playing as team1 in the first match after 2022-02-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 41: [164.2 139.69417475728156 8 4 1 53 47 8.25385934819897 21.59259259259259\n",
      " 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 41.\n",
      "Extracting data for team_id: 55 and match_dt: 2022-02-16 00:00:00\n",
      "Filtered 60 matches for team_id: 55\n",
      "Found 20 matches before and 40 matches after 2022-02-16 00:00:00\n",
      "First match after 2022-02-16 00:00:00: 2022-02-24 00:00:00 (team1_id: 55, team2_id: 69)\n",
      "Team 55 is playing as team1 in the first match after 2022-02-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 55: [169.6 141.33333333333331 11 6 0 74 36 8.733212341197822 27.55 21]\n",
      "Adding extracted data to team2 columns in first file for team2_id 55.\n",
      "Extracting data for team_id: 188 and match_dt: 2023-03-31 00:00:00\n",
      "Filtered 54 matches for team_id: 188\n",
      "Found 39 matches before and 15 matches after 2023-03-31 00:00:00\n",
      "First match after 2023-03-31 00:00:00: 2023-07-10 00:00:00 (team1_id: 62, team2_id: 188)\n",
      "Team 188 is playing as team2 in the first match after 2023-03-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 188: [154.0 131.11165048543688 4 2 0 33 12 7.225680933852139 13.526315789473683\n",
      " 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 188.\n",
      "Extracting data for team_id: 216 and match_dt: 2023-03-31 00:00:00\n",
      "Filtered 50 matches for team_id: 216\n",
      "Found 34 matches before and 16 matches after 2023-03-31 00:00:00\n",
      "First match after 2023-03-31 00:00:00: 2023-07-12 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 216 is playing as team1 in the first match after 2023-03-31 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 216: [130.8 131.83422937303482 6 3 0 53 13 7.759842519685039 19.53846153846154\n",
      " 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 216.\n",
      "Extracting data for team_id: 8182 and match_dt: 2023-05-29 00:00:00\n",
      "Filtered 34 matches for team_id: 8182\n",
      "Found 29 matches before and 5 matches after 2023-05-29 00:00:00\n",
      "First match after 2023-05-29 00:00:00: 2023-06-16 00:00:00 (team1_id: 8182, team2_id: 8917)\n",
      "Team 8182 is playing as team1 in the first match after 2023-05-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 8182: [144.8 137.27713973202077 8 2 0 62 19 8.379310344827587 24.857142857142858\n",
      " 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8182.\n",
      "Extracting data for team_id: 10366 and match_dt: 2023-05-29 00:00:00\n",
      "Filtered 34 matches for team_id: 10366\n",
      "Found 28 matches before and 6 matches after 2023-05-29 00:00:00\n",
      "First match after 2023-05-29 00:00:00: 2023-05-31 00:00:00 (team1_id: 10366, team2_id: 8917)\n",
      "Team 10366 is playing as team1 in the first match after 2023-05-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 10366: [150.2 131.1721163647769 6 3 0 72 16 7.789090909090909 19.642857142857142\n",
      " 33]\n",
      "Adding extracted data to team2 columns in first file for team2_id 10366.\n",
      "Extracting data for team_id: 47501 and match_dt: 2022-12-12 00:00:00\n",
      "Filtered 24 matches for team_id: 47501\n",
      "Found 13 matches before and 11 matches after 2022-12-12 00:00:00\n",
      "First match after 2022-12-12 00:00:00: 2022-12-18 00:00:00 (team1_id: 47501, team2_id: 47494)\n",
      "Team 47501 is playing as team1 in the first match after 2022-12-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 47501: [163.8 139.67948717948718 9 5 1 65 29 7.705479452054794 12.977777777777778\n",
      " 40]\n",
      "Adding extracted data to team1 columns in first file for team1_id 47501.\n",
      "Extracting data for team_id: 47487 and match_dt: 2022-12-12 00:00:00\n",
      "Filtered 20 matches for team_id: 47487\n",
      "Found 11 matches before and 9 matches after 2022-12-12 00:00:00\n",
      "First match after 2022-12-12 00:00:00: 2022-12-13 00:00:00 (team1_id: 47494, team2_id: 47487)\n",
      "Team 47487 is playing as team2 in the first match after 2022-12-12 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 47487: [131.4 118.7462121212121 8 3 0 63 15 6.8833652007648185 12.75609756097561\n",
      " 26]\n",
      "Adding extracted data to team2 columns in first file for team2_id 47487.\n",
      "Extracting data for team_id: 76 and match_dt: 2023-12-09 00:00:00\n",
      "Filtered 43 matches for team_id: 76\n",
      "Found 35 matches before and 8 matches after 2023-12-09 00:00:00\n",
      "First match after 2023-12-09 00:00:00: 2024-01-14 00:00:00 (team1_id: 76, team2_id: 69)\n",
      "Team 76 is playing as team1 in the first match after 2023-12-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 76: [145.4 122.57142857142858 7 2 0 61 19 7.895306859205776 21.307692307692307\n",
      " 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 76.\n",
      "Extracting data for team_id: 216 and match_dt: 2023-12-09 00:00:00\n",
      "Filtered 50 matches for team_id: 216\n",
      "Found 41 matches before and 9 matches after 2023-12-09 00:00:00\n",
      "First match after 2023-12-09 00:00:00: 2024-03-15 00:00:00 (team1_id: 216, team2_id: 293)\n",
      "Team 216 is playing as team1 in the first match after 2023-12-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 216: [167.6 141.13218390804596 6 3 0 48 35 7.34819897084048 16.194444444444443\n",
      " 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 216.\n",
      "Extracting data for team_id: 8056 and match_dt: 2022-05-27 00:00:00\n",
      "Filtered 38 matches for team_id: 8056\n",
      "Found 20 matches before and 18 matches after 2022-05-27 00:00:00\n",
      "First match after 2022-05-27 00:00:00: 2022-05-29 00:00:00 (team1_id: 9967, team2_id: 8056)\n",
      "Team 8056 is playing as team2 in the first match after 2022-05-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 8056: [154.4 128.66666666666666 8 5 0 52 25 8.177935943060497 19.379310344827587\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8056.\n",
      "Extracting data for team_id: 7258 and match_dt: 2022-05-27 00:00:00\n",
      "Filtered 37 matches for team_id: 7258\n",
      "Found 14 matches before and 23 matches after 2022-05-27 00:00:00\n",
      "First match after 2022-05-27 00:00:00: 2022-05-29 00:00:00 (team1_id: 7258, team2_id: 9701)\n",
      "Team 7258 is playing as team1 in the first match after 2022-05-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 7258: [166.4 139.94025886216554 8 4 0 74 29 8.224489795918368 15.473684210526317\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7258.\n",
      "Extracting data for team_id: 36126 and match_dt: 2023-09-24 00:00:00\n",
      "Filtered 25 matches for team_id: 36126\n",
      "Found 24 matches before and 1 matches after 2023-09-24 00:00:00\n",
      "First match after 2023-09-24 00:00:00: 2023-10-09 00:00:00 (team1_id: 36112, team2_id: 36126)\n",
      "Team 36126 is playing as team2 in the first match after 2023-09-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36126: [170.0 152.9499845948444 11 5 2 51 53 8.05168986083499 14.794117647058824\n",
      " 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36126.\n",
      "Extracting data for team_id: 36084 and match_dt: 2023-09-24 00:00:00\n",
      "Filtered 24 matches for team_id: 36084\n",
      "Found 23 matches before and 1 matches after 2023-09-24 00:00:00\n",
      "First match after 2023-09-24 00:00:00: 2023-10-09 00:00:00 (team1_id: 36084, team2_id: 36070)\n",
      "Team 36084 is playing as team1 in the first match after 2023-09-24 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 36084: [175.2 147.13590263691682 11 5 0 69 40 7.924324324324324 19.13793103448276\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36084.\n",
      "Extracting data for team_id: 6698 and match_dt: 2022-06-03 00:00:00\n",
      "Filtered 30 matches for team_id: 6698\n",
      "Found 14 matches before and 16 matches after 2022-06-03 00:00:00\n",
      "First match after 2022-06-03 00:00:00: 2022-06-18 00:00:00 (team1_id: 10618, team2_id: 6698)\n",
      "Team 6698 is playing as team2 in the first match after 2022-06-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 6698: [165.2 159.68305620120387 14 4 1 70 22 8.849094567404427\n",
      " 16.566666666666666 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 6698.\n",
      "Extracting data for team_id: 8987 and match_dt: 2022-06-03 00:00:00\n",
      "Filtered 30 matches for team_id: 8987\n",
      "Found 15 matches before and 15 matches after 2022-06-03 00:00:00\n",
      "First match after 2022-06-03 00:00:00: 2022-06-06 00:00:00 (team1_id: 10618, team2_id: 8987)\n",
      "Team 8987 is playing as team2 in the first match after 2022-06-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 8987: [129.6 178.34923484327655 6 3 0 54 35 9.768844221105528 13.266666666666667\n",
      " 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8987.\n",
      "Extracting data for team_id: 7573 and match_dt: 2022-07-03 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 17 matches before and 10 matches after 2022-07-03 00:00:00\n",
      "First match after 2022-07-03 00:00:00: 2022-10-06 00:00:00 (team1_id: 7727, team2_id: 7573)\n",
      "Team 7573 is playing as team2 in the first match after 2022-07-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 7573: [145.0 147.82034430012186 9 3 0 61 30 9.605263157894736 26.823529411764707\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7573.\n",
      "Extracting data for team_id: 8056 and match_dt: 2022-07-03 00:00:00\n",
      "Filtered 38 matches for team_id: 8056\n",
      "Found 24 matches before and 14 matches after 2022-07-03 00:00:00\n",
      "First match after 2022-07-03 00:00:00: 2022-07-06 00:00:00 (team1_id: 8056, team2_id: 7258)\n",
      "Team 8056 is playing as team1 in the first match after 2022-07-03 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 8056: [159.2 133.11581920903956 9 2 0 64 23 8.128378378378379 24.666666666666668\n",
      " 21]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8056.\n",
      "Extracting data for team_id: 17583 and match_dt: 2023-01-05 00:00:00\n",
      "Filtered 30 matches for team_id: 17583\n",
      "Found 19 matches before and 11 matches after 2023-01-05 00:00:00\n",
      "First match after 2023-01-05 00:00:00: 2023-01-14 00:00:00 (team1_id: 17583, team2_id: 17744)\n",
      "Team 17583 is playing as team1 in the first match after 2023-01-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 17583: [146.2 121.83333333333334 6 4 0 56 27 7.882352941176471 18.7 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 17583.\n",
      "Extracting data for team_id: 17744 and match_dt: 2023-01-05 00:00:00\n",
      "Filtered 29 matches for team_id: 17744\n",
      "Found 20 matches before and 9 matches after 2023-01-05 00:00:00\n",
      "First match after 2023-01-05 00:00:00: 2023-01-14 00:00:00 (team1_id: 17583, team2_id: 17744)\n",
      "Team 17744 is playing as team2 in the first match after 2023-01-05 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 17744: [193.2 161.0 12 4 0 79 45 9.57 16.666666666666668 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 17744.\n",
      "Extracting data for team_id: 30414 and match_dt: 2022-05-20 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 24 matches before and 12 matches after 2022-05-20 00:00:00\n",
      "First match after 2022-05-20 00:00:00: 2022-09-04 00:00:00 (team1_id: 30414, team2_id: 36014)\n",
      "Team 30414 is playing as team1 in the first match after 2022-05-20 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [167.0 139.16666666666669 11 4 0 69 36 8.414023372287145\n",
      " 21.392857142857142 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 30428 and match_dt: 2022-05-20 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 21 matches before and 12 matches after 2022-05-20 00:00:00\n",
      "First match after 2022-05-20 00:00:00: 2022-05-24 00:00:00 (team1_id: 30428, team2_id: 48341)\n",
      "Team 30428 is playing as team1 in the first match after 2022-05-20 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30428: [179.2 149.33333333333331 8 6 2 73 46 8.48 14.285714285714286 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 47508 and match_dt: 2022-12-07 00:00:00\n",
      "Filtered 21 matches for team_id: 47508\n",
      "Found 9 matches before and 12 matches after 2022-12-07 00:00:00\n",
      "First match after 2022-12-07 00:00:00: 2022-12-13 00:00:00 (team1_id: 47480, team2_id: 47508)\n",
      "Team 47508 is playing as team2 in the first match after 2022-12-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 47508: [131.4 123.00678149297444 8 3 0 56 18 8.0 19.92 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 47508.\n",
      "Extracting data for team_id: 47501 and match_dt: 2022-12-07 00:00:00\n",
      "Filtered 24 matches for team_id: 47501\n",
      "Found 13 matches before and 11 matches after 2022-12-07 00:00:00\n",
      "First match after 2022-12-07 00:00:00: 2022-12-18 00:00:00 (team1_id: 47501, team2_id: 47494)\n",
      "Team 47501 is playing as team1 in the first match after 2022-12-07 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 47501: [163.8 139.67948717948718 9 5 1 65 29 7.705479452054794 12.977777777777778\n",
      " 40]\n",
      "Adding extracted data to team2 columns in first file for team2_id 47501.\n",
      "Extracting data for team_id: 33963 and match_dt: 2022-01-02 00:00:00\n",
      "Filtered 36 matches for team_id: 33963\n",
      "Found 17 matches before and 19 matches after 2022-01-02 00:00:00\n",
      "First match after 2022-01-02 00:00:00: 2022-01-15 00:00:00 (team1_id: 33956, team2_id: 33963)\n",
      "Team 33963 is playing as team2 in the first match after 2022-01-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33963: [175.2 152.8709677419355 9 5 0 69 41 8.350180505415162 14.205128205128204\n",
      " 33]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33963.\n",
      "Extracting data for team_id: 33914 and match_dt: 2022-01-02 00:00:00\n",
      "Filtered 42 matches for team_id: 33914\n",
      "Found 16 matches before and 26 matches after 2022-01-02 00:00:00\n",
      "First match after 2022-01-02 00:00:00: 2022-01-17 00:00:00 (team1_id: 33956, team2_id: 33914)\n",
      "Team 33914 is playing as team2 in the first match after 2022-01-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 33914: [160.4 135.40476190476193 9 4 0 60 18 8.238500851788757 17.264705882352942\n",
      " 20]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33914.\n",
      "Extracting data for team_id: 22763 and match_dt: 2022-02-14 00:00:00\n",
      "Filtered 16 matches for team_id: 22763\n",
      "Found 7 matches before and 9 matches after 2022-02-14 00:00:00\n",
      "First match after 2022-02-14 00:00:00: 2022-02-18 00:00:00 (team1_id: 23316, team2_id: 22763)\n",
      "Team 22763 is playing as team2 in the first match after 2022-02-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 22763: [136.6 115.9862385321101 7 3 0 43 18 6.339622641509434 18.21875 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 22763.\n",
      "Extracting data for team_id: 23750 and match_dt: 2022-02-14 00:00:00\n",
      "Filtered 17 matches for team_id: 23750\n",
      "Found 6 matches before and 11 matches after 2022-02-14 00:00:00\n",
      "First match after 2022-02-14 00:00:00: 2022-02-19 00:00:00 (team1_id: 23869, team2_id: 23750)\n",
      "Team 23750 is playing as team2 in the first match after 2022-02-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 23750: [135.2 117.57894736842104 6 0 0 46 11 6.490434782608695 14.024390243902438\n",
      " 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 23750.\n",
      "Extracting data for team_id: 47494 and match_dt: 2022-12-21 00:00:00\n",
      "Filtered 16 matches for team_id: 47494\n",
      "Found 16 matches before and 0 matches after 2022-12-21 00:00:00\n",
      "No match after 2022-12-21 00:00:00. Using first match before 2022-12-21 00:00:00: 2022-12-18 00:00:00 (team1_id: 47501, team2_id: 47494)\n",
      "Team 47494 is playing as team2 in the first match before 2022-12-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 47494: [154.2 128.5 11 4 0 74 23 7.68166089965398 15.62162162162162 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 47494.\n",
      "Extracting data for team_id: 47487 and match_dt: 2022-12-21 00:00:00\n",
      "Filtered 20 matches for team_id: 47487\n",
      "Found 15 matches before and 5 matches after 2022-12-21 00:00:00\n",
      "First match after 2022-12-21 00:00:00: 2023-05-08 00:00:00 (team1_id: 47508, team2_id: 47487)\n",
      "Team 47487 is playing as team2 in the first match after 2022-12-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 47487: [134.0 122.68038740920096 10 3 0 55 22 7.988165680473372 26.68421052631579\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 47487.\n",
      "Extracting data for team_id: 33935 and match_dt: 2022-01-14 00:00:00\n",
      "Filtered 45 matches for team_id: 33935\n",
      "Found 19 matches before and 26 matches after 2022-01-14 00:00:00\n",
      "First match after 2022-01-14 00:00:00: 2022-01-17 00:00:00 (team1_id: 33921, team2_id: 33935)\n",
      "Team 33935 is playing as team2 in the first match after 2022-01-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33935: [174.6 149.11904761904765 10 5 1 59 36 7.7907375643224706\n",
      " 17.147058823529413 39]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33935.\n",
      "Extracting data for team_id: 33914 and match_dt: 2022-01-14 00:00:00\n",
      "Filtered 42 matches for team_id: 33914\n",
      "Found 16 matches before and 26 matches after 2022-01-14 00:00:00\n",
      "First match after 2022-01-14 00:00:00: 2022-01-17 00:00:00 (team1_id: 33956, team2_id: 33914)\n",
      "Team 33914 is playing as team2 in the first match after 2022-01-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 33914: [160.4 135.40476190476193 9 4 0 60 18 8.238500851788757 17.264705882352942\n",
      " 20]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33914.\n",
      "Extracting data for team_id: 9876 and match_dt: 2023-06-22 00:00:00\n",
      "Filtered 35 matches for team_id: 9876\n",
      "Found 31 matches before and 4 matches after 2023-06-22 00:00:00\n",
      "First match after 2023-06-22 00:00:00: 2023-07-06 00:00:00 (team1_id: 9876, team2_id: 7573)\n",
      "Team 9876 is playing as team1 in the first match after 2023-06-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 9876: [185.6 154.66666666666669 8 4 1 64 48 8.224956063268893 18.966666666666665\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 9876.\n",
      "Extracting data for team_id: 8700 and match_dt: 2023-06-22 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 25 matches before and 2 matches after 2023-06-22 00:00:00\n",
      "First match after 2023-06-22 00:00:00: 2023-06-23 00:00:00 (team1_id: 8056, team2_id: 8700)\n",
      "Team 8700 is playing as team2 in the first match after 2023-06-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 8700: [145.6 136.74582511359034 10 2 0 68 25 9.0 22.272727272727273 25]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8700.\n",
      "Extracting data for team_id: 48341 and match_dt: 2022-05-03 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 4 matches before and 20 matches after 2022-05-03 00:00:00\n",
      "First match after 2022-05-03 00:00:00: 2022-05-15 00:00:00 (team1_id: 30414, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match after 2022-05-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [173.25 144.375 9 3 0 64 21 7.925 16.0 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30407 and match_dt: 2022-05-03 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 19 matches before and 13 matches after 2022-05-03 00:00:00\n",
      "First match after 2022-05-03 00:00:00: 2022-05-13 00:00:00 (team1_id: 30407, team2_id: 30393)\n",
      "Team 30407 is playing as team1 in the first match after 2022-05-03 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [154.0 128.72033898305085 7 3 0 64 33 8.416502946954813 21.208333333333332\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 14454 and match_dt: 2022-10-11 00:00:00\n",
      "Filtered 20 matches for team_id: 14454\n",
      "Found 12 matches before and 8 matches after 2022-10-11 00:00:00\n",
      "First match after 2022-10-11 00:00:00: 2022-10-18 00:00:00 (team1_id: 13971, team2_id: 14454)\n",
      "Team 14454 is playing as team2 in the first match after 2022-10-11 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 14454: [158.8 140.03030303030303 8 2 1 60 25 8.430379746835442 25.136363636363637\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 14454.\n",
      "Extracting data for team_id: 12718 and match_dt: 2022-10-11 00:00:00\n",
      "Filtered 11 matches for team_id: 12718\n",
      "Found 9 matches before and 2 matches after 2022-10-11 00:00:00\n",
      "First match after 2022-10-11 00:00:00: 2023-10-19 00:00:00 (team1_id: 32388, team2_id: 12718)\n",
      "Team 12718 is playing as team2 in the first match after 2022-10-11 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 12718: [143.0 120.86506746626688 1 1 0 6 1 7.062611806797853 18.633333333333333\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 12718.\n",
      "Extracting data for team_id: 7608 and match_dt: 2022-06-21 00:00:00\n",
      "Filtered 28 matches for team_id: 7608\n",
      "Found 17 matches before and 11 matches after 2022-06-21 00:00:00\n",
      "First match after 2022-06-21 00:00:00: 2022-09-06 00:00:00 (team1_id: 7608, team2_id: 9701)\n",
      "Team 7608 is playing as team1 in the first match after 2022-06-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 7608: [140.6 127.93583678296866 6 1 0 32 23 7.301470588235293 13.6 41]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7608.\n",
      "Extracting data for team_id: 8056 and match_dt: 2022-06-21 00:00:00\n",
      "Filtered 38 matches for team_id: 8056\n",
      "Found 23 matches before and 15 matches after 2022-06-21 00:00:00\n",
      "First match after 2022-06-21 00:00:00: 2022-06-24 00:00:00 (team1_id: 9967, team2_id: 8056)\n",
      "Team 8056 is playing as team2 in the first match after 2022-06-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 8056: [152.8 127.33333333333331 8 1 0 56 22 7.777777777777778 20.482758620689655\n",
      " 19]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8056.\n",
      "Extracting data for team_id: 188 and match_dt: 2022-09-27 00:00:00\n",
      "Filtered 54 matches for team_id: 188\n",
      "Found 34 matches before and 20 matches after 2022-09-27 00:00:00\n",
      "First match after 2022-09-27 00:00:00: 2022-10-24 00:00:00 (team1_id: 188, team2_id: 118)\n",
      "Team 188 is playing as team1 in the first match after 2022-09-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 188: [139.0 115.83333333333331 3 1 0 31 11 7.356521739130435 23.958333333333332\n",
      " 20]\n",
      "Adding extracted data to team1 columns in first file for team1_id 188.\n",
      "Extracting data for team_id: 202 and match_dt: 2022-09-27 00:00:00\n",
      "Filtered 37 matches for team_id: 202\n",
      "Found 9 matches before and 28 matches after 2022-09-27 00:00:00\n",
      "First match after 2022-09-27 00:00:00: 2022-10-16 00:00:00 (team1_id: 202, team2_id: 118)\n",
      "Team 202 is playing as team1 in the first match after 2022-09-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 202: [163.0 137.40800786047652 7 1 0 34 14 7.290877796901893 17.08823529411765\n",
      " 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 202.\n",
      "Extracting data for team_id: 36126 and match_dt: 2023-09-16 00:00:00\n",
      "Filtered 25 matches for team_id: 36126\n",
      "Found 24 matches before and 1 matches after 2023-09-16 00:00:00\n",
      "First match after 2023-09-16 00:00:00: 2023-10-09 00:00:00 (team1_id: 36112, team2_id: 36126)\n",
      "Team 36126 is playing as team2 in the first match after 2023-09-16 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36126: [170.0 152.9499845948444 11 5 2 51 53 8.05168986083499 14.794117647058824\n",
      " 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36126.\n",
      "Extracting data for team_id: 36084 and match_dt: 2023-09-16 00:00:00\n",
      "Filtered 24 matches for team_id: 36084\n",
      "Found 22 matches before and 2 matches after 2023-09-16 00:00:00\n",
      "First match after 2023-09-16 00:00:00: 2023-09-22 00:00:00 (team1_id: 36084, team2_id: 36098)\n",
      "Team 36084 is playing as team1 in the first match after 2023-09-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 36084: [176.0 147.8025693035835 10 4 0 62 46 7.7558348294434465\n",
      " 18.566666666666663 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36084.\n",
      "Extracting data for team_id: 55 and match_dt: 2022-08-06 00:00:00\n",
      "Filtered 60 matches for team_id: 55\n",
      "Found 31 matches before and 29 matches after 2022-08-06 00:00:00\n",
      "First match after 2022-08-06 00:00:00: 2022-08-09 00:00:00 (team1_id: 55, team2_id: 293)\n",
      "Team 55 is playing as team1 in the first match after 2022-08-06 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 55: [174.8 161.85416666666666 10 6 1 88 36 7.694656488549618\n",
      " 14.555555555555555 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 55.\n",
      "Extracting data for team_id: 41 and match_dt: 2022-08-06 00:00:00\n",
      "Filtered 49 matches for team_id: 41\n",
      "Found 32 matches before and 17 matches after 2022-08-06 00:00:00\n",
      "First match after 2022-08-06 00:00:00: 2022-10-21 00:00:00 (team1_id: 41, team2_id: 216)\n",
      "Team 41 is playing as team1 in the first match after 2022-08-06 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 41: [154.2 128.5 5 3 0 57 35 7.38 18.181818181818183 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 41.\n",
      "Extracting data for team_id: 46773 and match_dt: 2022-09-02 00:00:00\n",
      "Filtered 18 matches for team_id: 46773\n",
      "Found 11 matches before and 7 matches after 2022-09-02 00:00:00\n",
      "First match after 2022-09-02 00:00:00: 2022-12-08 00:00:00 (team1_id: 46773, team2_id: 46738)\n",
      "Team 46773 is playing as team1 in the first match after 2022-09-02 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 46773: [138.6 141.55436842866993 8 1 0 49 31 8.484581497797357 15.133333333333333\n",
      " 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 46773.\n",
      "Extracting data for team_id: 46766 and match_dt: 2022-09-02 00:00:00\n",
      "Filtered 18 matches for team_id: 46766\n",
      "Found 12 matches before and 6 matches after 2022-09-02 00:00:00\n",
      "First match after 2022-09-02 00:00:00: 2023-02-08 00:00:00 (team1_id: 46752, team2_id: 46766)\n",
      "Team 46766 is playing as team2 in the first match after 2022-09-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 46766: [158.0 152.11990950226246 9 5 0 50 36 8.883910386965377 16.366666666666667\n",
      " 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 46766.\n",
      "Extracting data for team_id: 17653 and match_dt: 2023-12-30 00:00:00\n",
      "Filtered 38 matches for team_id: 17653\n",
      "Found 31 matches before and 7 matches after 2023-12-30 00:00:00\n",
      "First match after 2023-12-30 00:00:00: 2024-01-18 00:00:00 (team1_id: 17653, team2_id: 17982)\n",
      "Team 17653 is playing as team1 in the first match after 2023-12-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 17653: [135.8 139.21319654837967 8 3 0 66 19 7.871101871101871 17.178571428571427\n",
      " 38]\n",
      "Adding extracted data to team1 columns in first file for team1_id 17653.\n",
      "Extracting data for team_id: 17744 and match_dt: 2023-12-30 00:00:00\n",
      "Filtered 29 matches for team_id: 17744\n",
      "Found 25 matches before and 4 matches after 2023-12-30 00:00:00\n",
      "First match after 2023-12-30 00:00:00: 2024-01-13 00:00:00 (team1_id: 18570, team2_id: 17744)\n",
      "Team 17744 is playing as team2 in the first match after 2023-12-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 17744: [160.8 153.24137931034485 9 4 0 69 30 8.406716417910449 14.486486486486486\n",
      " 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 17744.\n",
      "Extracting data for team_id: 76 and match_dt: 2023-11-26 00:00:00\n",
      "Filtered 43 matches for team_id: 76\n",
      "Found 34 matches before and 9 matches after 2023-11-26 00:00:00\n",
      "First match after 2023-11-26 00:00:00: 2023-12-01 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 76 is playing as team2 in the first match after 2023-11-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 76: [150.6 125.90677966101696 7 3 0 64 20 8.089285714285715 20.74074074074074\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 76.\n",
      "Extracting data for team_id: 251 and match_dt: 2023-11-26 00:00:00\n",
      "Filtered 20 matches for team_id: 251\n",
      "Found 17 matches before and 3 matches after 2023-11-26 00:00:00\n",
      "First match after 2023-11-26 00:00:00: 2023-11-27 00:00:00 (team1_id: 1224, team2_id: 251)\n",
      "Team 251 is playing as team2 in the first match after 2023-11-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 251: [104.6 113.57001399677796 5 0 0 32 17 6.805194805194805 18.48 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 251.\n",
      "Extracting data for team_id: 10366 and match_dt: 2023-06-09 00:00:00\n",
      "Filtered 34 matches for team_id: 10366\n",
      "Found 30 matches before and 4 matches after 2023-06-09 00:00:00\n",
      "First match after 2023-06-09 00:00:00: 2023-06-16 00:00:00 (team1_id: 10366, team2_id: 10576)\n",
      "Team 10366 is playing as team1 in the first match after 2023-06-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 10366: [175.4 148.9755351681957 10 5 0 84 24 8.33276740237691 15.102564102564102\n",
      " 41]\n",
      "Adding extracted data to team1 columns in first file for team1_id 10366.\n",
      "Extracting data for team_id: 8917 and match_dt: 2023-06-09 00:00:00\n",
      "Filtered 33 matches for team_id: 8917\n",
      "Found 28 matches before and 5 matches after 2023-06-09 00:00:00\n",
      "First match after 2023-06-09 00:00:00: 2023-06-16 00:00:00 (team1_id: 8182, team2_id: 8917)\n",
      "Team 8917 is playing as team2 in the first match after 2023-06-09 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 8917: [166.2 140.56162464985994 11 3 0 99 20 9.059674502712475\n",
      " 24.043478260869566 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8917.\n",
      "Extracting data for team_id: 7258 and match_dt: 2022-07-02 00:00:00\n",
      "Filtered 37 matches for team_id: 7258\n",
      "Found 19 matches before and 18 matches after 2022-07-02 00:00:00\n",
      "First match after 2022-07-02 00:00:00: 2022-07-06 00:00:00 (team1_id: 8056, team2_id: 7258)\n",
      "Team 7258 is playing as team2 in the first match after 2022-07-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 7258: [178.8 161.12156448202958 13 5 0 87 34 9.274766355140189\n",
      " 18.448275862068964 33]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7258.\n",
      "Extracting data for team_id: 7573 and match_dt: 2022-07-02 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 17 matches before and 10 matches after 2022-07-02 00:00:00\n",
      "First match after 2022-07-02 00:00:00: 2022-10-06 00:00:00 (team1_id: 7727, team2_id: 7573)\n",
      "Team 7573 is playing as team2 in the first match after 2022-07-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 7573: [145.0 147.82034430012186 9 3 0 61 30 9.605263157894736 26.823529411764707\n",
      " 26]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7573.\n",
      "Extracting data for team_id: 7727 and match_dt: 2022-06-04 00:00:00\n",
      "Filtered 35 matches for team_id: 7727\n",
      "Found 17 matches before and 18 matches after 2022-06-04 00:00:00\n",
      "First match after 2022-06-04 00:00:00: 2022-06-17 00:00:00 (team1_id: 7727, team2_id: 8056)\n",
      "Team 7727 is playing as team1 in the first match after 2022-06-04 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 7727: [149.6 124.66666666666669 8 1 0 67 22 8.455066921606118 21.791666666666668\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7727.\n",
      "Extracting data for team_id: 9967 and match_dt: 2022-06-04 00:00:00\n",
      "Filtered 34 matches for team_id: 9967\n",
      "Found 18 matches before and 16 matches after 2022-06-04 00:00:00\n",
      "First match after 2022-06-04 00:00:00: 2022-06-17 00:00:00 (team1_id: 7258, team2_id: 9967)\n",
      "Team 9967 is playing as team2 in the first match after 2022-06-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 9967: [160.0 137.65686274509804 9 4 0 62 29 8.290155440414507 20.678571428571427\n",
      " 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 9967.\n",
      "Extracting data for team_id: 6838 and match_dt: 2023-05-28 00:00:00\n",
      "Filtered 32 matches for team_id: 6838\n",
      "Found 29 matches before and 3 matches after 2023-05-28 00:00:00\n",
      "First match after 2023-05-28 00:00:00: 2023-06-20 00:00:00 (team1_id: 6838, team2_id: 10366)\n",
      "Team 6838 is playing as team1 in the first match after 2023-05-28 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 6838: [147.2 135.62447813667328 8 3 1 57 19 8.169741697416974 27.1 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 6838.\n",
      "Extracting data for team_id: 10618 and match_dt: 2023-05-28 00:00:00\n",
      "Filtered 35 matches for team_id: 10618\n",
      "Found 29 matches before and 6 matches after 2023-05-28 00:00:00\n",
      "First match after 2023-05-28 00:00:00: 2023-05-30 00:00:00 (team1_id: 10618, team2_id: 8987)\n",
      "Team 10618 is playing as team1 in the first match after 2023-05-28 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 10618: [168.2 147.97619047619048 14 5 0 76 34 8.908765652951699 22.36 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 10618.\n",
      "Extracting data for team_id: 9876 and match_dt: 2022-06-09 00:00:00\n",
      "Filtered 35 matches for team_id: 9876\n",
      "Found 16 matches before and 19 matches after 2022-06-09 00:00:00\n",
      "First match after 2022-06-09 00:00:00: 2022-06-17 00:00:00 (team1_id: 8700, team2_id: 9876)\n",
      "Team 9876 is playing as team2 in the first match after 2022-06-09 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 9876: [162.6 144.6992132817041 9 4 0 60 39 7.928952042628774 13.731707317073171\n",
      " 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 9876.\n",
      "Extracting data for team_id: 8700 and match_dt: 2022-06-09 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 15 matches before and 12 matches after 2022-06-09 00:00:00\n",
      "First match after 2022-06-09 00:00:00: 2022-06-17 00:00:00 (team1_id: 8700, team2_id: 9876)\n",
      "Team 8700 is playing as team1 in the first match after 2022-06-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 8700: [165.4 138.82183908045977 11 4 0 75 26 8.418685121107266\n",
      " 16.055555555555557 38]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8700.\n",
      "Extracting data for team_id: 33942 and match_dt: 2022-12-30 00:00:00\n",
      "Filtered 35 matches for team_id: 33942\n",
      "Found 24 matches before and 11 matches after 2022-12-30 00:00:00\n",
      "First match after 2022-12-30 00:00:00: 2023-01-14 00:00:00 (team1_id: 33942, team2_id: 33949)\n",
      "Team 33942 is playing as team1 in the first match after 2022-12-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 33942: [138.0 124.63171355498724 8 3 0 53 26 7.234657039711191 14.972972972972974\n",
      " 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33942.\n",
      "Extracting data for team_id: 33956 and match_dt: 2022-12-30 00:00:00\n",
      "Filtered 44 matches for team_id: 33956\n",
      "Found 29 matches before and 15 matches after 2022-12-30 00:00:00\n",
      "First match after 2022-12-30 00:00:00: 2023-01-15 00:00:00 (team1_id: 33956, team2_id: 33935)\n",
      "Team 33956 is playing as team1 in the first match after 2022-12-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33956: [140.8 125.28651685393258 10 1 0 53 20 6.800731261425961\n",
      " 13.023809523809524 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33956.\n",
      "Extracting data for team_id: 10618 and match_dt: 2023-05-26 00:00:00\n",
      "Filtered 35 matches for team_id: 10618\n",
      "Found 29 matches before and 6 matches after 2023-05-26 00:00:00\n",
      "First match after 2023-05-26 00:00:00: 2023-05-30 00:00:00 (team1_id: 10618, team2_id: 8987)\n",
      "Team 10618 is playing as team1 in the first match after 2023-05-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 10618: [168.2 147.97619047619048 14 5 0 76 34 8.908765652951699 22.36 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 10618.\n",
      "Extracting data for team_id: 10576 and match_dt: 2023-05-26 00:00:00\n",
      "Filtered 31 matches for team_id: 10576\n",
      "Found 22 matches before and 9 matches after 2023-05-26 00:00:00\n",
      "First match after 2023-05-26 00:00:00: 2023-05-29 00:00:00 (team1_id: 10576, team2_id: 8301)\n",
      "Team 10576 is playing as team1 in the first match after 2023-05-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 10576: [175.2 150.60891089108912 12 4 0 82 31 8.40625 14.048780487804878 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 10576.\n",
      "Extracting data for team_id: 12669 and match_dt: 2023-10-17 00:00:00\n",
      "Filtered 11 matches for team_id: 12669\n",
      "Found 10 matches before and 1 matches after 2023-10-17 00:00:00\n",
      "First match after 2023-10-17 00:00:00: 2023-10-23 00:00:00 (team1_id: 12669, team2_id: 45933)\n",
      "Team 12669 is playing as team1 in the first match after 2023-10-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 12669: [134.0 121.69003005529058 3 0 0 33 9 7.455555555555556 23.47826086956522\n",
      " 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 12669.\n",
      "Extracting data for team_id: 32388 and match_dt: 2023-10-17 00:00:00\n",
      "Filtered 11 matches for team_id: 32388\n",
      "Found 10 matches before and 1 matches after 2023-10-17 00:00:00\n",
      "First match after 2023-10-17 00:00:00: 2023-10-19 00:00:00 (team1_id: 32388, team2_id: 12718)\n",
      "Team 32388 is playing as team1 in the first match after 2023-10-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 32388: [155.4 129.5 4 2 0 26 10 7.51006711409396 19.866666666666667 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 32388.\n",
      "Extracting data for team_id: 17653 and match_dt: 2023-02-04 00:00:00\n",
      "Filtered 38 matches for team_id: 17653\n",
      "Found 28 matches before and 10 matches after 2023-02-04 00:00:00\n",
      "First match after 2023-02-04 00:00:00: 2023-06-02 00:00:00 (team1_id: 18360, team2_id: 17653)\n",
      "Team 17653 is playing as team2 in the first match after 2023-02-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 17653: [154.2 128.5 9 3 0 64 17 8.018382352941178 18.75862068965517 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 17653.\n",
      "Extracting data for team_id: 18360 and match_dt: 2023-02-04 00:00:00\n",
      "Filtered 29 matches for team_id: 18360\n",
      "Found 21 matches before and 8 matches after 2023-02-04 00:00:00\n",
      "First match after 2023-02-04 00:00:00: 2023-06-02 00:00:00 (team1_id: 18360, team2_id: 17653)\n",
      "Team 18360 is playing as team1 in the first match after 2023-02-04 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 18360: [157.6 131.33333333333334 8 3 0 59 28 7.880910683012258 16.314285714285713\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 18360.\n",
      "Extracting data for team_id: 188 and match_dt: 2023-10-06 00:00:00\n",
      "Filtered 54 matches for team_id: 188\n",
      "Found 42 matches before and 12 matches after 2023-10-06 00:00:00\n",
      "First match after 2023-10-06 00:00:00: 2023-12-27 00:00:00 (team1_id: 48, team2_id: 188)\n",
      "Team 188 is playing as team2 in the first match after 2023-10-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 188: [141.4 152.32489453185096 3 1 0 36 11 8.149038461538462 18.08695652173913\n",
      " 25]\n",
      "Adding extracted data to team1 columns in first file for team1_id 188.\n",
      "Extracting data for team_id: 55 and match_dt: 2023-10-06 00:00:00\n",
      "Filtered 60 matches for team_id: 55\n",
      "Found 53 matches before and 7 matches after 2023-10-06 00:00:00\n",
      "First match after 2023-10-06 00:00:00: 2023-11-23 00:00:00 (team1_id: 27, team2_id: 55)\n",
      "Team 55 is playing as team2 in the first match after 2023-10-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 55: [178.8 151.4848484848485 8 4 1 60 39 8.243386243386244 18.29032258064516\n",
      " 33]\n",
      "Adding extracted data to team2 columns in first file for team2_id 55.\n",
      "Extracting data for team_id: 22497 and match_dt: 2022-02-20 00:00:00\n",
      "Filtered 13 matches for team_id: 22497\n",
      "Found 3 matches before and 10 matches after 2022-02-20 00:00:00\n",
      "First match after 2022-02-20 00:00:00: 2022-02-22 00:00:00 (team1_id: 22784, team2_id: 22497)\n",
      "Team 22497 is playing as team2 in the first match after 2022-02-20 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 22497: [148.66666666666666 123.88888888888889 6 1 0 40 11 6.951008645533141 13.88\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 22497.\n",
      "Extracting data for team_id: 22763 and match_dt: 2022-02-20 00:00:00\n",
      "Filtered 16 matches for team_id: 22763\n",
      "Found 8 matches before and 8 matches after 2022-02-20 00:00:00\n",
      "First match after 2022-02-20 00:00:00: 2022-02-25 00:00:00 (team1_id: 22763, team2_id: 23750)\n",
      "Team 22763 is playing as team1 in the first match after 2022-02-20 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 22763: [138.2 115.94827586206895 7 1 0 45 15 6.345762711864406 17.87878787878788\n",
      " 38]\n",
      "Adding extracted data to team2 columns in first file for team2_id 22763.\n",
      "Extracting data for team_id: 8700 and match_dt: 2023-07-02 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 27 matches before and 0 matches after 2023-07-02 00:00:00\n",
      "No match after 2023-07-02 00:00:00. Using first match before 2023-07-02 00:00:00: 2023-06-30 00:00:00 (team1_id: 7258, team2_id: 8700)\n",
      "Team 8700 is playing as team2 in the first match before 2023-07-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 8700: [153.0 141.9269845338802 11 2 0 69 28 8.688090737240076 17.633333333333333\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8700.\n",
      "Extracting data for team_id: 7573 and match_dt: 2023-07-02 00:00:00\n",
      "Filtered 27 matches for team_id: 7573\n",
      "Found 25 matches before and 2 matches after 2023-07-02 00:00:00\n",
      "First match after 2023-07-02 00:00:00: 2023-07-06 00:00:00 (team1_id: 9876, team2_id: 7573)\n",
      "Team 7573 is playing as team2 in the first match after 2023-07-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 7573: [167.8 140.29096045197738 11 2 0 58 38 8.427083333333332\n",
      " 15.157894736842104 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7573.\n",
      "Extracting data for team_id: 33914 and match_dt: 2023-12-31 00:00:00\n",
      "Filtered 42 matches for team_id: 33914\n",
      "Found 35 matches before and 7 matches after 2023-12-31 00:00:00\n",
      "First match after 2023-12-31 00:00:00: 2024-01-14 00:00:00 (team1_id: 33963, team2_id: 33914)\n",
      "Team 33914 is playing as team2 in the first match after 2023-12-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33914: [179.4 149.65126050420167 11 7 1 73 34 9.747292418772563 34.625 20]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33914.\n",
      "Extracting data for team_id: 33949 and match_dt: 2023-12-31 00:00:00\n",
      "Filtered 38 matches for team_id: 33949\n",
      "Found 34 matches before and 4 matches after 2023-12-31 00:00:00\n",
      "First match after 2023-12-31 00:00:00: 2024-01-13 00:00:00 (team1_id: 33949, team2_id: 33942)\n",
      "Team 33949 is playing as team1 in the first match after 2023-12-31 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33949: [108.6 124.21455825396876 6 1 0 46 16 7.68 18.47826086956522 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33949.\n",
      "Extracting data for team_id: 30407 and match_dt: 2022-04-08 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 16 matches before and 16 matches after 2022-04-08 00:00:00\n",
      "First match after 2022-04-08 00:00:00: 2022-04-17 00:00:00 (team1_id: 30407, team2_id: 36014)\n",
      "Team 30407 is playing as team1 in the first match after 2022-04-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30407: [159.6 133.38700564971754 7 3 0 60 35 7.939285714285714 17.5 32]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30407.\n",
      "Extracting data for team_id: 48341 and match_dt: 2022-04-08 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 1 matches before and 23 matches after 2022-04-08 00:00:00\n",
      "First match after 2022-04-08 00:00:00: 2022-04-14 00:00:00 (team1_id: 48341, team2_id: 30428)\n",
      "Team 48341 is playing as team1 in the first match after 2022-04-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 48341: [171.0 142.5 2 1 0 14 5 7.85 13.333333333333334 9]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 209 and match_dt: 2023-10-30 00:00:00\n",
      "Filtered 17 matches for team_id: 209\n",
      "Found 13 matches before and 4 matches after 2023-10-30 00:00:00\n",
      "First match after 2023-10-30 00:00:00: 2023-11-24 00:00:00 (team1_id: 251, team2_id: 209)\n",
      "Team 209 is playing as team2 in the first match after 2023-10-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 209: [142.0 127.49490004079966 8 5 0 56 22 7.639285714285714 24.347826086956523\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 209.\n",
      "Extracting data for team_id: 76 and match_dt: 2023-10-30 00:00:00\n",
      "Filtered 43 matches for team_id: 76\n",
      "Found 34 matches before and 9 matches after 2023-10-30 00:00:00\n",
      "First match after 2023-10-30 00:00:00: 2023-12-01 00:00:00 (team1_id: 216, team2_id: 76)\n",
      "Team 76 is playing as team2 in the first match after 2023-10-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 76: [150.6 125.90677966101696 7 3 0 64 20 8.089285714285715 20.74074074074074\n",
      " 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 76.\n",
      "Extracting data for team_id: 33935 and match_dt: 2022-01-04 00:00:00\n",
      "Filtered 45 matches for team_id: 33935\n",
      "Found 19 matches before and 26 matches after 2022-01-04 00:00:00\n",
      "First match after 2022-01-04 00:00:00: 2022-01-17 00:00:00 (team1_id: 33921, team2_id: 33935)\n",
      "Team 33935 is playing as team2 in the first match after 2022-01-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33935: [174.6 149.11904761904765 10 5 1 59 36 7.7907375643224706\n",
      " 17.147058823529413 39]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33935.\n",
      "Extracting data for team_id: 33956 and match_dt: 2022-01-04 00:00:00\n",
      "Filtered 44 matches for team_id: 33956\n",
      "Found 18 matches before and 26 matches after 2022-01-04 00:00:00\n",
      "First match after 2022-01-04 00:00:00: 2022-01-15 00:00:00 (team1_id: 33956, team2_id: 33963)\n",
      "Team 33956 is playing as team1 in the first match after 2022-01-04 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33956: [151.4 134.32740846723897 7 3 0 61 23 7.790408525754884 18.161290322580644\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33956.\n",
      "Extracting data for team_id: 30428 and match_dt: 2023-05-05 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 28 matches before and 5 matches after 2023-05-05 00:00:00\n",
      "First match after 2023-05-05 00:00:00: 2023-05-14 00:00:00 (team1_id: 30393, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match after 2023-05-05 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30428: [185.6 155.1723163841808 10 5 0 70 41 8.959866220735787 18.6875 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30428.\n",
      "Extracting data for team_id: 48341 and match_dt: 2023-05-05 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 17 matches before and 7 matches after 2023-05-05 00:00:00\n",
      "First match after 2023-05-05 00:00:00: 2023-05-15 00:00:00 (team1_id: 48341, team2_id: 36014)\n",
      "Team 48341 is playing as team1 in the first match after 2023-05-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 48341: [161.8 138.9574517554057 11 4 0 69 25 8.288659793814432 23.28 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 36112 and match_dt: 2022-09-18 00:00:00\n",
      "Filtered 27 matches for team_id: 36112\n",
      "Found 17 matches before and 10 matches after 2022-09-18 00:00:00\n",
      "First match after 2022-09-18 00:00:00: 2022-09-27 00:00:00 (team1_id: 36098, team2_id: 36112)\n",
      "Team 36112 is playing as team2 in the first match after 2022-09-18 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36112: [151.2 141.680790960452 7 2 0 60 34 8.052336448598131 16.21212121212121 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36112.\n",
      "Extracting data for team_id: 36126 and match_dt: 2022-09-18 00:00:00\n",
      "Filtered 25 matches for team_id: 36126\n",
      "Found 14 matches before and 11 matches after 2022-09-18 00:00:00\n",
      "First match after 2022-09-18 00:00:00: 2022-09-22 00:00:00 (team1_id: 38814, team2_id: 36126)\n",
      "Team 36126 is playing as team2 in the first match after 2022-09-18 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36126: [126.2 116.66666666666669 6 3 0 38 27 7.207100591715976 15.84375 32]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36126.\n",
      "Extracting data for team_id: 69 and match_dt: 2022-10-18 00:00:00\n",
      "Filtered 49 matches for team_id: 69\n",
      "Found 32 matches before and 17 matches after 2022-10-18 00:00:00\n",
      "First match after 2022-10-18 00:00:00: 2022-10-20 00:00:00 (team1_id: 69, team2_id: 118)\n",
      "Team 69 is playing as team1 in the first match after 2022-10-18 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 69: [149.2 128.2499862870934 11 4 0 46 29 8.266423357664234 26.095238095238095\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 69.\n",
      "Extracting data for team_id: 202 and match_dt: 2022-10-18 00:00:00\n",
      "Filtered 37 matches for team_id: 202\n",
      "Found 10 matches before and 27 matches after 2022-10-18 00:00:00\n",
      "First match after 2022-10-18 00:00:00: 2022-10-20 00:00:00 (team1_id: 202, team2_id: 209)\n",
      "Team 202 is playing as team1 in the first match after 2022-10-18 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 202: [150.2 126.74134119380987 6 1 0 28 10 7.304794520547945 18.838709677419356\n",
      " 38]\n",
      "Adding extracted data to team2 columns in first file for team2_id 202.\n",
      "Extracting data for team_id: 30414 and match_dt: 2022-05-12 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 23 matches before and 13 matches after 2022-05-12 00:00:00\n",
      "First match after 2022-05-12 00:00:00: 2022-05-15 00:00:00 (team1_id: 30414, team2_id: 48341)\n",
      "Team 30414 is playing as team1 in the first match after 2022-05-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [166.6 138.83333333333331 10 4 0 72 37 8.48730964467005 20.379310344827587\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 30435 and match_dt: 2022-05-12 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 19 matches before and 12 matches after 2022-05-12 00:00:00\n",
      "First match after 2022-05-12 00:00:00: 2022-06-04 00:00:00 (team1_id: 30435, team2_id: 30400)\n",
      "Team 30435 is playing as team1 in the first match after 2022-05-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [161.2 134.33333333333334 7 2 0 57 21 8.13065326633166 17.057142857142857\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 8700 and match_dt: 2023-06-04 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 24 matches before and 3 matches after 2023-06-04 00:00:00\n",
      "First match after 2023-06-04 00:00:00: 2023-06-18 00:00:00 (team1_id: 7258, team2_id: 8700)\n",
      "Team 8700 is playing as team2 in the first match after 2023-06-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 8700: [147.4 131.11544645610326 8 2 0 70 26 8.601156069364162 17.3 25]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8700.\n",
      "Extracting data for team_id: 7608 and match_dt: 2023-06-04 00:00:00\n",
      "Filtered 28 matches for team_id: 7608\n",
      "Found 24 matches before and 4 matches after 2023-06-04 00:00:00\n",
      "First match after 2023-06-04 00:00:00: 2023-06-18 00:00:00 (team1_id: 7573, team2_id: 7608)\n",
      "Team 7608 is playing as team2 in the first match after 2023-06-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 7608: [137.4 118.7004732927654 5 2 0 51 13 7.867172675521822 19.51851851851852\n",
      " 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7608.\n",
      "Extracting data for team_id: 33949 and match_dt: 2022-12-26 00:00:00\n",
      "Filtered 38 matches for team_id: 33949\n",
      "Found 24 matches before and 14 matches after 2022-12-26 00:00:00\n",
      "First match after 2022-12-26 00:00:00: 2023-01-14 00:00:00 (team1_id: 33942, team2_id: 33949)\n",
      "Team 33949 is playing as team2 in the first match after 2022-12-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33949: [144.0 120.0 5 3 1 45 23 6.964467005076143 15.972972972972974 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33949.\n",
      "Extracting data for team_id: 33956 and match_dt: 2022-12-26 00:00:00\n",
      "Filtered 44 matches for team_id: 33956\n",
      "Found 28 matches before and 16 matches after 2022-12-26 00:00:00\n",
      "First match after 2022-12-26 00:00:00: 2022-12-28 00:00:00 (team1_id: 33956, team2_id: 33942)\n",
      "Team 33956 is playing as team1 in the first match after 2022-12-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33956: [129.4 118.31726119050218 10 0 0 44 19 6.758490566037736 12.61904761904762\n",
      " 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33956.\n",
      "Extracting data for team_id: 258 and match_dt: 2022-02-21 00:00:00\n",
      "Filtered 1 matches for team_id: 258\n",
      "Found 1 matches before and 0 matches after 2022-02-21 00:00:00\n",
      "No match after 2022-02-21 00:00:00. Using first match before 2022-02-21 00:00:00: 2022-02-19 00:00:00 (team1_id: 202, team2_id: 258)\n",
      "Team 258 is playing as team2 in the first match before 2022-02-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 258: [0.0 0.0 0 0 0 0 0 0.0 0.0 0]\n",
      "Adding extracted data to team1 columns in first file for team1_id 258.\n",
      "Extracting data for team_id: 216 and match_dt: 2022-02-21 00:00:00\n",
      "Filtered 50 matches for team_id: 216\n",
      "Found 15 matches before and 35 matches after 2022-02-21 00:00:00\n",
      "First match after 2022-02-21 00:00:00: 2022-02-22 00:00:00 (team1_id: 216, team2_id: 272)\n",
      "Team 216 is playing as team1 in the first match after 2022-02-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 216: [154.8 130.31578947368422 8 1 0 41 22 7.44 17.647058823529413 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 216.\n",
      "Extracting data for team_id: 30393 and match_dt: 2023-04-10 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 28 matches before and 9 matches after 2023-04-10 00:00:00\n",
      "First match after 2023-04-10 00:00:00: 2023-04-15 00:00:00 (team1_id: 30393, team2_id: 30421)\n",
      "Team 30393 is playing as team1 in the first match after 2023-04-10 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [167.0 145.55882352941177 13 4 0 59 38 7.8125 16.941176470588236 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 48334 and match_dt: 2023-04-10 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 14 matches before and 5 matches after 2023-04-10 00:00:00\n",
      "First match after 2023-04-10 00:00:00: 2023-04-22 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match after 2023-04-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [150.0 130.4031007751938 6 2 0 46 38 7.420494699646643 12.863636363636363\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 55 and match_dt: 2022-08-07 00:00:00\n",
      "Filtered 60 matches for team_id: 55\n",
      "Found 31 matches before and 29 matches after 2022-08-07 00:00:00\n",
      "First match after 2022-08-07 00:00:00: 2022-08-09 00:00:00 (team1_id: 55, team2_id: 293)\n",
      "Team 55 is playing as team1 in the first match after 2022-08-07 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 55: [174.8 161.85416666666666 10 6 1 88 36 7.694656488549618\n",
      " 14.555555555555555 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 55.\n",
      "Extracting data for team_id: 41 and match_dt: 2022-08-07 00:00:00\n",
      "Filtered 49 matches for team_id: 41\n",
      "Found 32 matches before and 17 matches after 2022-08-07 00:00:00\n",
      "First match after 2022-08-07 00:00:00: 2022-10-21 00:00:00 (team1_id: 41, team2_id: 216)\n",
      "Team 41 is playing as team1 in the first match after 2022-08-07 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 41: [154.2 128.5 5 3 0 57 35 7.38 18.181818181818183 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 41.\n",
      "Extracting data for team_id: 17653 and match_dt: 2023-02-11 00:00:00\n",
      "Filtered 38 matches for team_id: 17653\n",
      "Found 28 matches before and 10 matches after 2023-02-11 00:00:00\n",
      "First match after 2023-02-11 00:00:00: 2023-06-02 00:00:00 (team1_id: 18360, team2_id: 17653)\n",
      "Team 17653 is playing as team2 in the first match after 2023-02-11 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 17653: [154.2 128.5 9 3 0 64 17 8.018382352941178 18.75862068965517 34]\n",
      "Adding extracted data to team1 columns in first file for team1_id 17653.\n",
      "Extracting data for team_id: 17982 and match_dt: 2023-02-11 00:00:00\n",
      "Filtered 32 matches for team_id: 17982\n",
      "Found 22 matches before and 10 matches after 2023-02-11 00:00:00\n",
      "First match after 2023-02-11 00:00:00: 2023-04-01 00:00:00 (team1_id: 18570, team2_id: 17982)\n",
      "Team 17982 is playing as team2 in the first match after 2023-02-11 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 17982: [152.4 140.3972693972694 7 4 0 62 40 8.239845261121857 16.677419354838708\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 17982.\n",
      "Extracting data for team_id: 40578 and match_dt: 2022-02-14 00:00:00\n",
      "Filtered 37 matches for team_id: 40578\n",
      "Found 13 matches before and 24 matches after 2022-02-14 00:00:00\n",
      "First match after 2022-02-14 00:00:00: 2022-02-17 00:00:00 (team1_id: 40550, team2_id: 40578)\n",
      "Team 40578 is playing as team2 in the first match after 2022-02-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 40578: [160.0 153.7335562987737 6 3 0 77 29 9.136363636363637 19.555555555555557\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40578.\n",
      "Extracting data for team_id: 40564 and match_dt: 2022-02-14 00:00:00\n",
      "Filtered 33 matches for team_id: 40564\n",
      "Found 14 matches before and 19 matches after 2022-02-14 00:00:00\n",
      "First match after 2022-02-14 00:00:00: 2022-02-18 00:00:00 (team1_id: 40564, team2_id: 40606)\n",
      "Team 40564 is playing as team1 in the first match after 2022-02-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 40564: [142.8 121.28816199376948 7 3 0 54 22 7.571177504393673 24.73913043478261\n",
      " 21]\n",
      "Adding extracted data to team2 columns in first file for team2_id 40564.\n",
      "Extracting data for team_id: 48 and match_dt: 2022-08-10 00:00:00\n",
      "Filtered 57 matches for team_id: 48\n",
      "Found 29 matches before and 28 matches after 2022-08-10 00:00:00\n",
      "First match after 2022-08-10 00:00:00: 2022-09-10 00:00:00 (team1_id: 188, team2_id: 48)\n",
      "Team 48 is playing as team2 in the first match after 2022-08-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48: [181.0 151.60256410256412 10 4 1 65 37 7.494661921708186 13.38095238095238\n",
      " 44]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48.\n",
      "Extracting data for team_id: 41 and match_dt: 2022-08-10 00:00:00\n",
      "Filtered 49 matches for team_id: 41\n",
      "Found 32 matches before and 17 matches after 2022-08-10 00:00:00\n",
      "First match after 2022-08-10 00:00:00: 2022-10-21 00:00:00 (team1_id: 41, team2_id: 216)\n",
      "Team 41 is playing as team1 in the first match after 2022-08-10 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 41: [154.2 128.5 5 3 0 57 35 7.38 18.181818181818183 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 41.\n",
      "Extracting data for team_id: 62 and match_dt: 2023-04-14 00:00:00\n",
      "Filtered 66 matches for team_id: 62\n",
      "Found 50 matches before and 16 matches after 2023-04-14 00:00:00\n",
      "First match after 2023-04-14 00:00:00: 2023-04-17 00:00:00 (team1_id: 48, team2_id: 62)\n",
      "Team 62 is playing as team2 in the first match after 2023-04-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 62: [151.2 126.0 7 1 0 57 23 6.534031413612565 15.486486486486486 33]\n",
      "Adding extracted data to team1 columns in first file for team1_id 62.\n",
      "Extracting data for team_id: 48 and match_dt: 2023-04-14 00:00:00\n",
      "Filtered 57 matches for team_id: 48\n",
      "Found 39 matches before and 18 matches after 2023-04-14 00:00:00\n",
      "First match after 2023-04-14 00:00:00: 2023-04-17 00:00:00 (team1_id: 48, team2_id: 62)\n",
      "Team 48 is playing as team1 in the first match after 2023-04-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 48: [151.0 139.2201550387597 11 6 0 53 36 7.102514506769825 11.23913043478261\n",
      " 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48.\n",
      "Extracting data for team_id: 48334 and match_dt: 2023-04-15 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 14 matches before and 5 matches after 2023-04-15 00:00:00\n",
      "First match after 2023-04-15 00:00:00: 2023-04-22 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match after 2023-04-15 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [150.0 130.4031007751938 6 2 0 46 38 7.420494699646643 12.863636363636363\n",
      " 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30407 and match_dt: 2023-04-15 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 25 matches before and 7 matches after 2023-04-15 00:00:00\n",
      "First match after 2023-04-15 00:00:00: 2023-04-20 00:00:00 (team1_id: 30393, team2_id: 30407)\n",
      "Team 30407 is playing as team2 in the first match after 2023-04-15 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30407: [167.0 146.18421052631578 8 2 0 79 33 8.593128390596744 19.06896551724138\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 8700 and match_dt: 2022-05-26 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 14 matches before and 13 matches after 2022-05-26 00:00:00\n",
      "First match after 2022-05-26 00:00:00: 2022-05-29 00:00:00 (team1_id: 7573, team2_id: 8700)\n",
      "Team 8700 is playing as team2 in the first match after 2022-05-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 8700: [164.8 137.33333333333334 10 5 0 76 22 8.237113402061855\n",
      " 14.923076923076923 37]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8700.\n",
      "Extracting data for team_id: 7608 and match_dt: 2022-05-26 00:00:00\n",
      "Filtered 28 matches for team_id: 7608\n",
      "Found 14 matches before and 14 matches after 2022-05-26 00:00:00\n",
      "First match after 2022-05-26 00:00:00: 2022-05-27 00:00:00 (team1_id: 7608, team2_id: 9967)\n",
      "Team 7608 is playing as team1 in the first match after 2022-05-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 7608: [153.6 134.73408239700373 7 1 0 50 27 8.103756708407872 15.52777777777778\n",
      " 39]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7608.\n",
      "Extracting data for team_id: 40298 and match_dt: 2023-01-23 00:00:00\n",
      "Filtered 32 matches for team_id: 40298\n",
      "Found 10 matches before and 22 matches after 2023-01-23 00:00:00\n",
      "First match after 2023-01-23 00:00:00: 2023-01-28 00:00:00 (team1_id: 40298, team2_id: 42573)\n",
      "Team 40298 is playing as team1 in the first match after 2023-01-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 40298: [156.0 135.20932607215795 10 5 0 48 39 7.091854419410746\n",
      " 20.607142857142858 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40298.\n",
      "Extracting data for team_id: 40452 and match_dt: 2023-01-23 00:00:00\n",
      "Filtered 11 matches for team_id: 40452\n",
      "Found 8 matches before and 3 matches after 2023-01-23 00:00:00\n",
      "First match after 2023-01-23 00:00:00: 2023-01-30 00:00:00 (team1_id: 40452, team2_id: 35790)\n",
      "Team 40452 is playing as team1 in the first match after 2023-01-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 40452: [142.4 120.63636363636364 8 2 0 59 19 7.450777202072539 25.17391304347826\n",
      " 25]\n",
      "Adding extracted data to team2 columns in first file for team2_id 40452.\n",
      "Extracting data for team_id: 18360 and match_dt: 2022-01-06 00:00:00\n",
      "Filtered 29 matches for team_id: 18360\n",
      "Found 14 matches before and 15 matches after 2022-01-06 00:00:00\n",
      "First match after 2022-01-06 00:00:00: 2022-01-15 00:00:00 (team1_id: 18360, team2_id: 17583)\n",
      "Team 18360 is playing as team1 in the first match after 2022-01-06 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 18360: [142.0 121.35714285714286 6 4 0 63 19 7.486910994764399 17.90625 25]\n",
      "Adding extracted data to team1 columns in first file for team1_id 18360.\n",
      "Extracting data for team_id: 18570 and match_dt: 2022-01-06 00:00:00\n",
      "Filtered 32 matches for team_id: 18570\n",
      "Found 14 matches before and 18 matches after 2022-01-06 00:00:00\n",
      "First match after 2022-01-06 00:00:00: 2022-01-16 00:00:00 (team1_id: 18570, team2_id: 17982)\n",
      "Team 18570 is playing as team1 in the first match after 2022-01-06 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 18570: [160.8 134.0 9 4 0 70 26 7.518716577540108 15.583333333333334 39]\n",
      "Adding extracted data to team2 columns in first file for team2_id 18570.\n",
      "Extracting data for team_id: 48 and match_dt: 2022-10-08 00:00:00\n",
      "Filtered 57 matches for team_id: 48\n",
      "Found 31 matches before and 26 matches after 2022-10-08 00:00:00\n",
      "First match after 2022-10-08 00:00:00: 2022-10-14 00:00:00 (team1_id: 48, team2_id: 62)\n",
      "Team 48 is playing as team1 in the first match after 2022-10-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 48: [175.6 149.73219373219374 11 5 1 61 34 7.887272727272727 20.37037037037037\n",
      " 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48.\n",
      "Extracting data for team_id: 62 and match_dt: 2022-10-08 00:00:00\n",
      "Filtered 66 matches for team_id: 62\n",
      "Found 41 matches before and 25 matches after 2022-10-08 00:00:00\n",
      "First match after 2022-10-08 00:00:00: 2022-10-14 00:00:00 (team1_id: 48, team2_id: 62)\n",
      "Team 62 is playing as team2 in the first match after 2022-10-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 62: [168.2 140.78632478632477 8 6 1 56 30 8.799295774647888 21.03703703703704\n",
      " 27]\n",
      "Adding extracted data to team2 columns in first file for team2_id 62.\n",
      "Extracting data for team_id: 33935 and match_dt: 2023-01-04 00:00:00\n",
      "Filtered 45 matches for team_id: 33935\n",
      "Found 28 matches before and 17 matches after 2023-01-04 00:00:00\n",
      "First match after 2023-01-04 00:00:00: 2023-01-13 00:00:00 (team1_id: 33963, team2_id: 33935)\n",
      "Team 33935 is playing as team2 in the first match after 2023-01-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 33935: [160.6 135.09107734268463 9 4 0 61 27 7.252525252525253 15.23076923076923\n",
      " 38]\n",
      "Adding extracted data to team1 columns in first file for team1_id 33935.\n",
      "Extracting data for team_id: 33963 and match_dt: 2023-01-04 00:00:00\n",
      "Filtered 36 matches for team_id: 33963\n",
      "Found 25 matches before and 11 matches after 2023-01-04 00:00:00\n",
      "First match after 2023-01-04 00:00:00: 2023-01-13 00:00:00 (team1_id: 33963, team2_id: 33935)\n",
      "Team 33963 is playing as team1 in the first match after 2023-01-04 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 33963: [138.0 120.83333333333331 8 4 0 51 27 7.605633802816902 12.743589743589745\n",
      " 38]\n",
      "Adding extracted data to team2 columns in first file for team2_id 33963.\n",
      "Extracting data for team_id: 30407 and match_dt: 2023-04-22 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 26 matches before and 6 matches after 2023-04-22 00:00:00\n",
      "First match after 2023-04-22 00:00:00: 2023-04-28 00:00:00 (team1_id: 48334, team2_id: 30407)\n",
      "Team 30407 is playing as team2 in the first match after 2023-04-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30407: [168.6 149.06621642602082 8 2 0 71 34 8.79120879120879 18.2 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30407.\n",
      "Extracting data for team_id: 30435 and match_dt: 2023-04-22 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 25 matches before and 6 matches after 2023-04-22 00:00:00\n",
      "First match after 2023-04-22 00:00:00: 2023-05-16 00:00:00 (team1_id: 48334, team2_id: 30435)\n",
      "Team 30435 is playing as team2 in the first match after 2023-04-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30435: [175.4 149.29510703363914 8 3 0 61 35 9.132743362831858 22.6 26]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 188 and match_dt: 2022-09-25 00:00:00\n",
      "Filtered 54 matches for team_id: 188\n",
      "Found 34 matches before and 20 matches after 2022-09-25 00:00:00\n",
      "First match after 2022-09-25 00:00:00: 2022-10-24 00:00:00 (team1_id: 188, team2_id: 118)\n",
      "Team 188 is playing as team1 in the first match after 2022-09-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 188: [139.0 115.83333333333331 3 1 0 31 11 7.356521739130435 23.958333333333332\n",
      " 20]\n",
      "Adding extracted data to team1 columns in first file for team1_id 188.\n",
      "Extracting data for team_id: 202 and match_dt: 2022-09-25 00:00:00\n",
      "Filtered 37 matches for team_id: 202\n",
      "Found 9 matches before and 28 matches after 2022-09-25 00:00:00\n",
      "First match after 2022-09-25 00:00:00: 2022-10-16 00:00:00 (team1_id: 202, team2_id: 118)\n",
      "Team 202 is playing as team1 in the first match after 2022-09-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 202: [163.0 137.40800786047652 7 1 0 34 14 7.290877796901893 17.08823529411765\n",
      " 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 202.\n",
      "Extracting data for team_id: 9701 and match_dt: 2023-06-30 00:00:00\n",
      "Filtered 40 matches for team_id: 9701\n",
      "Found 36 matches before and 4 matches after 2023-06-30 00:00:00\n",
      "First match after 2023-06-30 00:00:00: 2023-07-06 00:00:00 (team1_id: 7727, team2_id: 9701)\n",
      "Team 9701 is playing as team2 in the first match after 2023-06-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 9701: [153.4 145.9010750918765 11 2 0 54 42 8.823529411764707 17.0 47]\n",
      "Adding extracted data to team1 columns in first file for team1_id 9701.\n",
      "Extracting data for team_id: 9876 and match_dt: 2023-06-30 00:00:00\n",
      "Filtered 35 matches for team_id: 9876\n",
      "Found 31 matches before and 4 matches after 2023-06-30 00:00:00\n",
      "First match after 2023-06-30 00:00:00: 2023-07-06 00:00:00 (team1_id: 9876, team2_id: 7573)\n",
      "Team 9876 is playing as team1 in the first match after 2023-06-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 9876: [185.6 154.66666666666669 8 4 1 64 48 8.224956063268893 18.966666666666665\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 9876.\n",
      "Extracting data for team_id: 30414 and match_dt: 2022-05-08 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 23 matches before and 13 matches after 2022-05-08 00:00:00\n",
      "First match after 2022-05-08 00:00:00: 2022-05-15 00:00:00 (team1_id: 30414, team2_id: 48341)\n",
      "Team 30414 is playing as team1 in the first match after 2022-05-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [166.6 138.83333333333331 10 4 0 72 37 8.48730964467005 20.379310344827587\n",
      " 27]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 30421 and match_dt: 2022-05-08 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 23 matches before and 14 matches after 2022-05-08 00:00:00\n",
      "First match after 2022-05-08 00:00:00: 2022-05-16 00:00:00 (team1_id: 30421, team2_id: 30407)\n",
      "Team 30421 is playing as team1 in the first match after 2022-05-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30421: [171.2 157.96711259754738 12 4 0 78 41 9.175824175824175 18.2 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 17982 and match_dt: 2023-02-09 00:00:00\n",
      "Filtered 32 matches for team_id: 17982\n",
      "Found 22 matches before and 10 matches after 2023-02-09 00:00:00\n",
      "First match after 2023-02-09 00:00:00: 2023-04-01 00:00:00 (team1_id: 18570, team2_id: 17982)\n",
      "Team 17982 is playing as team2 in the first match after 2023-02-09 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 17982: [152.4 140.3972693972694 7 4 0 62 40 8.239845261121857 16.677419354838708\n",
      " 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 17982.\n",
      "Extracting data for team_id: 18360 and match_dt: 2023-02-09 00:00:00\n",
      "Filtered 29 matches for team_id: 18360\n",
      "Found 21 matches before and 8 matches after 2023-02-09 00:00:00\n",
      "First match after 2023-02-09 00:00:00: 2023-06-02 00:00:00 (team1_id: 18360, team2_id: 17653)\n",
      "Team 18360 is playing as team1 in the first match after 2023-02-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 18360: [157.6 131.33333333333334 8 3 0 59 28 7.880910683012258 16.314285714285713\n",
      " 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 18360.\n",
      "Extracting data for team_id: 40606 and match_dt: 2022-01-29 00:00:00\n",
      "Filtered 38 matches for team_id: 40606\n",
      "Found 10 matches before and 28 matches after 2022-01-29 00:00:00\n",
      "First match after 2022-01-29 00:00:00: 2022-02-13 00:00:00 (team1_id: 40592, team2_id: 40606)\n",
      "Team 40606 is playing as team2 in the first match after 2022-01-29 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 40606: [142.4 124.84782608695654 7 1 0 52 32 7.468085106382979 14.1 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 40606.\n",
      "Extracting data for team_id: 44904 and match_dt: 2022-01-29 00:00:00\n",
      "Filtered 42 matches for team_id: 44904\n",
      "Found 14 matches before and 28 matches after 2022-01-29 00:00:00\n",
      "First match after 2022-01-29 00:00:00: 2022-01-31 00:00:00 (team1_id: 44904, team2_id: 40592)\n",
      "Team 44904 is playing as team1 in the first match after 2022-01-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 44904: [181.0 152.33333333333331 15 6 0 80 43 8.126064735945485\n",
      " 15.051282051282053 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 44904.\n",
      "Extracting data for team_id: 55 and match_dt: 2022-06-12 00:00:00\n",
      "Filtered 60 matches for team_id: 55\n",
      "Found 26 matches before and 34 matches after 2022-06-12 00:00:00\n",
      "First match after 2022-06-12 00:00:00: 2022-06-14 00:00:00 (team1_id: 55, team2_id: 34)\n",
      "Team 55 is playing as team1 in the first match after 2022-06-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 55: [174.8 151.70398970398972 9 6 0 76 29 8.518518518518519 21.807692307692307\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 55.\n",
      "Extracting data for team_id: 34 and match_dt: 2022-06-12 00:00:00\n",
      "Filtered 44 matches for team_id: 34\n",
      "Found 27 matches before and 17 matches after 2022-06-12 00:00:00\n",
      "First match after 2022-06-12 00:00:00: 2022-06-14 00:00:00 (team1_id: 55, team2_id: 34)\n",
      "Team 34 is playing as team2 in the first match after 2022-06-12 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 34: [165.4 151.04511802107828 10 5 1 75 32 8.545794392523364 16.71875 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 34.\n",
      "Extracting data for team_id: 47529 and match_dt: 2023-01-31 00:00:00\n",
      "Filtered 32 matches for team_id: 47529\n",
      "Found 13 matches before and 19 matches after 2023-01-31 00:00:00\n",
      "First match after 2023-01-31 00:00:00: 2023-03-02 00:00:00 (team1_id: 47529, team2_id: 42573)\n",
      "Team 47529 is playing as team1 in the first match after 2023-01-31 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 47529: [196.2 163.5 13 6 1 67 61 8.76 17.647058823529413 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 47529.\n",
      "Extracting data for team_id: 40452 and match_dt: 2023-01-31 00:00:00\n",
      "Filtered 11 matches for team_id: 40452\n",
      "Found 9 matches before and 2 matches after 2023-01-31 00:00:00\n",
      "First match after 2023-01-31 00:00:00: 2023-07-01 00:00:00 (team1_id: 42573, team2_id: 40452)\n",
      "Team 40452 is playing as team2 in the first match after 2023-01-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 40452: [145.2 121.0 7 3 0 65 20 7.525597269624573 26.636363636363637 22]\n",
      "Adding extracted data to team2 columns in first file for team2_id 40452.\n",
      "Extracting data for team_id: 202 and match_dt: 2023-02-16 00:00:00\n",
      "Filtered 37 matches for team_id: 202\n",
      "Found 13 matches before and 24 matches after 2023-02-16 00:00:00\n",
      "First match after 2023-02-16 00:00:00: 2023-02-18 00:00:00 (team1_id: 293, team2_id: 202)\n",
      "Team 202 is playing as team2 in the first match after 2023-02-16 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 202: [154.8 129.41525423728814 7 2 0 40 21 7.266331658291458 19.9 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 202.\n",
      "Extracting data for team_id: 293 and match_dt: 2023-02-16 00:00:00\n",
      "Filtered 38 matches for team_id: 293\n",
      "Found 22 matches before and 16 matches after 2023-02-16 00:00:00\n",
      "First match after 2023-02-16 00:00:00: 2023-02-18 00:00:00 (team1_id: 293, team2_id: 202)\n",
      "Team 293 is playing as team1 in the first match after 2023-02-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 293: [150.6 125.5 10 2 0 47 18 7.236486486486487 19.733333333333334 34]\n",
      "Adding extracted data to team2 columns in first file for team2_id 293.\n",
      "Extracting data for team_id: 44904 and match_dt: 2023-02-17 00:00:00\n",
      "Filtered 42 matches for team_id: 44904\n",
      "Found 22 matches before and 20 matches after 2023-02-17 00:00:00\n",
      "First match after 2023-02-17 00:00:00: 2023-02-22 00:00:00 (team1_id: 44904, team2_id: 40564)\n",
      "Team 44904 is playing as team1 in the first match after 2023-02-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 44904: [153.6 136.90740740740742 10 5 0 73 14 7.46524064171123 15.583333333333334\n",
      " 40]\n",
      "Adding extracted data to team1 columns in first file for team1_id 44904.\n",
      "Extracting data for team_id: 40550 and match_dt: 2023-02-17 00:00:00\n",
      "Filtered 35 matches for team_id: 40550\n",
      "Found 19 matches before and 16 matches after 2023-02-17 00:00:00\n",
      "First match after 2023-02-17 00:00:00: 2023-02-20 00:00:00 (team1_id: 40592, team2_id: 40550)\n",
      "Team 40550 is playing as team2 in the first match after 2023-02-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 40550: [176.2 146.83333333333331 9 4 0 62 31 8.08 17.647058823529413 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 40550.\n",
      "Extracting data for team_id: 36112 and match_dt: 2022-09-22 00:00:00\n",
      "Filtered 27 matches for team_id: 36112\n",
      "Found 17 matches before and 10 matches after 2022-09-22 00:00:00\n",
      "First match after 2022-09-22 00:00:00: 2022-09-27 00:00:00 (team1_id: 36098, team2_id: 36112)\n",
      "Team 36112 is playing as team2 in the first match after 2022-09-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36112: [151.2 141.680790960452 7 2 0 60 34 8.052336448598131 16.21212121212121 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36112.\n",
      "Extracting data for team_id: 36084 and match_dt: 2022-09-22 00:00:00\n",
      "Filtered 24 matches for team_id: 36084\n",
      "Found 13 matches before and 11 matches after 2022-09-22 00:00:00\n",
      "First match after 2022-09-22 00:00:00: 2022-09-24 00:00:00 (team1_id: 36084, team2_id: 36126)\n",
      "Team 36084 is playing as team1 in the first match after 2022-09-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 36084: [131.6 116.03436426116836 4 2 0 48 33 6.440860215053764 12.4 40]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36084.\n",
      "Extracting data for team_id: 9967 and match_dt: 2023-06-08 00:00:00\n",
      "Filtered 34 matches for team_id: 9967\n",
      "Found 29 matches before and 5 matches after 2023-06-08 00:00:00\n",
      "First match after 2023-06-08 00:00:00: 2023-06-20 00:00:00 (team1_id: 9967, team2_id: 8056)\n",
      "Team 9967 is playing as team1 in the first match after 2023-06-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 9967: [162.0 136.04347826086956 9 4 0 70 30 8.896174863387978 23.869565217391305\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 9967.\n",
      "Extracting data for team_id: 8700 and match_dt: 2023-06-08 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 24 matches before and 3 matches after 2023-06-08 00:00:00\n",
      "First match after 2023-06-08 00:00:00: 2023-06-18 00:00:00 (team1_id: 7258, team2_id: 8700)\n",
      "Team 8700 is playing as team2 in the first match after 2023-06-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 8700: [147.4 131.11544645610326 8 2 0 70 26 8.601156069364162 17.3 25]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8700.\n",
      "Extracting data for team_id: 8301 and match_dt: 2022-06-05 00:00:00\n",
      "Filtered 38 matches for team_id: 8301\n",
      "Found 19 matches before and 19 matches after 2022-06-05 00:00:00\n",
      "First match after 2022-06-05 00:00:00: 2022-06-17 00:00:00 (team1_id: 10576, team2_id: 8301)\n",
      "Team 8301 is playing as team2 in the first match after 2022-06-05 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 8301: [166.4 144.94281524926686 9 4 0 86 23 7.886323268206039 12.511111111111113\n",
      " 38]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8301.\n",
      "Extracting data for team_id: 10576 and match_dt: 2022-06-05 00:00:00\n",
      "Filtered 31 matches for team_id: 10576\n",
      "Found 15 matches before and 16 matches after 2022-06-05 00:00:00\n",
      "First match after 2022-06-05 00:00:00: 2022-06-17 00:00:00 (team1_id: 10576, team2_id: 8301)\n",
      "Team 10576 is playing as team1 in the first match after 2022-06-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 10576: [177.0 147.5 11 4 0 63 31 8.01015228426396 13.431818181818182 41]\n",
      "Adding extracted data to team2 columns in first file for team2_id 10576.\n",
      "Extracting data for team_id: 8301 and match_dt: 2022-06-02 00:00:00\n",
      "Filtered 38 matches for team_id: 8301\n",
      "Found 19 matches before and 19 matches after 2022-06-02 00:00:00\n",
      "First match after 2022-06-02 00:00:00: 2022-06-17 00:00:00 (team1_id: 10576, team2_id: 8301)\n",
      "Team 8301 is playing as team2 in the first match after 2022-06-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 8301: [166.4 144.94281524926686 9 4 0 86 23 7.886323268206039 12.511111111111113\n",
      " 38]\n",
      "Adding extracted data to team1 columns in first file for team1_id 8301.\n",
      "Extracting data for team_id: 10366 and match_dt: 2022-06-02 00:00:00\n",
      "Filtered 34 matches for team_id: 10366\n",
      "Found 20 matches before and 14 matches after 2022-06-02 00:00:00\n",
      "First match after 2022-06-02 00:00:00: 2022-06-19 00:00:00 (team1_id: 10366, team2_id: 6698)\n",
      "Team 10366 is playing as team1 in the first match after 2022-06-02 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 10366: [167.4 174.19193845762604 9 4 1 68 40 8.777777777777779 13.5 37]\n",
      "Adding extracted data to team2 columns in first file for team2_id 10366.\n",
      "Extracting data for team_id: 9967 and match_dt: 2023-06-16 00:00:00\n",
      "Filtered 34 matches for team_id: 9967\n",
      "Found 29 matches before and 5 matches after 2023-06-16 00:00:00\n",
      "First match after 2023-06-16 00:00:00: 2023-06-20 00:00:00 (team1_id: 9967, team2_id: 8056)\n",
      "Team 9967 is playing as team1 in the first match after 2023-06-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 9967: [162.0 136.04347826086956 9 4 0 70 30 8.896174863387978 23.869565217391305\n",
      " 26]\n",
      "Adding extracted data to team1 columns in first file for team1_id 9967.\n",
      "Extracting data for team_id: 7727 and match_dt: 2023-06-16 00:00:00\n",
      "Filtered 35 matches for team_id: 7727\n",
      "Found 29 matches before and 6 matches after 2023-06-16 00:00:00\n",
      "First match after 2023-06-16 00:00:00: 2023-06-18 00:00:00 (team1_id: 9876, team2_id: 7727)\n",
      "Team 7727 is playing as team2 in the first match after 2023-06-16 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 7727: [142.4 136.44356667398142 8 5 1 64 25 8.113636363636363 27.5 42]\n",
      "Adding extracted data to team2 columns in first file for team2_id 7727.\n",
      "Extracting data for team_id: 11591 and match_dt: 2022-10-14 00:00:00\n",
      "Filtered 13 matches for team_id: 11591\n",
      "Found 9 matches before and 4 matches after 2022-10-14 00:00:00\n",
      "First match after 2022-10-14 00:00:00: 2022-10-20 00:00:00 (team1_id: 11591, team2_id: 13131)\n",
      "Team 11591 is playing as team1 in the first match after 2022-10-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 11591: [155.8 135.19932574799833 7 5 0 51 35 7.131487889273355 15.62162162162162\n",
      " 33]\n",
      "Adding extracted data to team1 columns in first file for team1_id 11591.\n",
      "Extracting data for team_id: 11220 and match_dt: 2022-10-14 00:00:00\n",
      "Filtered 15 matches for team_id: 11220\n",
      "Found 10 matches before and 5 matches after 2022-10-14 00:00:00\n",
      "First match after 2022-10-14 00:00:00: 2022-10-16 00:00:00 (team1_id: 45933, team2_id: 11220)\n",
      "Team 11220 is playing as team2 in the first match after 2022-10-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 11220: [131.8 109.83333333333331 2 2 0 12 8 7.033747779751333 24.47826086956522\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 11220.\n",
      "Extracting data for team_id: 7727 and match_dt: 2023-06-06 00:00:00\n",
      "Filtered 35 matches for team_id: 7727\n",
      "Found 29 matches before and 6 matches after 2023-06-06 00:00:00\n",
      "First match after 2023-06-06 00:00:00: 2023-06-18 00:00:00 (team1_id: 9876, team2_id: 7727)\n",
      "Team 7727 is playing as team2 in the first match after 2023-06-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 7727: [142.4 136.44356667398142 8 5 1 64 25 8.113636363636363 27.5 42]\n",
      "Adding extracted data to team1 columns in first file for team1_id 7727.\n",
      "Extracting data for team_id: 8700 and match_dt: 2023-06-06 00:00:00\n",
      "Filtered 27 matches for team_id: 8700\n",
      "Found 24 matches before and 3 matches after 2023-06-06 00:00:00\n",
      "First match after 2023-06-06 00:00:00: 2023-06-18 00:00:00 (team1_id: 7258, team2_id: 8700)\n",
      "Team 8700 is playing as team2 in the first match after 2023-06-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 8700: [147.4 131.11544645610326 8 2 0 70 26 8.601156069364162 17.3 25]\n",
      "Adding extracted data to team2 columns in first file for team2_id 8700.\n",
      "Extracting data for team_id: 14629 and match_dt: 2022-10-16 00:00:00\n",
      "Filtered 10 matches for team_id: 14629\n",
      "Found 10 matches before and 0 matches after 2022-10-16 00:00:00\n",
      "No match after 2022-10-16 00:00:00. Using first match before 2022-10-16 00:00:00: 2022-10-14 00:00:00 (team1_id: 14629, team2_id: 13131)\n",
      "Team 14629 is playing as team1 in the first match before 2022-10-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 14629: [128.4 113.26251526251528 6 3 0 44 13 6.686346863468635 17.483870967741936\n",
      " 33]\n",
      "Adding extracted data to team1 columns in first file for team1_id 14629.\n",
      "Extracting data for team_id: 45961 and match_dt: 2022-10-16 00:00:00\n",
      "Filtered 11 matches for team_id: 45961\n",
      "Found 8 matches before and 3 matches after 2022-10-16 00:00:00\n",
      "First match after 2022-10-16 00:00:00: 2022-10-18 00:00:00 (team1_id: 15623, team2_id: 45961)\n",
      "Team 45961 is playing as team2 in the first match after 2022-10-16 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 45961: [134.6 113.5990990990991 0 0 0 5 1 6.862944162436548 17.90909090909091 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 45961.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-03-22 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-03-22 00:00:00\n",
      "No match after 2024-03-22 00:00:00. Using first match before 2024-03-22 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-03-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-03-22 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-03-22 00:00:00\n",
      "No match after 2024-03-22 00:00:00. Using first match before 2024-03-22 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-03-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30414.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-03-23 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-03-23 00:00:00\n",
      "No match after 2024-03-23 00:00:00. Using first match before 2024-03-23 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-03-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-03-23 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-03-23 00:00:00\n",
      "No match after 2024-03-23 00:00:00. Using first match before 2024-03-23 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-03-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-03-23 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-03-23 00:00:00\n",
      "No match after 2024-03-23 00:00:00. Using first match before 2024-03-23 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-03-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-03-23 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-03-23 00:00:00\n",
      "No match after 2024-03-23 00:00:00. Using first match before 2024-03-23 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-03-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-03-24 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-03-24 00:00:00\n",
      "No match after 2024-03-24 00:00:00. Using first match before 2024-03-24 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-03-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30428.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-03-24 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-03-24 00:00:00\n",
      "No match after 2024-03-24 00:00:00. Using first match before 2024-03-24 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-03-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-03-24 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-03-24 00:00:00\n",
      "No match after 2024-03-24 00:00:00. Using first match before 2024-03-24 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-03-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-03-24 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-03-24 00:00:00\n",
      "No match after 2024-03-24 00:00:00. Using first match before 2024-03-24 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-03-24 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-03-25 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-03-25 00:00:00\n",
      "No match after 2024-03-25 00:00:00. Using first match before 2024-03-25 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-03-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30407.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-03-25 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-03-25 00:00:00\n",
      "No match after 2024-03-25 00:00:00. Using first match before 2024-03-25 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-03-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30393.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-03-26 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-03-26 00:00:00\n",
      "No match after 2024-03-26 00:00:00. Using first match before 2024-03-26 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-03-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-03-26 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-03-26 00:00:00\n",
      "No match after 2024-03-26 00:00:00. Using first match before 2024-03-26 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-03-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-03-27 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-03-27 00:00:00\n",
      "No match after 2024-03-27 00:00:00. Using first match before 2024-03-27 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-03-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-03-27 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-03-27 00:00:00\n",
      "No match after 2024-03-27 00:00:00. Using first match before 2024-03-27 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-03-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-03-28 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-03-28 00:00:00\n",
      "No match after 2024-03-28 00:00:00. Using first match before 2024-03-28 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-03-28 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30428.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-03-28 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-03-28 00:00:00\n",
      "No match after 2024-03-28 00:00:00. Using first match before 2024-03-28 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-03-28 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-03-29 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-03-29 00:00:00\n",
      "No match after 2024-03-29 00:00:00. Using first match before 2024-03-29 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-03-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-03-29 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-03-29 00:00:00\n",
      "No match after 2024-03-29 00:00:00. Using first match before 2024-03-29 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-03-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30400.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-03-30 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-03-30 00:00:00\n",
      "No match after 2024-03-30 00:00:00. Using first match before 2024-03-30 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-03-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-03-30 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-03-30 00:00:00\n",
      "No match after 2024-03-30 00:00:00. Using first match before 2024-03-30 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-03-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-03-31 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-03-31 00:00:00\n",
      "No match after 2024-03-31 00:00:00. Using first match before 2024-03-31 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-03-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-03-31 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-03-31 00:00:00\n",
      "No match after 2024-03-31 00:00:00. Using first match before 2024-03-31 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-03-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-03-31 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-03-31 00:00:00\n",
      "No match after 2024-03-31 00:00:00. Using first match before 2024-03-31 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-03-31 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-03-31 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-03-31 00:00:00\n",
      "No match after 2024-03-31 00:00:00. Using first match before 2024-03-31 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-03-31 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30414.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-01 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-01 00:00:00\n",
      "No match after 2024-04-01 00:00:00. Using first match before 2024-04-01 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-01 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30435.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-01 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-01 00:00:00\n",
      "No match after 2024-04-01 00:00:00. Using first match before 2024-04-01 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-01 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-02 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-02 00:00:00\n",
      "No match after 2024-04-02 00:00:00. Using first match before 2024-04-02 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-02 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-02 00:00:00\n",
      "No match after 2024-04-02 00:00:00. Using first match before 2024-04-02 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-02 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30393.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-03 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-03 00:00:00\n",
      "No match after 2024-04-03 00:00:00. Using first match before 2024-04-03 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-03 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-03 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-03 00:00:00\n",
      "No match after 2024-04-03 00:00:00. Using first match before 2024-04-03 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-03 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-04 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-04 00:00:00\n",
      "No match after 2024-04-04 00:00:00. Using first match before 2024-04-04 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-04-04 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-04-04 00:00:00\n",
      "No match after 2024-04-04 00:00:00. Using first match before 2024-04-04 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-04-04 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-04-05 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-04-05 00:00:00\n",
      "No match after 2024-04-05 00:00:00. Using first match before 2024-04-05 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-04-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-04-05 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-04-05 00:00:00\n",
      "No match after 2024-04-05 00:00:00. Using first match before 2024-04-05 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-04-05 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-06 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-06 00:00:00\n",
      "No match after 2024-04-06 00:00:00. Using first match before 2024-04-06 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-06 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-06 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-06 00:00:00\n",
      "No match after 2024-04-06 00:00:00. Using first match before 2024-04-06 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-07 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-07 00:00:00\n",
      "No match after 2024-04-07 00:00:00. Using first match before 2024-04-07 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-07 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-07 00:00:00\n",
      "No match after 2024-04-07 00:00:00. Using first match before 2024-04-07 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-07 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-07 00:00:00\n",
      "No match after 2024-04-07 00:00:00. Using first match before 2024-04-07 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-07 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30435.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-07 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-07 00:00:00\n",
      "No match after 2024-04-07 00:00:00. Using first match before 2024-04-07 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-08 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-08 00:00:00\n",
      "No match after 2024-04-08 00:00:00. Using first match before 2024-04-08 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-04-08 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-04-08 00:00:00\n",
      "No match after 2024-04-08 00:00:00. Using first match before 2024-04-08 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-04-08 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30414.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-04-09 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-04-09 00:00:00\n",
      "No match after 2024-04-09 00:00:00. Using first match before 2024-04-09 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-04-09 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-04-09 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-04-09 00:00:00\n",
      "No match after 2024-04-09 00:00:00. Using first match before 2024-04-09 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-04-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-10 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-10 00:00:00\n",
      "No match after 2024-04-10 00:00:00. Using first match before 2024-04-10 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30428.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-10 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-10 00:00:00\n",
      "No match after 2024-04-10 00:00:00. Using first match before 2024-04-10 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-11 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-11 00:00:00\n",
      "No match after 2024-04-11 00:00:00. Using first match before 2024-04-11 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-11 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-11 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-11 00:00:00\n",
      "No match after 2024-04-11 00:00:00. Using first match before 2024-04-11 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-11 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-12 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-12 00:00:00\n",
      "No match after 2024-04-12 00:00:00. Using first match before 2024-04-12 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-12 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-12 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-12 00:00:00\n",
      "No match after 2024-04-12 00:00:00. Using first match before 2024-04-12 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-12 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-04-13 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-04-13 00:00:00\n",
      "No match after 2024-04-13 00:00:00. Using first match before 2024-04-13 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-04-13 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30407.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-13 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-13 00:00:00\n",
      "No match after 2024-04-13 00:00:00. Using first match before 2024-04-13 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-13 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-14 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-14 00:00:00\n",
      "No match after 2024-04-14 00:00:00. Using first match before 2024-04-14 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-14 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-14 00:00:00\n",
      "No match after 2024-04-14 00:00:00. Using first match before 2024-04-14 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30400.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-04-14 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-04-14 00:00:00\n",
      "No match after 2024-04-14 00:00:00. Using first match before 2024-04-14 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-04-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-14 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-14 00:00:00\n",
      "No match after 2024-04-14 00:00:00. Using first match before 2024-04-14 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-14 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-04-15 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-04-15 00:00:00\n",
      "No match after 2024-04-15 00:00:00. Using first match before 2024-04-15 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-04-15 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-15 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-15 00:00:00\n",
      "No match after 2024-04-15 00:00:00. Using first match before 2024-04-15 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-15 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30393.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-16 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-16 00:00:00\n",
      "No match after 2024-04-16 00:00:00. Using first match before 2024-04-16 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-16 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-16 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-16 00:00:00\n",
      "No match after 2024-04-16 00:00:00. Using first match before 2024-04-16 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-16 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-17 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-17 00:00:00\n",
      "No match after 2024-04-17 00:00:00. Using first match before 2024-04-17 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-17 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-17 00:00:00\n",
      "No match after 2024-04-17 00:00:00. Using first match before 2024-04-17 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-18 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-18 00:00:00\n",
      "No match after 2024-04-18 00:00:00. Using first match before 2024-04-18 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-18 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30435.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-04-18 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-04-18 00:00:00\n",
      "No match after 2024-04-18 00:00:00. Using first match before 2024-04-18 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-04-18 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-04-19 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-04-19 00:00:00\n",
      "No match after 2024-04-19 00:00:00. Using first match before 2024-04-19 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-04-19 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-19 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-19 00:00:00\n",
      "No match after 2024-04-19 00:00:00. Using first match before 2024-04-19 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-19 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-04-20 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-04-20 00:00:00\n",
      "No match after 2024-04-20 00:00:00. Using first match before 2024-04-20 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-04-20 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-20 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-20 00:00:00\n",
      "No match after 2024-04-20 00:00:00. Using first match before 2024-04-20 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-20 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-04-21 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-04-21 00:00:00\n",
      "No match after 2024-04-21 00:00:00. Using first match before 2024-04-21 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-04-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30407.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-21 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-21 00:00:00\n",
      "No match after 2024-04-21 00:00:00. Using first match before 2024-04-21 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-21 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-21 00:00:00\n",
      "No match after 2024-04-21 00:00:00. Using first match before 2024-04-21 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-21 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-21 00:00:00\n",
      "No match after 2024-04-21 00:00:00. Using first match before 2024-04-21 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30393.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-22 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-22 00:00:00\n",
      "No match after 2024-04-22 00:00:00. Using first match before 2024-04-22 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30435.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-22 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-22 00:00:00\n",
      "No match after 2024-04-22 00:00:00. Using first match before 2024-04-22 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-04-23 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-04-23 00:00:00\n",
      "No match after 2024-04-23 00:00:00. Using first match before 2024-04-23 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-04-23 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-23 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-23 00:00:00\n",
      "No match after 2024-04-23 00:00:00. Using first match before 2024-04-23 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-23 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-24 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-24 00:00:00\n",
      "No match after 2024-04-24 00:00:00. Using first match before 2024-04-24 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-24 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-24 00:00:00\n",
      "No match after 2024-04-24 00:00:00. Using first match before 2024-04-24 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48341.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-25 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-25 00:00:00\n",
      "No match after 2024-04-25 00:00:00. Using first match before 2024-04-25 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-25 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-04-25 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-04-25 00:00:00\n",
      "No match after 2024-04-25 00:00:00. Using first match before 2024-04-25 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-04-25 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-26 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-26 00:00:00\n",
      "No match after 2024-04-26 00:00:00. Using first match before 2024-04-26 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-04-26 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-04-26 00:00:00\n",
      "No match after 2024-04-26 00:00:00. Using first match before 2024-04-26 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-04-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-27 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-27 00:00:00\n",
      "No match after 2024-04-27 00:00:00. Using first match before 2024-04-27 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-04-27 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-04-27 00:00:00\n",
      "No match after 2024-04-27 00:00:00. Using first match before 2024-04-27 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-04-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-27 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-27 00:00:00\n",
      "No match after 2024-04-27 00:00:00. Using first match before 2024-04-27 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-27 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-27 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-27 00:00:00\n",
      "No match after 2024-04-27 00:00:00. Using first match before 2024-04-27 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-27 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-04-28 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-04-28 00:00:00\n",
      "No match after 2024-04-28 00:00:00. Using first match before 2024-04-28 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-04-28 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-04-28 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-04-28 00:00:00\n",
      "No match after 2024-04-28 00:00:00. Using first match before 2024-04-28 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-04-28 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-04-28 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-04-28 00:00:00\n",
      "No match after 2024-04-28 00:00:00. Using first match before 2024-04-28 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-04-28 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-04-28 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-04-28 00:00:00\n",
      "No match after 2024-04-28 00:00:00. Using first match before 2024-04-28 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-04-28 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30393.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-04-29 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-04-29 00:00:00\n",
      "No match after 2024-04-29 00:00:00. Using first match before 2024-04-29 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-04-29 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-04-29 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-04-29 00:00:00\n",
      "No match after 2024-04-29 00:00:00. Using first match before 2024-04-29 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-04-29 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30400.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-04-30 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-04-30 00:00:00\n",
      "No match after 2024-04-30 00:00:00. Using first match before 2024-04-30 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-04-30 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30435.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-04-30 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-04-30 00:00:00\n",
      "No match after 2024-04-30 00:00:00. Using first match before 2024-04-30 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-04-30 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-05-01 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-05-01 00:00:00\n",
      "No match after 2024-05-01 00:00:00. Using first match before 2024-05-01 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-05-01 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-05-01 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-05-01 00:00:00\n",
      "No match after 2024-05-01 00:00:00. Using first match before 2024-05-01 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-05-01 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-02 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-02 00:00:00\n",
      "No match after 2024-05-02 00:00:00. Using first match before 2024-05-02 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-05-02 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-05-02 00:00:00\n",
      "No match after 2024-05-02 00:00:00. Using first match before 2024-05-02 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-05-02 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-05-03 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-05-03 00:00:00\n",
      "No match after 2024-05-03 00:00:00. Using first match before 2024-05-03 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-05-03 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-05-03 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-05-03 00:00:00\n",
      "No match after 2024-05-03 00:00:00. Using first match before 2024-05-03 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-05-03 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-05-04 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-05-04 00:00:00\n",
      "No match after 2024-05-04 00:00:00. Using first match before 2024-05-04 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-05-04 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-05-04 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-05-04 00:00:00\n",
      "No match after 2024-05-04 00:00:00. Using first match before 2024-05-04 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-05-04 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30393.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-05-05 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-05-05 00:00:00\n",
      "No match after 2024-05-05 00:00:00. Using first match before 2024-05-05 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-05-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-05-05 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-05-05 00:00:00\n",
      "No match after 2024-05-05 00:00:00. Using first match before 2024-05-05 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-05-05 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-05-05 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-05-05 00:00:00\n",
      "No match after 2024-05-05 00:00:00. Using first match before 2024-05-05 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-05-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30414.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-05-05 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-05-05 00:00:00\n",
      "No match after 2024-05-05 00:00:00. Using first match before 2024-05-05 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-05-05 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-06 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-06 00:00:00\n",
      "No match after 2024-05-06 00:00:00. Using first match before 2024-05-06 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-06 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-05-06 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-05-06 00:00:00\n",
      "No match after 2024-05-06 00:00:00. Using first match before 2024-05-06 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-05-06 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-05-07 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-05-07 00:00:00\n",
      "No match after 2024-05-07 00:00:00. Using first match before 2024-05-07 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-05-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-05-07 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-05-07 00:00:00\n",
      "No match after 2024-05-07 00:00:00. Using first match before 2024-05-07 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-05-07 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-05-08 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-05-08 00:00:00\n",
      "No match after 2024-05-08 00:00:00. Using first match before 2024-05-08 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-05-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-08 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-08 00:00:00\n",
      "No match after 2024-05-08 00:00:00. Using first match before 2024-05-08 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-08 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-05-09 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-05-09 00:00:00\n",
      "No match after 2024-05-09 00:00:00. Using first match before 2024-05-09 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-05-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-05-09 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-05-09 00:00:00\n",
      "No match after 2024-05-09 00:00:00. Using first match before 2024-05-09 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-05-09 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 48341 and match_dt: 2024-05-10 00:00:00\n",
      "Filtered 24 matches for team_id: 48341\n",
      "Found 24 matches before and 0 matches after 2024-05-10 00:00:00\n",
      "No match after 2024-05-10 00:00:00. Using first match before 2024-05-10 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 48341 is playing as team2 in the first match before 2024-05-10 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48341: [200.0 166.66666666666669 12 8 1 81 45 9.449477351916377\n",
      " 17.393939393939394 31]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48341.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-05-10 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-05-10 00:00:00\n",
      "No match after 2024-05-10 00:00:00. Using first match before 2024-05-10 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-05-10 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30414.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-05-11 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-05-11 00:00:00\n",
      "No match after 2024-05-11 00:00:00. Using first match before 2024-05-11 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-05-11 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30400.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-05-11 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-05-11 00:00:00\n",
      "No match after 2024-05-11 00:00:00. Using first match before 2024-05-11 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-05-11 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-05-12 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-05-12 00:00:00\n",
      "No match after 2024-05-12 00:00:00. Using first match before 2024-05-12 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-05-12 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30428.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-05-12 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-05-12 00:00:00\n",
      "No match after 2024-05-12 00:00:00. Using first match before 2024-05-12 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-05-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30414.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-05-12 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-05-12 00:00:00\n",
      "No match after 2024-05-12 00:00:00. Using first match before 2024-05-12 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-05-12 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-05-12 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-05-12 00:00:00\n",
      "No match after 2024-05-12 00:00:00. Using first match before 2024-05-12 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-05-12 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30421.\n",
      "Extracting data for team_id: 30421 and match_dt: 2024-05-14 00:00:00\n",
      "Filtered 37 matches for team_id: 30421\n",
      "Found 37 matches before and 0 matches after 2024-05-14 00:00:00\n",
      "No match after 2024-05-14 00:00:00. Using first match before 2024-05-14 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30421 is playing as team2 in the first match before 2024-05-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30421: [159.8 138.3106796116505 8 6 0 72 28 8.222984562607204 16.65714285714286\n",
      " 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30421.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-05-14 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-05-14 00:00:00\n",
      "No match after 2024-05-14 00:00:00. Using first match before 2024-05-14 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-05-14 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team2 columns in first file for team2_id 48334.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-05-15 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-05-15 00:00:00\n",
      "No match after 2024-05-15 00:00:00. Using first match before 2024-05-15 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-05-15 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30428.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-05-15 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-05-15 00:00:00\n",
      "No match after 2024-05-15 00:00:00. Using first match before 2024-05-15 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-05-15 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30407.\n",
      "Extracting data for team_id: 48334 and match_dt: 2024-05-17 00:00:00\n",
      "Filtered 19 matches for team_id: 48334\n",
      "Found 19 matches before and 0 matches after 2024-05-17 00:00:00\n",
      "No match after 2024-05-17 00:00:00. Using first match before 2024-05-17 00:00:00: 2023-07-05 00:00:00 (team1_id: 48341, team2_id: 48334)\n",
      "Team 48334 is playing as team2 in the first match before 2024-05-17 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 48334: [173.6 147.63725490196077 10 5 0 67 38 8.319587628865978\n",
      " 14.923076923076923 36]\n",
      "Adding extracted data to team1 columns in first file for team1_id 48334.\n",
      "Extracting data for team_id: 30435 and match_dt: 2024-05-17 00:00:00\n",
      "Filtered 31 matches for team_id: 30435\n",
      "Found 31 matches before and 0 matches after 2024-05-17 00:00:00\n",
      "No match after 2024-05-17 00:00:00. Using first match before 2024-05-17 00:00:00: 2023-12-05 00:00:00 (team1_id: 30435, team2_id: 48341)\n",
      "Team 30435 is playing as team1 in the first match before 2024-05-17 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30435: [182.4 158.4777369622085 12 5 1 77 39 9.005405405405405 23.125 28]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30435.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-05-18 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-05-18 00:00:00\n",
      "No match after 2024-05-18 00:00:00. Using first match before 2024-05-18 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-05-18 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30414 and match_dt: 2024-05-18 00:00:00\n",
      "Filtered 36 matches for team_id: 30414\n",
      "Found 36 matches before and 0 matches after 2024-05-18 00:00:00\n",
      "No match after 2024-05-18 00:00:00. Using first match before 2024-05-18 00:00:00: 2023-10-05 00:00:00 (team1_id: 30414, team2_id: 30421)\n",
      "Team 30414 is playing as team1 in the first match before 2024-05-18 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30414: [173.8 154.11104889884285 10 4 0 63 38 8.268551236749117\n",
      " 18.258064516129032 35]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30414.\n",
      "Extracting data for team_id: 30407 and match_dt: 2024-05-19 00:00:00\n",
      "Filtered 32 matches for team_id: 30407\n",
      "Found 32 matches before and 0 matches after 2024-05-19 00:00:00\n",
      "No match after 2024-05-19 00:00:00. Using first match before 2024-05-19 00:00:00: 2023-08-05 00:00:00 (team1_id: 30407, team2_id: 30400)\n",
      "Team 30407 is playing as team1 in the first match before 2024-05-19 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30407: [190.6 158.83333333333331 6 1 0 46 27 9.19 16.216216216216218 30]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30407.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-19 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-19 00:00:00\n",
      "No match after 2024-05-19 00:00:00. Using first match before 2024-05-19 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-19 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team2 columns in first file for team2_id 36014.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-21 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-21 00:00:00\n",
      "No match after 2024-05-21 00:00:00. Using first match before 2024-05-21 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-21 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-05-21 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-05-21 00:00:00\n",
      "No match after 2024-05-21 00:00:00. Using first match before 2024-05-21 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-05-21 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30400.\n",
      "Extracting data for team_id: 30393 and match_dt: 2024-05-22 00:00:00\n",
      "Filtered 37 matches for team_id: 30393\n",
      "Found 37 matches before and 0 matches after 2024-05-22 00:00:00\n",
      "No match after 2024-05-22 00:00:00. Using first match before 2024-05-22 00:00:00: 2023-09-05 00:00:00 (team1_id: 30393, team2_id: 30435)\n",
      "Team 30393 is playing as team1 in the first match before 2024-05-22 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team1_id 30393: [171.8 145.65732087227417 8 7 2 85 26 8.784466019417476 17.75862068965517\n",
      " 29]\n",
      "Adding extracted data to team1 columns in first file for team1_id 30393.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-05-22 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-05-22 00:00:00\n",
      "No match after 2024-05-22 00:00:00. Using first match before 2024-05-22 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-05-22 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-24 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-24 00:00:00\n",
      "No match after 2024-05-24 00:00:00. Using first match before 2024-05-24 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30428 and match_dt: 2024-05-24 00:00:00\n",
      "Filtered 33 matches for team_id: 30428\n",
      "Found 33 matches before and 0 matches after 2024-05-24 00:00:00\n",
      "No match after 2024-05-24 00:00:00. Using first match before 2024-05-24 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30428 is playing as team2 in the first match before 2024-05-24 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team2_id 30428: [170.6 150.4871794871795 12 6 0 74 37 8.796330275229357 14.342105263157896\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30428.\n",
      "Extracting data for team_id: 36014 and match_dt: 2024-05-26 00:00:00\n",
      "Filtered 32 matches for team_id: 36014\n",
      "Found 32 matches before and 0 matches after 2024-05-26 00:00:00\n",
      "No match after 2024-05-26 00:00:00. Using first match before 2024-05-26 00:00:00: 2023-07-05 00:00:00 (team1_id: 30428, team2_id: 36014)\n",
      "Team 36014 is playing as team2 in the first match before 2024-05-26 00:00:00. Extracting team2 columns.\n",
      "Extracted data for team1_id 36014: [183.0 152.5 8 6 1 83 33 9.187183811129849 20.448275862068964 24]\n",
      "Adding extracted data to team1 columns in first file for team1_id 36014.\n",
      "Extracting data for team_id: 30400 and match_dt: 2024-05-26 00:00:00\n",
      "Filtered 41 matches for team_id: 30400\n",
      "Found 41 matches before and 0 matches after 2024-05-26 00:00:00\n",
      "No match after 2024-05-26 00:00:00. Using first match before 2024-05-26 00:00:00: 2023-11-05 00:00:00 (team1_id: 30400, team2_id: 30428)\n",
      "Team 30400 is playing as team1 in the first match before 2024-05-26 00:00:00. Extracting team1 columns.\n",
      "Extracted data for team2_id 30400: [183.8 153.5819209039548 13 7 0 78 46 8.754782608695653 19.82758620689655\n",
      " 30]\n",
      "Adding extracted data to team2 columns in first file for team2_id 30400.\n",
      "   match id  team1  team1_id  \\\n",
      "0   9272619  Me Ss     33949   \n",
      "1   9086958     Na       209   \n",
      "2   9433654     Gn      7573   \n",
      "3   9097248     Ks     22784   \n",
      "4   9097234     Ws     23841   \n",
      "\n",
      "                                    team1_roster_ids  team2  team2_id  \\\n",
      "0  4003390.0:7960994.0:3901078.0:2669316.0:373710...  Ht Hs     33928   \n",
      "1  5836452.0:8246468.0:7500324.0:3065502.0:363350...  Si La        69   \n",
      "2  5164844.0:8110185.0:2979857.0:1722048.0:270743...     St      9701   \n",
      "3  3496933.0:4167673.0:4160316.0:1863889.0:310883...     Ds     22763   \n",
      "4  4166882.0:3009215.0:1963443.0:3252927.0:417185...     Ts     23750   \n",
      "\n",
      "                                    team2_roster_ids toss winner  \\\n",
      "0  5843200.0:4223883.0:4655384.0:6249256.0:216159...       Ht Hs   \n",
      "1  7200598.0:4403531.0:3260564.0:2420760.0:239834...       Si La   \n",
      "2  6139370.0:7694581.0:3294444.0:3239102.0:481700...          St   \n",
      "3  3399745.0:4898074.0:3782225.0:2252452.0:223190...          Ks   \n",
      "4  2654014.0:2667223.0:3406717.0:3057312.0:415964...          Ts   \n",
      "\n",
      "  toss decision           venue  ... rolling_avg_team2__  \\\n",
      "0         field        Be Ol Ht  ...                 NaN   \n",
      "1         field  GA Sm Sh Gg Va  ...               149.2   \n",
      "2         field        Sa Gs Cf  ...                 NaN   \n",
      "3           bat  St Gs Pk Pt Eh  ...               136.4   \n",
      "4         field  St Gs Pk Pt Eh  ...               127.6   \n",
      "\n",
      "  rolling_strike_rate_team2__ no_30+score_team_last5_team2__  \\\n",
      "0                         NaN                            NaN   \n",
      "1                  128.249986                           11.0   \n",
      "2                         NaN                            NaN   \n",
      "3                  116.652905                            8.0   \n",
      "4                  113.887123                            5.0   \n",
      "\n",
      "  no_50+score_team_last5_team2__ no_100+score_team_last5_team2__  \\\n",
      "0                            NaN                             NaN   \n",
      "1                            4.0                             0.0   \n",
      "2                            NaN                             NaN   \n",
      "3                            3.0                             0.0   \n",
      "4                            1.0                             0.0   \n",
      "\n",
      "   boundaries_hit_team2__  sixes_hit_team2__  \\\n",
      "0                     NaN                NaN   \n",
      "1                    46.0               29.0   \n",
      "2                     NaN                NaN   \n",
      "3                    40.0               21.0   \n",
      "4                    38.0               13.0   \n",
      "\n",
      "   avg_bowler_economy_last5_team2__  rolling_avg_bowl_strRate_team2__  \\\n",
      "0                               NaN                               NaN   \n",
      "1                          8.266423                         26.095238   \n",
      "2                               NaN                               NaN   \n",
      "3                          6.580311                         19.300000   \n",
      "4                          6.652406                         15.162162   \n",
      "\n",
      "   wickets_taken_last5_team2__  \n",
      "0                          NaN  \n",
      "1                         30.0  \n",
      "2                          NaN  \n",
      "3                         32.0  \n",
      "4                         39.0  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "file1_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/Test Data Sample.csv'\n",
    "file2_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Features Only Cleaned.xlsx'\n",
    "updated_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/updated_data.csv'\n",
    "\n",
    "# Load the existing CSV file\n",
    "df_existing = pd.read_csv(file1_path)\n",
    "\n",
    "# Load the second Excel file\n",
    "df_new = pd.read_excel(file2_path)\n",
    "\n",
    "# Define the columns to extract\n",
    "columns_to_extract = [\n",
    "    'rolling_avg_team1', 'rolling_avg_team2', 'rolling_strike_rate_team1', 'rolling_strike_rate_team2',\n",
    "    'no_30+score_team_last5_team1', 'no_50+score_team_last5_team1', 'no_100+score_team_last5_team1',\n",
    "    'no_30+score_team_last5_team2', 'no_50+score_team_last5_team2', 'no_100+score_team_last5_team2',\n",
    "    'boundaries_hit_team1', 'boundaries_hit_team2', 'sixes_hit_team1', 'sixes_hit_team2',\n",
    "    'avg_bowler_economy_last5_team1', 'avg_bowler_economy_last5_team2', 'rolling_avg_bowl_strRate_team1',\n",
    "    'rolling_avg_bowl_strRate_team2', 'wickets_taken_last5_team1', 'wickets_taken_last5_team2'\n",
    "]\n",
    "\n",
    "# Convert match_dt to datetime in both DataFrames\n",
    "df_existing['match_dt'] = pd.to_datetime(df_existing['match_dt'])\n",
    "df_new['match_dt'] = pd.to_datetime(df_new['match_dt'])\n",
    "\n",
    "# Function to extract data for a given team and match date\n",
    "def extract_team_data(match_dt, team_id, df_new, columns_to_extract):\n",
    "    print(f\"Extracting data for team_id: {team_id} and match_dt: {match_dt}\")\n",
    "    \n",
    "    # Filter the second DataFrame for the specific team\n",
    "    df_team = df_new[(df_new['team1_id'] == team_id) | (df_new['team2_id'] == team_id)]\n",
    "    print(f\"Filtered {len(df_team)} matches for team_id: {team_id}\")\n",
    "\n",
    "    # Sort matches before and after the given match_dt\n",
    "    df_team_before = df_team[df_team['match_dt'] <= match_dt].sort_values(by='match_dt', ascending=False)\n",
    "    df_team_after = df_team[df_team['match_dt'] > match_dt].sort_values(by='match_dt')\n",
    "\n",
    "    print(f\"Found {len(df_team_before)} matches before and {len(df_team_after)} matches after {match_dt}\")\n",
    "\n",
    "    if not df_team_after.empty:\n",
    "        first_match_after = df_team_after.iloc[0]\n",
    "        print(f\"First match after {match_dt}: {first_match_after['match_dt']} (team1_id: {first_match_after['team1_id']}, team2_id: {first_match_after['team2_id']})\")\n",
    "        if first_match_after['team1_id'] == team_id:\n",
    "            print(f\"Team {team_id} is playing as team1 in the first match after {match_dt}. Extracting team1 columns.\")\n",
    "            return first_match_after[[col for col in columns_to_extract if 'team1' in col]]\n",
    "        else:\n",
    "            print(f\"Team {team_id} is playing as team2 in the first match after {match_dt}. Extracting team2 columns.\")\n",
    "            return first_match_after[[col for col in columns_to_extract if 'team2' in col]]\n",
    "    elif not df_team_before.empty:\n",
    "        first_match_before = df_team_before.iloc[0]\n",
    "        print(f\"No match after {match_dt}. Using first match before {match_dt}: {first_match_before['match_dt']} (team1_id: {first_match_before['team1_id']}, team2_id: {first_match_before['team2_id']})\")\n",
    "        if first_match_before['team1_id'] == team_id:\n",
    "            print(f\"Team {team_id} is playing as team1 in the first match before {match_dt}. Extracting team1 columns.\")\n",
    "            return first_match_before[[col for col in columns_to_extract if 'team1' in col]]\n",
    "        else:\n",
    "            print(f\"Team {team_id} is playing as team2 in the first match before {match_dt}. Extracting team2 columns.\")\n",
    "            return first_match_before[[col for col in columns_to_extract if 'team2' in col]]\n",
    "    print(f\"No match found for team_id: {team_id} either before or after {match_dt}\")\n",
    "    return pd.Series([None] * len(columns_to_extract), index=columns_to_extract)\n",
    "\n",
    "# Iterate over each row in the existing DataFrame\n",
    "for idx, row in df_existing.iterrows():\n",
    "    match_dt = row['match_dt']\n",
    "    \n",
    "    # Process team1\n",
    "    team1_id = row['team1_id']\n",
    "    team1_data = extract_team_data(match_dt, team1_id, df_new, columns_to_extract)\n",
    "    print(f\"Extracted data for team1_id {team1_id}: {team1_data.values}\")\n",
    "    \n",
    "    if row['team1_id'] == team1_id:\n",
    "        print(f\"Adding extracted data to team1 columns in first file for team1_id {team1_id}.\")\n",
    "        for col in team1_data.index:\n",
    "            new_col_name = col.replace('team1', 'team1_').replace('team2', 'team1_')\n",
    "            df_existing.loc[idx, new_col_name] = team1_data[col]\n",
    "    else:\n",
    "        print(f\"Adding extracted data to team2 columns in first file for team1_id {team1_id}.\")\n",
    "        for col in team1_data.index:\n",
    "            new_col_name = col.replace('team1', 'team2_').replace('team2', 'team2_')\n",
    "            df_existing.loc[idx, new_col_name] = team1_data[col]\n",
    "    \n",
    "    # Process team2\n",
    "    team2_id = row['team2_id']\n",
    "    team2_data = extract_team_data(match_dt, team2_id, df_new, columns_to_extract)\n",
    "    print(f\"Extracted data for team2_id {team2_id}: {team2_data.values}\")\n",
    "    \n",
    "    if row['team2_id'] == team2_id:\n",
    "        print(f\"Adding extracted data to team2 columns in first file for team2_id {team2_id}.\")\n",
    "        for col in team2_data.index:\n",
    "            new_col_name = col.replace('team1', 'team2_').replace('team2', 'team2_')\n",
    "            df_existing.loc[idx, new_col_name] = team2_data[col]\n",
    "    else:\n",
    "        print(f\"Adding extracted data to team1 columns in first file for team2_id {team2_id}.\")\n",
    "        for col in team2_data.index:\n",
    "            new_col_name = col.replace('team1', 'team1_').replace('team2', 'team1_')\n",
    "            df_existing.loc[idx, new_col_name] = team2_data[col]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df_existing.to_csv(updated_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(df_existing.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76104ed-3d7c-44fa-96cc-3abda99154db",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a695c7f6-6f3d-46a4-b1d1-189e575fae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.2, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 400}\n",
      "Accuracy: 0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Features Only Cleaned.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure match_id is not the index\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert match_date to datetime and extract date features\n",
    "data['match_date'] = pd.to_datetime(data['match_date'])\n",
    "data['year'] = data['match_date'].dt.year\n",
    "data['month'] = data['match_date'].dt.month\n",
    "data['day_of_week'] = data['match_date'].dt.dayofweek\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['toss_winner_team_name', 'toss_decision_by_toss_winning_team']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column].astype(str))\n",
    "\n",
    "# Create binary target variable: 1 if team1 wins, 0 if team2 wins\n",
    "data['target'] = (data['winner_id'] == data['team1_id']).astype(int)\n",
    "\n",
    "# Prepare the data\n",
    "features = ['boundaries_hit_team1', 'boundaries_hit_team2',\n",
    "            'rolling_avg_bowl_strRate_team1', 'rolling_avg_bowl_strRate_team2', 'rolling_avg_team1', \n",
    "            'rolling_avg_team2', 'rolling_strike_rate_team1', 'rolling_strike_rate_team2', \n",
    "            'toss_winner_team_name', \n",
    "            'toss_decision_by_toss_winning_team', 'team1_id', 'team2_id', 'wickets_taken_last5_team2', 'wickets_taken_last5_team1']\n",
    "\n",
    "X = data[features]\n",
    "y = data['target']\n",
    "\n",
    "# Identify and handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Sort the data by match_date to ensure correct ordering\n",
    "data = data.sort_values(by='match_date')\n",
    "\n",
    "# Define the percentage for training data\n",
    "train_size = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "# Determine the cutoff index for the training set\n",
    "cutoff_index = int(len(data) * train_size)\n",
    "\n",
    "# Split the data into training and testing sets based on the cutoff index\n",
    "train_data = data.iloc[:cutoff_index]\n",
    "test_data = data.iloc[cutoff_index:]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['target']\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Impute missing values in train and test sets\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Define the model and hyperparameter grid\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'learning_rate': [0.01, 0.3, 0.5],\n",
    "    'max_depth': [11, 13, 15],\n",
    "    'colsample_bytree': [0.2, 0.8]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, '/Users/pratikrohila/Desktop/AMEX DATA/xgboost_cricket_model_tuned.pkl')\n",
    "\n",
    "# Save the label encoder for future use\n",
    "joblib.dump(label_encoder, '/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e757f41-f7e9-48a3-981c-bb6dd2d0efb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     match_id  team1_id  team2_id  predicted_winner\n",
      "0     9272619   33949.0   33928.0           33928.0\n",
      "1     9086958     209.0      69.0              69.0\n",
      "2     9433654    7573.0    9701.0            7573.0\n",
      "3     9097248   22784.0   22763.0           22763.0\n",
      "4     9097234   23841.0   23750.0           23750.0\n",
      "..        ...       ...       ...               ...\n",
      "202   9984162   30407.0   36014.0           36014.0\n",
      "203   9984176   36014.0   30400.0           36014.0\n",
      "204   9984183   30393.0   30428.0           30428.0\n",
      "205   9984190   36014.0   30428.0           30428.0\n",
      "206   9984197   36014.0   30400.0           36014.0\n",
      "\n",
      "[207 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model = joblib.load('/Users/pratikrohila/Desktop/AMEX DATA/xgboost_cricket_model_tuned.pkl')\n",
    "label_encoder = joblib.load('/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl')\n",
    "\n",
    "# Define a function to prepare new match data\n",
    "def prepare_new_match_data(new_data, label_encoder, features):\n",
    "    # Encode categorical features\n",
    "    categorical_columns = ['toss_winner_team_name', 'toss_decision_by_toss_winning_team']\n",
    "    for column in categorical_columns:\n",
    "        new_data[column] = new_data[column].astype(str).map(lambda s: s if s in label_encoder.classes_ else '<unknown>')\n",
    "        new_data[column] = new_data[column].map(lambda s: label_encoder.transform([s])[0] if s in label_encoder.classes_ else -1)\n",
    "    \n",
    "    # Identify and handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    new_data[features] = imputer.fit_transform(new_data[features])\n",
    "    \n",
    "    return new_data[features]\n",
    "\n",
    "# Load the new match data from the provided CSV file\n",
    "new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/updated_data.csv'\n",
    "new_match_data = pd.read_csv(new_file_path)\n",
    "\n",
    "# Define the feature columns\n",
    "features = [\n",
    "    'boundaries_hit_team1_', 'boundaries_hit_team2_',\n",
    "    'rolling_avg_bowl_strRate_team1_', 'rolling_avg_bowl_strRate_team2_', \n",
    "    'rolling_avg_team1_', 'rolling_avg_team2_', \n",
    "    'rolling_strike_rate_team1_', 'rolling_strike_rate_team2_', \n",
    "    'toss_winner_team_name', 'toss_decision_by_toss_winning_team', \n",
    "    'team1_id', 'team2_id', 'wickets_taken_last5_team2_', \n",
    "    'wickets_taken_last5_team1_'\n",
    "]\n",
    "\n",
    "# Prepare the new match data\n",
    "X_new = prepare_new_match_data(new_match_data, label_encoder, features)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Map predictions back to team1_id or team2_id\n",
    "new_match_data['predicted_winner'] = new_match_data.apply(\n",
    "    lambda row: row['team1_id'] if predictions[row.name] == 1 else row['team2_id'], axis=1)\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "output_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/predicted_winners_New3.csv'\n",
    "new_match_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the predictions\n",
    "print(new_match_data[['match_id', 'team1_id', 'team2_id', 'predicted_winner']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6478244-8718-4bb5-bbfd-acc7d604128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id dataset_type  win_pred_team_id  win_pred_score train_algorithm  \\\n",
      "0   9272619           r1             33949        0.533543         xgboost   \n",
      "1   9086958           r1                69        0.376358         xgboost   \n",
      "2   9433654           r1              7573        0.716891         xgboost   \n",
      "3   9097248           r1             22784        0.559862         xgboost   \n",
      "4   9097234           r1             23750        0.474241         xgboost   \n",
      "\n",
      "  Ensemble?  train_hps_trees  train_hps_depth  train_hps_lr indep_feat_id1  \\\n",
      "0        no              100                8           0.1                  \n",
      "1        no              100                8           0.1                  \n",
      "2        no              100                8           0.1                  \n",
      "3        no              100                8           0.1                  \n",
      "4        no              100                8           0.1                  \n",
      "\n",
      "  indep_feat_id2 indep_feat_id3 indep_feat_id4 indep_feat_id5 indep_feat_id6  \\\n",
      "0                                                                              \n",
      "1                                                                              \n",
      "2                                                                              \n",
      "3                                                                              \n",
      "4                                                                              \n",
      "\n",
      "  indep_feat_id7 indep_feat_id8 indep_feat_id9 indep_feat_id10  \n",
      "0                                                               \n",
      "1                                                               \n",
      "2                                                               \n",
      "3                                                               \n",
      "4                                                               \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model = joblib.load('/Users/pratikrohila/Desktop/AMEX DATA/xgboost_cricket_model_tuned.pkl')\n",
    "label_encoder = joblib.load('/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl')\n",
    "\n",
    "# Define a function to prepare new match data\n",
    "def prepare_new_match_data(new_data, label_encoder, features):\n",
    "    # Encode categorical features\n",
    "    categorical_columns = ['toss_winner_team_name', 'toss_decision_by_toss_winning_team']\n",
    "    for column in categorical_columns:\n",
    "        new_data[column] = new_data[column].astype(str).map(lambda s: s if s in label_encoder.classes_ else '<unknown>')\n",
    "        new_data[column] = new_data[column].map(lambda s: label_encoder.transform([s])[0] if s in label_encoder.classes_ else -1)\n",
    "    \n",
    "    # Identify and handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    new_data[features] = imputer.fit_transform(new_data[features])\n",
    "    \n",
    "    return new_data[features]\n",
    "\n",
    "# Load the new match data from the provided CSV file\n",
    "new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/updated_data.csv'\n",
    "new_match_data = pd.read_csv(new_file_path)\n",
    "\n",
    "# Define the feature columns expected by the model\n",
    "features = [\n",
    "    'boundaries_hit_team1_', 'boundaries_hit_team2_',\n",
    "    'rolling_avg_bowl_strRate_team1_', 'rolling_avg_bowl_strRate_team2_', \n",
    "    'rolling_avg_team1_', 'rolling_avg_team2_', \n",
    "    'rolling_strike_rate_team1_', 'rolling_strike_rate_team2_', \n",
    "    'no_30+score_team_last5_team1_', 'no_50+score_team_last5_team1_', \n",
    "    'no_30+score_team_last5_team2_', 'no_50+score_team_last5_team2_', \n",
    "    'toss_winner_team_name', 'toss_decision_by_toss_winning_team'\n",
    "]\n",
    "\n",
    "# Add dataset_type with default value\n",
    "new_match_data['dataset_type'] = 'r1'  # or 'train' based on your context\n",
    "\n",
    "# Ensure we select only the features expected by the model\n",
    "new_match_data = new_match_data[features + ['team1_id', 'team2_id', 'match_id', 'dataset_type']]\n",
    "\n",
    "# Prepare the new match data\n",
    "X_new = prepare_new_match_data(new_match_data, label_encoder, features)\n",
    "\n",
    "# Make predictions and get probabilities\n",
    "predictions = model.predict(X_new)\n",
    "prediction_probs = model.predict_proba(X_new)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Map predictions back to team1_id or team2_id\n",
    "new_match_data['win_pred_team_id'] = new_match_data.apply(\n",
    "    lambda row: row['team1_id'] if predictions[row.name] == 1 else row['team2_id'], axis=1)\n",
    "\n",
    "# Add win_pred_score (probability)\n",
    "new_match_data['win_pred_score'] = prediction_probs\n",
    "\n",
    "# Add fixed variables\n",
    "new_match_data['train_algorithm'] = 'xgboost'\n",
    "new_match_data['Ensemble?'] = 'no'\n",
    "new_match_data['train_hps_trees'] = 100\n",
    "new_match_data['train_hps_depth'] = 8\n",
    "new_match_data['train_hps_lr'] = 0.1\n",
    "\n",
    "# Add empty columns for dynamic variables\n",
    "for i in range(1, 11):\n",
    "    new_match_data[f'indep_feat_id{i}'] = ''\n",
    "\n",
    "# Create the submission dataframe with required columns\n",
    "submission = new_match_data[['match_id', 'dataset_type', 'win_pred_team_id', 'win_pred_score', \n",
    "                             'train_algorithm', 'Ensemble?', 'train_hps_trees', 'train_hps_depth', \n",
    "                             'train_hps_lr'] + [f'indep_feat_id{i}' for i in range(1, 11)]]\n",
    "\n",
    "# Save the submission dataframe to a new CSV file\n",
    "output_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/predicted_winners_New4.csv'\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the submission dataframe\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec566a93-ffb3-4ddf-8fcf-be228696add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.2, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 400}\n",
      "Accuracy: 0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Features Only Cleaned.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure match_id is not the index\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert match_date to datetime and extract date features\n",
    "data['match_date'] = pd.to_datetime(data['match_date'])\n",
    "data['year'] = data['match_date'].dt.year\n",
    "data['month'] = data['match_date'].dt.month\n",
    "data['day_of_week'] = data['match_date'].dt.dayofweek\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['toss_winner_team_name', 'toss_decision_by_toss_winning_team']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column].astype(str))\n",
    "\n",
    "# Create binary target variable: 1 if team1 wins, 0 if team2 wins\n",
    "data['target'] = (data['winner_id'] == data['team1_id']).astype(int)\n",
    "\n",
    "# Prepare the data\n",
    "features = ['boundaries_hit_team1', 'boundaries_hit_team2',\n",
    "            'rolling_avg_bowl_strRate_team1', 'rolling_avg_bowl_strRate_team2', 'rolling_avg_team1', \n",
    "            'rolling_avg_team2', 'rolling_strike_rate_team1', 'rolling_strike_rate_team2', \n",
    "            'toss_winner_team_name', \n",
    "            'toss_decision_by_toss_winning_team', 'team1_id', 'team2_id', 'wickets_taken_last5_team2', 'wickets_taken_last5_team1']\n",
    "\n",
    "X = data[features]\n",
    "y = data['target']\n",
    "\n",
    "# Identify and handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Sort the data by match_date to ensure correct ordering\n",
    "data = data.sort_values(by='match_date')\n",
    "\n",
    "# Define the percentage for training data\n",
    "train_size = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "# Determine the cutoff index for the training set\n",
    "cutoff_index = int(len(data) * train_size)\n",
    "\n",
    "# Split the data into training and testing sets based on the cutoff index\n",
    "train_data = data.iloc[:cutoff_index]\n",
    "test_data = data.iloc[cutoff_index:]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['target']\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Impute missing values in train and test sets\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Define the model and hyperparameter grid\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'learning_rate': [0.01, 0.3, 0.5],\n",
    "    'max_depth': [11, 13, 15],\n",
    "    'colsample_bytree': [0.2, 0.8]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, '/Users/pratikrohila/Desktop/AMEX DATA/xgboost_cricket_model_tuned.pkl')\n",
    "\n",
    "# Save the label encoder for future use\n",
    "joblib.dump(label_encoder, '/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49d72e4f-ad93-4aaa-bbad-ba2d59cabfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features are present in the new match data\n",
      "Shape of new_match_data: (207, 14)\n",
      "Expected number of features: 14\n",
      "   match_id dataset_type  win_pred_team_id  win_pred_score train_algorithm  \\\n",
      "0   9272619           r1           33928.0        0.440741         xgboost   \n",
      "1   9086958           r1              69.0        0.337049         xgboost   \n",
      "2   9433654           r1            7573.0        0.663494         xgboost   \n",
      "3   9097248           r1           22763.0        0.379820         xgboost   \n",
      "4   9097234           r1           23750.0        0.392633         xgboost   \n",
      "\n",
      "  Ensemble?  train_hps_trees  train_hps_depth  train_hps_lr  indep_feat_id1  \\\n",
      "0        no              100                8           0.1       15.972973   \n",
      "1        no              100                8           0.1       23.083333   \n",
      "2        no              100                8           0.1       15.157895   \n",
      "3        no              100                8           0.1       15.833333   \n",
      "4        no              100                8           0.1       17.294118   \n",
      "\n",
      "   indep_feat_id2  indep_feat_id3  indep_feat_id4  indep_feat_id5  \\\n",
      "0       15.055556           144.0           151.8      120.000000   \n",
      "1       26.095238           120.6           149.2      102.346753   \n",
      "2       17.000000           179.2           153.4      149.790961   \n",
      "3       19.300000           138.8           136.4      119.549020   \n",
      "4       15.162162           151.0           127.6      125.833333   \n",
      "\n",
      "   indep_feat_id6  indep_feat_id7  indep_feat_id8  indep_feat_id9  \\\n",
      "0      140.695094            -1.0             1.0            33.0   \n",
      "1      128.249986            -1.0             1.0            30.0   \n",
      "2      145.901075            -1.0             1.0            47.0   \n",
      "3      116.652905            -1.0             0.0            32.0   \n",
      "4      113.887124            -1.0             1.0            39.0   \n",
      "\n",
      "   indep_feat_id10  \n",
      "0             35.0  \n",
      "1             25.0  \n",
      "2             36.0  \n",
      "3             28.0  \n",
      "4             29.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model = joblib.load('/Users/pratikrohila/Desktop/AMEX DATA/xgboost_cricket_model_tuned.pkl')\n",
    "label_encoder = joblib.load('/Users/pratikrohila/Desktop/AMEX DATA/label_encoder.pkl')\n",
    "\n",
    "# Define a function to prepare new match data\n",
    "def prepare_new_match_data(new_data, label_encoder, features):\n",
    "    # Encode categorical features\n",
    "    categorical_columns = ['toss_winner_team_name', 'toss_decision_by_toss_winning_team']\n",
    "    for column in categorical_columns:\n",
    "        new_data[column] = new_data[column].astype(str).map(lambda s: s if s in label_encoder.classes_ else '<unknown>')\n",
    "        new_data[column] = new_data[column].map(lambda s: label_encoder.transform([s])[0] if s in label_encoder.classes_ else -1)\n",
    "    \n",
    "    # Identify and handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    new_data[features] = imputer.fit_transform(new_data[features])\n",
    "    \n",
    "    return new_data[features]\n",
    "\n",
    "# Load the new match data from the provided CSV file\n",
    "new_file_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/updated_data.csv'\n",
    "new_match_data = pd.read_csv(new_file_path)\n",
    "\n",
    "# Define the feature columns expected by the model\n",
    "# Replace 'some_other_feature1', 'some_other_feature2' with actual feature names used in training\n",
    "features = [\n",
    "    'boundaries_hit_team1_', 'boundaries_hit_team2_',\n",
    "    'rolling_avg_bowl_strRate_team1_', 'rolling_avg_bowl_strRate_team2_', \n",
    "    'rolling_avg_team1_', 'rolling_avg_team2_', \n",
    "    'rolling_strike_rate_team1_', 'rolling_strike_rate_team2_', \n",
    "    'toss_winner_team_name', 'toss_decision_by_toss_winning_team',\n",
    "    'wickets_taken_last5_team1_', 'wickets_taken_last5_team2_',\n",
    "    'team1_id', 'team2_id'\n",
    "]\n",
    "\n",
    "# Check if all features are in the new match data\n",
    "missing_features = [feature for feature in features if feature not in new_match_data.columns]\n",
    "if missing_features:\n",
    "    print(f\"Missing features in new match data: {missing_features}\")\n",
    "else:\n",
    "    print(\"All features are present in the new match data\")\n",
    "\n",
    "# Add dataset_type with default value\n",
    "new_match_data['dataset_type'] = 'r1'  # or 'train' based on your context\n",
    "\n",
    "# Ensure we select only the features expected by the model\n",
    "new_match_data = new_match_data[features + ['match_id', 'dataset_type']]\n",
    "\n",
    "# Print the shape of the new data to debug\n",
    "print(f\"Shape of new_match_data: {new_match_data[features].shape}\")\n",
    "print(f\"Expected number of features: {model.get_booster().num_features()}\")\n",
    "\n",
    "# Prepare the new match data\n",
    "X_new = prepare_new_match_data(new_match_data, label_encoder, features)\n",
    "\n",
    "# Make predictions and get probabilities\n",
    "predictions = model.predict(X_new)\n",
    "prediction_probs = model.predict_proba(X_new)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Map predictions back to team1_id or team2_id\n",
    "new_match_data['win_pred_team_id'] = new_match_data.apply(\n",
    "    lambda row: row['team1_id'] if predictions[row.name] == 1 else row['team2_id'], axis=1)\n",
    "\n",
    "# Add win_pred_score (probability)\n",
    "new_match_data['win_pred_score'] = prediction_probs\n",
    "\n",
    "# Add fixed variables\n",
    "new_match_data['train_algorithm'] = 'xgboost'\n",
    "new_match_data['Ensemble?'] = 'no'\n",
    "new_match_data['train_hps_trees'] = 100\n",
    "new_match_data['train_hps_depth'] = 8\n",
    "new_match_data['train_hps_lr'] = 0.1\n",
    "\n",
    "# Add top 10 features as dynamic variables\n",
    "top_10_features = [\n",
    "    'rolling_avg_bowl_strRate_team1_', 'rolling_avg_bowl_strRate_team2_', \n",
    "    'rolling_avg_team1_', 'rolling_avg_team2_', \n",
    "    'rolling_strike_rate_team1_', 'rolling_strike_rate_team2_', \n",
    "    'toss_winner_team_name', 'toss_decision_by_toss_winning_team', \n",
    "    'wickets_taken_last5_team2_', 'wickets_taken_last5_team1_'\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(top_10_features, 1):\n",
    "    new_match_data[f'indep_feat_id{i}'] = new_match_data[feature]\n",
    "\n",
    "# Create the submission dataframe with required columns\n",
    "submission = new_match_data[['match_id', 'dataset_type', 'win_pred_team_id', 'win_pred_score', \n",
    "                             'train_algorithm', 'Ensemble?', 'train_hps_trees', 'train_hps_depth', \n",
    "                             'train_hps_lr'] + [f'indep_feat_id{i}' for i in range(1, 11)]]\n",
    "\n",
    "# Save the submission dataframe to a new CSV file\n",
    "output_path = '/Users/pratikrohila/Desktop/AMEX Round 2/Test Data Sample/predicted_winners_New3.csv'\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the submission dataframe\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ff62d-7669-472a-a6ea-5066befcbca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
